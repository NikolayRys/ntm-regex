{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experimentation with Neural Turing Machines and two other models for sequence processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trying out 3 different models on 6 different datasets for algorithmic inference."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU support is available.\n"
     ]
    }
   ],
   "source": [
    "# Wire up the required libraries\n",
    "import numpy as np                                                 # Array operations\n",
    "import tensorflow as tf                                            # Deep learning\n",
    "import tensorflow.keras as keras                                   # For simplified deep learning interface\n",
    "from tensorflow.keras.models import Sequential                     # For building models\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Data preprocessing\n",
    "from sklearn.model_selection import train_test_split               # Data splitting\n",
    "import tensorflow_models as tfm                                    # Models library for transformers\n",
    "import keras_nlp as knlp                                           # For positional encoding\n",
    "import pandas as pd                                                # Dataframe operations\n",
    "import matplotlib.pyplot as plt                                    # Plot history\n",
    "import seaborn as sns                                              # Improve plot aesthetics\n",
    "import pickle                                                      # Save and training history\n",
    "import sys                                                         # For system calls\n",
    "sys.path.append('.')                                               # Add local modules to path\n",
    "from ntm import NTMCell                                            # Local NTM implementation\n",
    "\n",
    "# Custom layer to add positional encoding for the transformer model to use inside sequential Keras models\n",
    "class EncodePositions(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EncodePositions, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.add(inputs, knlp.layers.SinePositionEncoding()(inputs))\n",
    "\n",
    "# Common methods for all the experiments\n",
    "\n",
    "# Plot the training history for each model\n",
    "def plot_history(history):\n",
    "    # Plot training history, placing the figures side-by-side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    # Plot training and validation loss\n",
    "    ax1.plot(history.history['loss'], label='Training loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation loss')\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.axhline(y=0.0, color='r', linestyle='--')\n",
    "    ax1.legend()\n",
    "    # Plot training and validation accuracy\n",
    "    ax2.plot(history.history['accuracy'], label='Training accuracy')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.axhline(y=1.0, color='r', linestyle='--')\n",
    "    fig.show()\n",
    "\n",
    "# Common method for training each models, with fixed parameters\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    # Callback to restore the best weights\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True, mode='min')\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=1)\n",
    "    return history\n",
    "\n",
    "# Encode alphabet characters as one-hot vectors\n",
    "def char_to_one_hot(char, num_chars, char_to_index):\n",
    "    one_hot = np.zeros(num_chars)\n",
    "    one_hot[char_to_index[char]] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Encode a string as a one-hot matrix\n",
    "def string_to_one_hot(string, num_chars, char_to_index):\n",
    "    one_hot = np.zeros((len(string), num_chars))\n",
    "    for i, char in enumerate(string):\n",
    "        one_hot[i] = char_to_one_hot(char, num_chars, char_to_index)\n",
    "    return one_hot\n",
    "\n",
    "# Pad using keras pad_sequences\n",
    "def pad_one_hot(one_hot, max_seq_len):\n",
    "    return pad_sequences([one_hot], maxlen=max_seq_len, dtype='float32', padding='post', truncating='post')[0]\n",
    "\n",
    "# Show the contents and shape of the processed data\n",
    "def inspect_data(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    print(\"X_train shape: {}\".format(X_train.shape))\n",
    "    print(\"y_train shape: {}\".format(y_train.shape))\n",
    "    print(\"X_val shape: {}\".format(X_val.shape))\n",
    "    print(\"y_val shape: {}\".format(y_val.shape))\n",
    "    print(\"X_test shape: {}\".format(X_test.shape))\n",
    "    print(\"y_test shape: {}\".format(y_test.shape))\n",
    "    print(\"X_train example: {}\".format(X_train[0][0:5]))\n",
    "    print(\"y_train example: {}\".format(y_train[0][0:5]))\n",
    "\n",
    "# Common method to build the models, where input and output layers are fixed, but the core model is variable\n",
    "def build_model(layers, input_shape, output_shape, activation):\n",
    "    # First value is the max length of the one-hot vectors, and the second is the dimension of the alphabet\n",
    "    model = Sequential()\n",
    "    # Masking input layer to ignore padding\n",
    "    model.add(keras.layers.Masking(mask_value=0., input_shape=input_shape))\n",
    "    model.add(keras.layers.LayerNormalization())\n",
    "    # The variable component of the model\n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "    # Output and learning parameters\n",
    "    model.add(keras.layers.Dense(output_shape, activation=activation))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# Build Neural Turing Machine model with approx 1700 trainable parameters in the basic version\n",
    "def build_ntm(num_controller_units=6,  num_controller_layers=1,             # Memory controller parameters\n",
    "              num_memory_locations=32, memory_location_size=8,              # Memory size parameters\n",
    "              num_write_heads=1, num_read_heads=2,                          # Memory access parameters\n",
    "              recurrent_output_dimension=8,                                 # Output dimension of the NTM\n",
    "              input_shape=(22, 18), output_shape=2, activation='softmax'):  # Task-dependent configuration\n",
    "\n",
    "    ntm_cell = NTMCell(num_controller_layers, num_controller_units,\n",
    "                       num_memory_locations, memory_location_size,\n",
    "                       num_read_heads, num_write_heads,\n",
    "                       output_dim=recurrent_output_dimension)\n",
    "    layer = keras.layers.RNN(ntm_cell, name='neural_turing_machine')\n",
    "    model = build_model([layer], input_shape, output_shape, activation)\n",
    "    ntm_cell.params_count()\n",
    "    return model\n",
    "\n",
    "# Build LSTM model with approx 1700 trainable parameters in the basic version\n",
    "def build_lstm(nodes=13, input_shape=(22, 18), output_shape=2, activation='softmax'):\n",
    "    return build_model([keras.layers.LSTM(nodes)], input_shape, output_shape, activation)\n",
    "\n",
    "# Build Transformer model with approx 1700 trainable parameters in the basic version\n",
    "def build_transformer(num_layers=1, num_attention_heads=1,intermediate_size=8,\n",
    "                      input_shape=(22, 18), output_shape=2, activation='softmax'):\n",
    "    transformer_layers = [\n",
    "        # Add positional encoding as suggested in the paper https://arxiv.org/pdf/1706.03762.pdf\n",
    "        EncodePositions(),\n",
    "        # Main transformer layer, converting the input sequence to intermediate representations\n",
    "        tfm.nlp.models.TransformerEncoder(num_layers=num_layers, num_attention_heads=num_attention_heads, intermediate_size=intermediate_size),\n",
    "        # Reduce the converted sequence to a fixed length vector\n",
    "        keras.layers.GlobalMaxPooling1D()\n",
    "    ]\n",
    "    return build_model(transformer_layers, input_shape, output_shape, activation)\n",
    "\n",
    "# Compare models by training and plotting their validation loss\n",
    "def compare_models(ntm_train_data, lstm_train_data, transformer_train_data, X_test, y_test):\n",
    "    ntm_history = ntm_train_data.history\n",
    "    lstm_history = lstm_train_data.history\n",
    "    transformer_history = transformer_train_data.history\n",
    "    plt.plot(ntm_history['val_loss'], label='NTM')\n",
    "    plt.plot(lstm_history['val_loss'], label='LSTM')\n",
    "    plt.plot(transformer_history['val_loss'], label='Transformer')\n",
    "    plt.title('Validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    # Add baseline at y=0\n",
    "    plt.axhline(y=0.0, color='r', linestyle='--')\n",
    "\n",
    "    ntm_loss, _ = ntm_train_data.model.evaluate(X_test, y_test)\n",
    "    lstm_loss, _ = lstm_train_data.model.evaluate(X_test, y_test)\n",
    "    transformer_loss, _ = transformer_train_data.model.evaluate(X_test, y_test)\n",
    "\n",
    "    plt.axhline(y=ntm_loss, color='g', linestyle='--')\n",
    "    plt.axhline(y=lstm_loss, color='b', linestyle='--')\n",
    "    plt.axhline(y=transformer_loss, color='r', linestyle='--')\n",
    "\n",
    "    # Add label near minimums, placing it on the opposite side of the line\n",
    "    plt.text(0, ntm_loss + 0.01, 'NTM: {:.4f}'.format(ntm_loss), color='g')\n",
    "    plt.text(0, lstm_loss + 0.01, 'LSTM: {:.4f}'.format(lstm_loss), color='b')\n",
    "    plt.text(0, transformer_loss + 0.01, 'Transformer: {:.4f}'.format(transformer_loss), color='r')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Select and save the model that achieved the best test loss after 5 training attempts\n",
    "def determine_best_model(name, architecture, X_train, X_val, y_train, y_val, X_test, y_test, input_shape, output_shape, activation):\n",
    "    best_history = None\n",
    "    best_model = None\n",
    "    best_loss = None\n",
    "\n",
    "    # Try 5 times to counteract the randomness of the training\n",
    "    for i in range(5):\n",
    "        model = architecture(input_shape=input_shape, output_shape=output_shape, activation=activation)\n",
    "        history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "        loss, _ = model.evaluate(X_test, y_test)\n",
    "\n",
    "        if best_loss is None or loss < best_loss:\n",
    "            best_history = history\n",
    "            best_model = model\n",
    "            best_loss = loss\n",
    "\n",
    "    # Save model and history\n",
    "    best_model.save(f\"artefacts/best_{name}.h5\")\n",
    "    with open(f\"artefacts/best_history_{name}.pkl\", 'wb') as f:\n",
    "        pickle.dump(best_history, f)\n",
    "\n",
    "    # To load it back later\n",
    "    # ntm = keras.models.load_model( 'artefacts/best_1_ntm.h5', custom_objects={'NTMCell': NTMCell})\n",
    "    return best_history\n",
    "\n",
    "# Run the experiment for a given dataset on all 3 models\n",
    "def experiment(number, data_gen, holdout, input_shape, output_shape, activation):\n",
    "    X_train, X_val, y_train, y_val, X_test, y_test = data_gen(holdout=holdout)\n",
    "\n",
    "    with tf.device(\"/cpu:0\"): # After NTM implementation to TF 2.0, we need to temporarily switch off GPU usage, because there were some performance issues\n",
    "        ntm_history = determine_best_model(f\"ntm_{number}\", build_ntm, X_train, X_val, y_train, y_val, X_test, y_test, input_shape, output_shape, activation)\n",
    "    lstm_history = determine_best_model(f\"lstm_{number}\", build_lstm, X_train, X_val, y_train, y_val, X_test, y_test, input_shape, output_shape, activation)\n",
    "    transformer_history = determine_best_model(f\"transformer_{number}\", build_transformer, X_train, X_val, y_train, y_val, X_test, y_test, input_shape, output_shape, activation)\n",
    "\n",
    "    compare_models(ntm_history, lstm_history, transformer_history, X_test, y_test)\n",
    "\n",
    "# Check gpu availability for to speed up the training later\n",
    "if tf.test.is_built_with_cuda() and bool(tf.config.list_physical_devices('GPU')):\n",
    "    print(\"GPU support is available.\")\n",
    "else:\n",
    "    print(\"No GPU support available.\")\n",
    "\n",
    "# Use seaborn's default style to make attractive graphs\n",
    "sns.set()\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple regex for time recognition, 1700 parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Load and preprocess the data for the time recognition task\n",
    "def time_task(holdout):\n",
    "    # Convert alphabet into one-hot vectors\n",
    "    alphabet = \"0123456789APapMm: \"\n",
    "    num_chars = len(alphabet)\n",
    "    char_to_index = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\n",
    "    # Load the created data\n",
    "    df = pd.read_csv('time.csv')\n",
    "\n",
    "    # Convert true/false to categorical using keras.utils.to_categorical\n",
    "    df['valid_int'] = df['valid'].apply(lambda x: 1 if x else 0)\n",
    "    df['valid_one_hot'] = keras.utils.to_categorical(df['valid_int']).tolist()\n",
    "\n",
    "    # Convert the time strings to one-hot vectors and pad them to the max length with null characters\n",
    "    df['time_one_hot'] = df['string'].apply(lambda x: string_to_one_hot(x, num_chars, char_to_index))\n",
    "    # Find the max length of the one-hot vectors\n",
    "    max_seq_len = df['time_one_hot'].apply(lambda x: x.shape[0]).max()\n",
    "    df['time_one_hot'] = df['time_one_hot'].apply(lambda x: pad_one_hot(x, max_seq_len))\n",
    "\n",
    "    # Extract columns to make the data easier to work with\n",
    "    X = np.stack(df['time_one_hot'].values)\n",
    "    y = np.stack(df['valid_one_hot'].values)\n",
    "\n",
    "    # Split the data into training and testing sets, preserving the ratio of valid/invalid times\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=holdout, stratify=y, random_state=43)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=holdout, stratify=y_train_val, random_state=43)\n",
    "\n",
    "    # Illustrate the data\n",
    "    inspect_data(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    return X_train, X_val, y_train, y_val, X_test, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 1: Sufficient available data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7200, 22, 18)\n",
      "y_train shape: (7200, 2)\n",
      "X_val shape: (4800, 22, 18)\n",
      "y_val shape: (4800, 2)\n",
      "X_test shape: (8000, 22, 18)\n",
      "y_test shape: (8000, 2)\n",
      "X_train example: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "y_train example: [0. 1.]\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_7 (Masking)         (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_7 (Laye  (None, 22, 18)           36        \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 16s 93ms/step - loss: 0.6823 - accuracy: 0.5714 - val_loss: 0.6703 - val_accuracy: 0.6023\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.6398 - accuracy: 0.6572 - val_loss: 0.5976 - val_accuracy: 0.7031\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.4785 - accuracy: 0.7885 - val_loss: 0.3601 - val_accuracy: 0.8575\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.3151 - accuracy: 0.8767 - val_loss: 0.2750 - val_accuracy: 0.8950\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.2523 - accuracy: 0.9035 - val_loss: 0.2404 - val_accuracy: 0.9060\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.2227 - accuracy: 0.9165 - val_loss: 0.2128 - val_accuracy: 0.9204\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.1978 - accuracy: 0.9271 - val_loss: 0.1940 - val_accuracy: 0.9340\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.1753 - accuracy: 0.9369 - val_loss: 0.1721 - val_accuracy: 0.9377\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.1519 - accuracy: 0.9458 - val_loss: 0.1546 - val_accuracy: 0.9490\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.1329 - accuracy: 0.9521 - val_loss: 0.1382 - val_accuracy: 0.9504\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.1109 - accuracy: 0.9614 - val_loss: 0.1219 - val_accuracy: 0.9623\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0936 - accuracy: 0.9692 - val_loss: 0.1113 - val_accuracy: 0.9613\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0778 - accuracy: 0.9728 - val_loss: 0.0919 - val_accuracy: 0.9708\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0644 - accuracy: 0.9774 - val_loss: 0.0778 - val_accuracy: 0.9762\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0527 - accuracy: 0.9821 - val_loss: 0.0679 - val_accuracy: 0.9777\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0477 - accuracy: 0.9822 - val_loss: 0.1025 - val_accuracy: 0.9683\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0411 - accuracy: 0.9867 - val_loss: 0.0605 - val_accuracy: 0.9821\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0377 - accuracy: 0.9871 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.0594 - val_accuracy: 0.9823\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0591 - val_accuracy: 0.9821\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0297 - accuracy: 0.9901 - val_loss: 0.0558 - val_accuracy: 0.9844\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.0573 - val_accuracy: 0.9850\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.0503 - val_accuracy: 0.9858\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0246 - accuracy: 0.9901 - val_loss: 0.0434 - val_accuracy: 0.9885\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.0486 - val_accuracy: 0.9871\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0514 - val_accuracy: 0.9883\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0467 - val_accuracy: 0.9877\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0429 - val_accuracy: 0.9877\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0432 - val_accuracy: 0.9892\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0429 - val_accuracy: 0.9892\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0432 - val_accuracy: 0.9887\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.0595 - val_accuracy: 0.9879\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0457 - val_accuracy: 0.9890\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0502 - val_accuracy: 0.9890\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0470 - val_accuracy: 0.9890\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 0.0586 - val_accuracy: 0.9852\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0442 - val_accuracy: 0.9896\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0410 - val_accuracy: 0.9919\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0359 - val_accuracy: 0.9917\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0401 - val_accuracy: 0.9919\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0450 - val_accuracy: 0.9902\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0420 - val_accuracy: 0.9908\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0421 - val_accuracy: 0.9923\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0380 - val_accuracy: 0.9921\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0534 - val_accuracy: 0.9900\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0542 - val_accuracy: 0.9904\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0465 - val_accuracy: 0.9904\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0370 - val_accuracy: 0.9929\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0414 - val_accuracy: 0.9923\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 0.0579 - val_accuracy: 0.9862\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0319 - val_accuracy: 0.9929\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0369 - val_accuracy: 0.9917\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0303 - val_accuracy: 0.9927\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0344 - val_accuracy: 0.9929\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0325 - val_accuracy: 0.9929\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0384 - val_accuracy: 0.9925\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.0369 - val_accuracy: 0.9921\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0386 - val_accuracy: 0.9923\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.0309 - val_accuracy: 0.9942\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0362 - val_accuracy: 0.9921\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0451 - val_accuracy: 0.9921\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0398 - val_accuracy: 0.9919\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0343 - val_accuracy: 0.9927\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0339 - val_accuracy: 0.9933\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0363 - val_accuracy: 0.9935\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 9.9696e-04 - accuracy: 0.9999 - val_loss: 0.0412 - val_accuracy: 0.9927\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.0383 - val_accuracy: 0.9925\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0760 - val_accuracy: 0.9890\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.0327 - val_accuracy: 0.9923\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0405 - val_accuracy: 0.9917\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0401 - val_accuracy: 0.9919\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 9.1821e-04 - accuracy: 0.9997 - val_loss: 0.0373 - val_accuracy: 0.9929\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 7.0457e-04 - accuracy: 0.9999 - val_loss: 0.0369 - val_accuracy: 0.9935\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 6.7823e-04 - accuracy: 0.9999 - val_loss: 0.0371 - val_accuracy: 0.9929\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 5.4414e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9925\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 5.5016e-04 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9929\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 5.0786e-04 - accuracy: 0.9999 - val_loss: 0.0416 - val_accuracy: 0.9925\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 4.5415e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9919\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 3.9463e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9925\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 3.5573e-04 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9917\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 8.6555e-04 - accuracy: 0.9999 - val_loss: 0.0574 - val_accuracy: 0.9912\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.1765 - val_accuracy: 0.9440\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0292 - accuracy: 0.9933 - val_loss: 0.0316 - val_accuracy: 0.9929\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0294 - val_accuracy: 0.9937\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0342 - val_accuracy: 0.9931\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 6.7654e-04 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9940\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 5.9936e-04 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9931\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 5.3309e-04 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9931\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 4.8993e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9931\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 4.0969e-04 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9935\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 4.1283e-04 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9931\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 3.7281e-04 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9933\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 3.2318e-04 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9937\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 2.9561e-04 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9937\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 2.8033e-04 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9925\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 2.5139e-04 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9927\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 2.6523e-04 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9937\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 2.2777e-04 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9933\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 2.1511e-04 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9935\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.9441e-04 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9937\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.8493e-04 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9933\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.6670e-04 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9933\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.6740e-04 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9940\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.5803e-04 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9931\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.4333e-04 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9937\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.2508e-04 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9933\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.3079e-04 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9935\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.1225e-04 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9933\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.0721e-04 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9933\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.0075e-04 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9933\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 9.6144e-05 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9933\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 9.0150e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9931\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 8.3923e-05 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9940\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 7.6597e-05 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9931\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 6.7968e-05 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9933\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 7.6066e-05 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9940\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 5.8968e-05 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9935\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 6.0477e-05 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9935\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 5.3010e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9933\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 5.2775e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9933\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 4.5889e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9933\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 2.9629e-04 - accuracy: 0.9999 - val_loss: 0.0756 - val_accuracy: 0.9898\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.0344 - accuracy: 0.9926 - val_loss: 0.0460 - val_accuracy: 0.9912\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0579 - val_accuracy: 0.9902\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0222 - val_accuracy: 0.9946\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 9.0286e-04 - accuracy: 0.9999 - val_loss: 0.0234 - val_accuracy: 0.9950\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 3.2751e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9950\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 2.8052e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9950\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 2.4136e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9948\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 2.2242e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9950\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 2.0838e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9948\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.8037e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9950\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.6606e-04 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9944\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.5839e-04 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9948\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.4553e-04 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9948\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.3702e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9948\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.2034e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9946\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.1481e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 1.0790e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9946\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 9.9779e-05 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9948\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 9.2550e-05 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9950\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 8.8866e-05 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9948\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 7.6165e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9944\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 7.6177e-05 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9946\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 7.8186e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9948\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 6.6603e-05 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9946\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 6.6977e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9946\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 5.8977e-05 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9950\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 5.5313e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9950\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 5.1320e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9946\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 4.6891e-05 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9946\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 4.8218e-05 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9950\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 4.5346e-05 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9948\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 3.7287e-05 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9946\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 3.9443e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9946\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 3.5252e-05 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9946\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 3.2755e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9948\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 3.1733e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9944\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 2.8767e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9944\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 2.8754e-05 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9944\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 2.5608e-05 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9950\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 10s 89ms/step - loss: 2.3530e-05 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9950\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 2.2056e-05 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9946\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 2.0223e-05 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9944\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.9922e-05 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9944\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.9643e-05 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9942\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.7757e-05 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9944\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.6088e-05 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9950\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.5619e-05 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9948\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.5271e-05 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9946\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.3430e-05 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9944\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.2797e-05 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9944\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.2083e-05 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9946\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.0986e-05 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9942\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 1.0769e-05 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9946\n",
      "250/250 [==============================] - 5s 17ms/step - loss: 0.0203 - accuracy: 0.9966\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_8 (Masking)         (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_8 (Laye  (None, 22, 18)           36        \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 16s 92ms/step - loss: 0.6762 - accuracy: 0.5935 - val_loss: 0.6663 - val_accuracy: 0.6104\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.6371 - accuracy: 0.6567 - val_loss: 0.5989 - val_accuracy: 0.7060\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.5150 - accuracy: 0.7617 - val_loss: 0.4375 - val_accuracy: 0.8100\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 10s 88ms/step - loss: 0.4024 - accuracy: 0.8261 - val_loss: 0.3577 - val_accuracy: 0.8560\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.3218 - accuracy: 0.8724 - val_loss: 0.2859 - val_accuracy: 0.8854\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.2695 - accuracy: 0.8957 - val_loss: 0.2428 - val_accuracy: 0.9106\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.2251 - accuracy: 0.9158 - val_loss: 0.2068 - val_accuracy: 0.9215\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.1921 - accuracy: 0.9282 - val_loss: 0.1732 - val_accuracy: 0.9388\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.1620 - accuracy: 0.9415 - val_loss: 0.1498 - val_accuracy: 0.9473\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.1351 - accuracy: 0.9518 - val_loss: 0.1343 - val_accuracy: 0.9548\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.1134 - accuracy: 0.9603 - val_loss: 0.1150 - val_accuracy: 0.9617\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.1009 - accuracy: 0.9649 - val_loss: 0.1075 - val_accuracy: 0.9663\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.0861 - accuracy: 0.9694 - val_loss: 0.1105 - val_accuracy: 0.9667\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.0837 - accuracy: 0.9712 - val_loss: 0.1136 - val_accuracy: 0.9615\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.0708 - accuracy: 0.9739 - val_loss: 0.0910 - val_accuracy: 0.9710\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0618 - accuracy: 0.9785 - val_loss: 0.0854 - val_accuracy: 0.9704\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 0.0907 - val_accuracy: 0.9706\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0524 - accuracy: 0.9811 - val_loss: 0.0756 - val_accuracy: 0.9750\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0451 - accuracy: 0.9843 - val_loss: 0.0790 - val_accuracy: 0.9752\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0413 - accuracy: 0.9860 - val_loss: 0.0722 - val_accuracy: 0.9781\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0376 - accuracy: 0.9867 - val_loss: 0.0683 - val_accuracy: 0.9800\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0428 - accuracy: 0.9842 - val_loss: 0.1060 - val_accuracy: 0.9690\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0437 - accuracy: 0.9858 - val_loss: 0.0664 - val_accuracy: 0.9808\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0347 - accuracy: 0.9876 - val_loss: 0.0660 - val_accuracy: 0.9821\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0283 - accuracy: 0.9896 - val_loss: 0.0639 - val_accuracy: 0.9831\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.0633 - val_accuracy: 0.9833\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.0263 - accuracy: 0.9897 - val_loss: 0.0624 - val_accuracy: 0.9829\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0406 - accuracy: 0.9861 - val_loss: 0.0850 - val_accuracy: 0.9754\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0362 - accuracy: 0.9867 - val_loss: 0.0579 - val_accuracy: 0.9831\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.0571 - val_accuracy: 0.9852\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.0627 - val_accuracy: 0.9850\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0193 - accuracy: 0.9925 - val_loss: 0.0642 - val_accuracy: 0.9858\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.0598 - val_accuracy: 0.9860\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0172 - accuracy: 0.9928 - val_loss: 0.0603 - val_accuracy: 0.9869\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.0785 - val_accuracy: 0.9802\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0191 - accuracy: 0.9924 - val_loss: 0.0554 - val_accuracy: 0.9860\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 0.0575 - val_accuracy: 0.9865\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0140 - accuracy: 0.9943 - val_loss: 0.0561 - val_accuracy: 0.9860\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 0.0665 - val_accuracy: 0.9856\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 0.0595 - val_accuracy: 0.9869\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.0585 - val_accuracy: 0.9867\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.0633 - val_accuracy: 0.9875\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0143 - accuracy: 0.9946 - val_loss: 0.0826 - val_accuracy: 0.9837\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0188 - accuracy: 0.9925 - val_loss: 0.0565 - val_accuracy: 0.9873\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0143 - accuracy: 0.9942 - val_loss: 0.0569 - val_accuracy: 0.9883\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.0628 - val_accuracy: 0.9883\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 0.0660 - val_accuracy: 0.9869\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0119 - accuracy: 0.9947 - val_loss: 0.0693 - val_accuracy: 0.9875\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0111 - accuracy: 0.9949 - val_loss: 0.0782 - val_accuracy: 0.9860\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0434 - val_accuracy: 0.9892\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0469 - val_accuracy: 0.9898\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 0.0490 - val_accuracy: 0.9900\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0078 - accuracy: 0.9967 - val_loss: 0.0547 - val_accuracy: 0.9900\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0090 - accuracy: 0.9962 - val_loss: 0.0630 - val_accuracy: 0.9881\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.0549 - val_accuracy: 0.9900\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.0599 - val_accuracy: 0.9894\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.0677 - val_accuracy: 0.9873\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0671 - val_accuracy: 0.9887\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0664 - val_accuracy: 0.9896\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0069 - accuracy: 0.9969 - val_loss: 0.0543 - val_accuracy: 0.9900\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0610 - accuracy: 0.9851 - val_loss: 0.0504 - val_accuracy: 0.9877\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0426 - val_accuracy: 0.9908\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0443 - val_accuracy: 0.9912\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0460 - val_accuracy: 0.9912\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0531 - val_accuracy: 0.9900\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0527 - val_accuracy: 0.9910\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0542 - val_accuracy: 0.9900\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0583 - val_accuracy: 0.9904\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0483 - val_accuracy: 0.9910\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0576 - val_accuracy: 0.9904\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0626 - val_accuracy: 0.9902\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0507 - val_accuracy: 0.9894\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0469 - val_accuracy: 0.9892\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.0486 - val_accuracy: 0.9904\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0515 - val_accuracy: 0.9910\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0555 - val_accuracy: 0.9902\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0483 - val_accuracy: 0.9912\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0478 - val_accuracy: 0.9915\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0504 - val_accuracy: 0.9908\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0538 - val_accuracy: 0.9906\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0506 - val_accuracy: 0.9906\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0492 - val_accuracy: 0.9906\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0492 - val_accuracy: 0.9915\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.1489 - val_accuracy: 0.9737\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0460 - val_accuracy: 0.9910\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0493 - val_accuracy: 0.9906\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0527 - val_accuracy: 0.9910\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0569 - val_accuracy: 0.9910\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0563 - val_accuracy: 0.9900\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0608 - val_accuracy: 0.9902\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0588 - val_accuracy: 0.9902\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0592 - val_accuracy: 0.9908\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0582 - val_accuracy: 0.9906\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 10s 87ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0637 - val_accuracy: 0.9902\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9904\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0711 - val_accuracy: 0.9892\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0614 - val_accuracy: 0.9902\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0661 - val_accuracy: 0.9902\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0586 - val_accuracy: 0.9904\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.0749 - val_accuracy: 0.9794\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0418 - accuracy: 0.9896 - val_loss: 0.0465 - val_accuracy: 0.9892\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0464 - val_accuracy: 0.9919\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0451 - val_accuracy: 0.9923\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0479 - val_accuracy: 0.9923\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0473 - val_accuracy: 0.9923\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0530 - val_accuracy: 0.9915\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0494 - val_accuracy: 0.9919\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0537 - val_accuracy: 0.9912\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0536 - val_accuracy: 0.9912\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0549 - val_accuracy: 0.9912\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0537 - val_accuracy: 0.9919\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0549 - val_accuracy: 0.9915\n",
      "250/250 [==============================] - 5s 17ms/step - loss: 0.0434 - accuracy: 0.9914\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_9 (Masking)         (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_9 (Laye  (None, 22, 18)           36        \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 16s 94ms/step - loss: 0.6864 - accuracy: 0.5649 - val_loss: 0.6800 - val_accuracy: 0.5804\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.6584 - accuracy: 0.6307 - val_loss: 0.6266 - val_accuracy: 0.6673\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.5250 - accuracy: 0.7503 - val_loss: 0.4109 - val_accuracy: 0.8242\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.3159 - accuracy: 0.8790 - val_loss: 0.2468 - val_accuracy: 0.9098\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.2191 - accuracy: 0.9258 - val_loss: 0.1932 - val_accuracy: 0.9310\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.1678 - accuracy: 0.9454 - val_loss: 0.1515 - val_accuracy: 0.9538\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.1343 - accuracy: 0.9572 - val_loss: 0.1260 - val_accuracy: 0.9615\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.1055 - accuracy: 0.9697 - val_loss: 0.1096 - val_accuracy: 0.9696\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0926 - accuracy: 0.9732 - val_loss: 0.0958 - val_accuracy: 0.9698\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0779 - accuracy: 0.9771 - val_loss: 0.0867 - val_accuracy: 0.9769\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0697 - accuracy: 0.9799 - val_loss: 0.0795 - val_accuracy: 0.9790\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0648 - accuracy: 0.9817 - val_loss: 0.0706 - val_accuracy: 0.9810\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0545 - accuracy: 0.9854 - val_loss: 0.0707 - val_accuracy: 0.9810\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0486 - accuracy: 0.9875 - val_loss: 0.0706 - val_accuracy: 0.9796\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0502 - accuracy: 0.9864 - val_loss: 0.0619 - val_accuracy: 0.9827\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0409 - accuracy: 0.9889 - val_loss: 0.0612 - val_accuracy: 0.9840\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0426 - accuracy: 0.9882 - val_loss: 0.0591 - val_accuracy: 0.9846\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0365 - accuracy: 0.9903 - val_loss: 0.0593 - val_accuracy: 0.9823\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0385 - accuracy: 0.9893 - val_loss: 0.0527 - val_accuracy: 0.9860\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0355 - accuracy: 0.9906 - val_loss: 0.0498 - val_accuracy: 0.9869\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0315 - accuracy: 0.9910 - val_loss: 0.0498 - val_accuracy: 0.9865\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0299 - accuracy: 0.9919 - val_loss: 0.0583 - val_accuracy: 0.9833\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0495 - val_accuracy: 0.9862\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0291 - accuracy: 0.9914 - val_loss: 0.0442 - val_accuracy: 0.9890\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0470 - val_accuracy: 0.9875\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 0.0474 - val_accuracy: 0.9867\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 0.0393 - val_accuracy: 0.9906\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0425 - val_accuracy: 0.9896\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.0413 - val_accuracy: 0.9892\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 0.0460 - val_accuracy: 0.9887\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 0.0639 - val_accuracy: 0.9827\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.0398 - val_accuracy: 0.9906\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0493 - val_accuracy: 0.9885\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.0434 - val_accuracy: 0.9912\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.0663 - val_accuracy: 0.9835\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.0326 - val_accuracy: 0.9923\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0376 - val_accuracy: 0.9917\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0425 - val_accuracy: 0.9919\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0521 - val_accuracy: 0.9894\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0330 - val_accuracy: 0.9937\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0464 - val_accuracy: 0.9917\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0387 - val_accuracy: 0.9931\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.0335 - val_accuracy: 0.9935\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0371 - val_accuracy: 0.9931\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0363 - val_accuracy: 0.9925\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0351 - val_accuracy: 0.9925\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.0389 - val_accuracy: 0.9929\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0395 - val_accuracy: 0.9931\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.0299 - val_accuracy: 0.9937\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0337 - val_accuracy: 0.9937\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0404 - val_accuracy: 0.9908\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0363 - val_accuracy: 0.9942\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0294 - val_accuracy: 0.9935\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0356 - val_accuracy: 0.9935\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0335 - val_accuracy: 0.9933\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.0290 - val_accuracy: 0.9933\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0317 - val_accuracy: 0.9944\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0367 - val_accuracy: 0.9927\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0287 - val_accuracy: 0.9952\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0524 - val_accuracy: 0.9921\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0343 - val_accuracy: 0.9937\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0365 - val_accuracy: 0.9933\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0300 - val_accuracy: 0.9940\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0339 - val_accuracy: 0.9952\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0356 - val_accuracy: 0.9944\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0378 - val_accuracy: 0.9942\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0300 - val_accuracy: 0.9946\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.0286 - val_accuracy: 0.9946\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0371 - val_accuracy: 0.9940\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0292 - val_accuracy: 0.9950\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0394 - val_accuracy: 0.9937\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0318 - val_accuracy: 0.9950\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0314 - val_accuracy: 0.9948\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0342 - val_accuracy: 0.9950\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0352 - val_accuracy: 0.9929\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0332 - val_accuracy: 0.9946\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0353 - val_accuracy: 0.9950\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0346 - val_accuracy: 0.9940\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0792 - val_accuracy: 0.9873\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0281 - val_accuracy: 0.9958\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0286 - val_accuracy: 0.9960\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0265 - val_accuracy: 0.9969\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0367 - val_accuracy: 0.9935\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.0731e-04 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9965\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.1461e-04 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9962\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.5550e-04 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9967\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 2.9262e-04 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9962\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.1585e-04 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9962\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.1494e-04 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9954\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 0.0297 - val_accuracy: 0.9948\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0437 - val_accuracy: 0.9915\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.0301 - val_accuracy: 0.9946\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0289 - val_accuracy: 0.9948\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.8796e-04 - accuracy: 0.9999 - val_loss: 0.0266 - val_accuracy: 0.9965\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.2533e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9967\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.8695e-04 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9960\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.4093e-04 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9967\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.1041e-04 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9967\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.7853e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9967\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.5934e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9967\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 1.4030e-04 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9965\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 1.3249e-04 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9965\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.1026e-04 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9965\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.0393e-04 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9965\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 9.2573e-05 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9965\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.3762e-05 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9965\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.7374e-05 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9965\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.1134e-05 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9962\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.1315e-05 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9962\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.5401e-05 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9962\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.3699e-05 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9960\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.2253e-05 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9962\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 4.7316e-05 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9960\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 4.4208e-05 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9962\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 3.9891e-05 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9962\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.7043e-05 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9962\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 3.4330e-05 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9962\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 3.2292e-05 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9960\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 2.9527e-05 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9962\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.8344e-05 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9962\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 2.6360e-05 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9962\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 2.4274e-05 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9962\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.1909e-05 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9962\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 2.0665e-05 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9962\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.9366e-05 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9965\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.7645e-05 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9962\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.6746e-05 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9960\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.5381e-05 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9965\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.4281e-05 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9965\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 1.3523e-05 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9965\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 1.1990e-05 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9965\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 1.0958e-05 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9965\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.0312e-05 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9965\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 9.5546e-06 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9965\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.7838e-06 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9965\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.2494e-06 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9965\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.5341e-06 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9965\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 7.1287e-06 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9965\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.4446e-06 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9965\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 6.3130e-06 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9965\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 5.6967e-06 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9965\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.2097e-06 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9965\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 4.7785e-06 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9967\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.6502e-06 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9967\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.1929e-06 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9965\n",
      "250/250 [==============================] - 5s 17ms/step - loss: 0.0198 - accuracy: 0.9965\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_10 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_10 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 16s 91ms/step - loss: 0.6894 - accuracy: 0.5608 - val_loss: 0.6817 - val_accuracy: 0.5967\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.6513 - accuracy: 0.6464 - val_loss: 0.5957 - val_accuracy: 0.7023\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.4667 - accuracy: 0.7875 - val_loss: 0.3605 - val_accuracy: 0.8515\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.2908 - accuracy: 0.8900 - val_loss: 0.2613 - val_accuracy: 0.9021\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.2241 - accuracy: 0.9186 - val_loss: 0.2196 - val_accuracy: 0.9202\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.1832 - accuracy: 0.9353 - val_loss: 0.1728 - val_accuracy: 0.9438\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.1476 - accuracy: 0.9499 - val_loss: 0.1395 - val_accuracy: 0.9473\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.1096 - accuracy: 0.9651 - val_loss: 0.0983 - val_accuracy: 0.9733\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0844 - accuracy: 0.9726 - val_loss: 0.0815 - val_accuracy: 0.9785\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0638 - accuracy: 0.9815 - val_loss: 0.0582 - val_accuracy: 0.9825\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0457 - accuracy: 0.9875 - val_loss: 0.0487 - val_accuracy: 0.9871\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.0425 - val_accuracy: 0.9890\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.0364 - val_accuracy: 0.9894\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0311 - val_accuracy: 0.9912\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.0282 - val_accuracy: 0.9933\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.0438 - val_accuracy: 0.9869\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 0.0245 - val_accuracy: 0.9937\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.0249 - val_accuracy: 0.9944\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.0238 - val_accuracy: 0.9948\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0258 - val_accuracy: 0.9942\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0211 - val_accuracy: 0.9956\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0337 - val_accuracy: 0.9919\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0201 - val_accuracy: 0.9954\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0193 - val_accuracy: 0.9958\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0217 - val_accuracy: 0.9954\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0337 - val_accuracy: 0.9944\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0256 - val_accuracy: 0.9944\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0217 - val_accuracy: 0.9950\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0204 - val_accuracy: 0.9956\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0298 - val_accuracy: 0.9950\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0194 - val_accuracy: 0.9958\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0212 - val_accuracy: 0.9954\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.5425e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9956\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.2553e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9958\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.0357e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9960\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.9688e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9960\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.4022e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9960\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.6563e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9962\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.9947e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9954\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.4252e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9965\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.2870e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9962\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.3217e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9958\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.0828e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9958\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.8504e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9958\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.8022e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9958\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.5718e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9958\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.4750e-04 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9960\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.3951e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9958\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.3093e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9960\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.1572e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9958\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.0615e-04 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9956\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 9.6127e-05 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9962\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.8286e-05 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9960\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.1879e-05 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9962\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.7691e-05 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9960\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.4394e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9962\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.4934e-05 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9962\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.0285e-05 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9960\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.3196e-05 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9960\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.2537e-05 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9965\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.2332e-05 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9967\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.6824e-05 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9962\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.0060e-05 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9962\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.7944e-05 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9962\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.5742e-05 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9967\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.3579e-05 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9962\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.2154e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9960\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.8989e-05 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9960\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.7954e-05 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9965\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.4994e-05 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9965\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.4268e-05 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9965\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.1231e-05 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9967\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.0818e-05 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9967\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.8910e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9962\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.7612e-05 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9965\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.5985e-05 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9965\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.4950e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9965\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.3683e-05 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9965\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.2998e-05 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9967\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.2363e-05 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9965\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.1616e-05 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9965\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.0859e-05 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9965\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.0319e-05 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9965\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 9.3310e-06 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9965\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.8389e-06 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9965\n",
      "250/250 [==============================] - 5s 17ms/step - loss: 0.0157 - accuracy: 0.9969\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_11 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_11 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 17s 91ms/step - loss: 0.6894 - accuracy: 0.5421 - val_loss: 0.6794 - val_accuracy: 0.6029\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.6469 - accuracy: 0.6568 - val_loss: 0.5864 - val_accuracy: 0.7175\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.4997 - accuracy: 0.7672 - val_loss: 0.3982 - val_accuracy: 0.8354\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 0.3252 - accuracy: 0.8717 - val_loss: 0.2673 - val_accuracy: 0.9056\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.2277 - accuracy: 0.9201 - val_loss: 0.2092 - val_accuracy: 0.9329\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.1735 - accuracy: 0.9404 - val_loss: 0.1641 - val_accuracy: 0.9435\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.1304 - accuracy: 0.9585 - val_loss: 0.1240 - val_accuracy: 0.9583\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0933 - accuracy: 0.9717 - val_loss: 0.0894 - val_accuracy: 0.9719\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0722 - accuracy: 0.9808 - val_loss: 0.0762 - val_accuracy: 0.9800\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 0.0558 - accuracy: 0.9837 - val_loss: 0.0614 - val_accuracy: 0.9840\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0492 - accuracy: 0.9862 - val_loss: 0.0577 - val_accuracy: 0.9844\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 0.0535 - val_accuracy: 0.9865\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 0.0330 - accuracy: 0.9901 - val_loss: 0.0445 - val_accuracy: 0.9875\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.0432 - val_accuracy: 0.9892\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.0380 - val_accuracy: 0.9900\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 0.0362 - val_accuracy: 0.9900\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.0429 - val_accuracy: 0.9892\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0274 - val_accuracy: 0.9927\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0279 - val_accuracy: 0.9931\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0332 - val_accuracy: 0.9925\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0246 - val_accuracy: 0.9944\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0271 - val_accuracy: 0.9944\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0261 - val_accuracy: 0.9948\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0306 - val_accuracy: 0.9946\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0268 - val_accuracy: 0.9935\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0306 - val_accuracy: 0.9944\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9944\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.6346e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9950\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 6.8023e-04 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9952\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.0990e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9954\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.4218e-04 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9954\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.3325e-04 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9956\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.6756e-04 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9958\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.5723e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9958\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.0165e-04 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9954\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 2.1643e-04 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9956\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 1.9946e-04 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9952\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.5354e-04 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9942\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.0389 - val_accuracy: 0.9923\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0214 - val_accuracy: 0.9940\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0194 - val_accuracy: 0.9962\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.0212 - val_accuracy: 0.9956\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0240 - val_accuracy: 0.9948\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.3640e-04 - accuracy: 0.9999 - val_loss: 0.0183 - val_accuracy: 0.9962\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.3763e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9965\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 2.8308e-04 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9967\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.3092e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9960\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.9039e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9969\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.6605e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9967\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.4744e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9969\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.3656e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9962\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.2613e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9969\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.1083e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9971\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.0091e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9969\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 9.4169e-05 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9969\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.4892e-05 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9967\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.2247e-05 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9969\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.3309e-05 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9971\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.7056e-05 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9969\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.0910e-05 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9971\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.7618e-05 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9969\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 5.2072e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9969\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 5.1075e-05 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9969\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 4.4447e-05 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9969\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 4.1714e-05 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9971\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.8620e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9969\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.6318e-05 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9969\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.2038e-05 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9971\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 3.1332e-05 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9969\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.8365e-05 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9969\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.6896e-05 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9969\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.3983e-05 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9969\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.3064e-05 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9973\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.1873e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9969\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 2.0034e-05 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9969\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.8137e-05 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9971\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.7037e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9969\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.5792e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9973\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.4844e-05 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9971\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.3449e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9971\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.2686e-05 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9969\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.1863e-05 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9971\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.0968e-05 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9971\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 1.0400e-05 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9971\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 9.6986e-06 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9967\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 9.1666e-06 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9973\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 8.3885e-06 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9973\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 7.9801e-06 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9973\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 7.3765e-06 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9973\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.8878e-06 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9971\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 6.3791e-06 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9973\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 10s 86ms/step - loss: 5.9661e-06 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9973\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 5.5495e-06 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9971\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 10s 85ms/step - loss: 5.1994e-06 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9971\n",
      "250/250 [==============================] - 5s 17ms/step - loss: 0.0160 - accuracy: 0.9967\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......masking\n",
      ".........vars\n",
      "......rnn\n",
      ".........cell\n",
      "............controller\n",
      "...............cells\n",
      "..................lstm_cell\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "........................2\n",
      "...............vars\n",
      "............output_layer\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............parameters_layer\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............read_layers\n",
      "...............dense\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_1\n",
      "..................vars\n",
      ".....................0\n",
      "............vars\n",
      "...............0\n",
      "............w_layers\n",
      "...............dense\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_1\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_2\n",
      "..................vars\n",
      ".....................0\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-26 21:04:34        80720\n",
      "config.json                                    2023-03-26 21:04:33         2123\n",
      "metadata.json                                  2023-03-26 21:04:33           64\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_12 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_12 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 13ms/step - loss: 0.6758 - accuracy: 0.6193 - val_loss: 0.6604 - val_accuracy: 0.6577\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6260 - accuracy: 0.7103 - val_loss: 0.5684 - val_accuracy: 0.7638\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4641 - accuracy: 0.8242 - val_loss: 0.3764 - val_accuracy: 0.8669\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3251 - accuracy: 0.8856 - val_loss: 0.2776 - val_accuracy: 0.9083\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.2389 - accuracy: 0.9197 - val_loss: 0.2007 - val_accuracy: 0.9333\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.1665 - accuracy: 0.9478 - val_loss: 0.1366 - val_accuracy: 0.9571\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.1067 - accuracy: 0.9732 - val_loss: 0.0899 - val_accuracy: 0.9787\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0745 - accuracy: 0.9833 - val_loss: 0.0800 - val_accuracy: 0.9794\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0633 - accuracy: 0.9847 - val_loss: 0.0609 - val_accuracy: 0.9871\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0522 - accuracy: 0.9887 - val_loss: 0.0568 - val_accuracy: 0.9890\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0476 - accuracy: 0.9896 - val_loss: 0.0511 - val_accuracy: 0.9898\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0425 - accuracy: 0.9904 - val_loss: 0.0507 - val_accuracy: 0.9887\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0375 - accuracy: 0.9922 - val_loss: 0.0544 - val_accuracy: 0.9877\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0353 - accuracy: 0.9922 - val_loss: 0.0472 - val_accuracy: 0.9900\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0322 - accuracy: 0.9933 - val_loss: 0.0428 - val_accuracy: 0.9908\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0319 - accuracy: 0.9933 - val_loss: 0.0428 - val_accuracy: 0.9919\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0281 - accuracy: 0.9946 - val_loss: 0.0416 - val_accuracy: 0.9915\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0255 - accuracy: 0.9954 - val_loss: 0.0451 - val_accuracy: 0.9900\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0234 - accuracy: 0.9958 - val_loss: 0.0365 - val_accuracy: 0.9925\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0230 - accuracy: 0.9960 - val_loss: 0.0372 - val_accuracy: 0.9929\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0215 - accuracy: 0.9964 - val_loss: 0.0364 - val_accuracy: 0.9925\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0209 - accuracy: 0.9965 - val_loss: 0.0361 - val_accuracy: 0.9927\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0211 - accuracy: 0.9961 - val_loss: 0.0371 - val_accuracy: 0.9919\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0187 - accuracy: 0.9965 - val_loss: 0.0372 - val_accuracy: 0.9923\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0181 - accuracy: 0.9968 - val_loss: 0.0300 - val_accuracy: 0.9935\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9964 - val_loss: 0.0343 - val_accuracy: 0.9921\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0180 - accuracy: 0.9964 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0582 - val_accuracy: 0.9854\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 0.0263 - val_accuracy: 0.9935\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.0270 - val_accuracy: 0.9929\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 0.0191 - val_accuracy: 0.9950\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.0195 - val_accuracy: 0.9948\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.0350 - val_accuracy: 0.9900\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.0162 - val_accuracy: 0.9965\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0173 - val_accuracy: 0.9958\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0149 - val_accuracy: 0.9965\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0152 - val_accuracy: 0.9958\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.0156 - val_accuracy: 0.9958\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0132 - val_accuracy: 0.9971\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0123 - val_accuracy: 0.9967\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0231 - val_accuracy: 0.9948\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0201 - val_accuracy: 0.9952\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0086 - val_accuracy: 0.9979\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0458 - val_accuracy: 0.9892\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0161 - val_accuracy: 0.9960\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0083 - val_accuracy: 0.9977\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0120 - val_accuracy: 0.9969\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0102 - val_accuracy: 0.9973\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0082 - val_accuracy: 0.9975\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0094 - val_accuracy: 0.9975\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0086 - val_accuracy: 0.9975\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0112 - val_accuracy: 0.9973\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0130 - val_accuracy: 0.9971\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0108 - val_accuracy: 0.9973\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0143 - val_accuracy: 0.9967\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0137 - val_accuracy: 0.9969\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0266 - val_accuracy: 0.9942\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0125 - val_accuracy: 0.9971\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.3752e-04 - accuracy: 0.9999 - val_loss: 0.0179 - val_accuracy: 0.9962\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.4545e-04 - accuracy: 0.9999 - val_loss: 0.0122 - val_accuracy: 0.9969\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.1617e-04 - accuracy: 0.9999 - val_loss: 0.0208 - val_accuracy: 0.9956\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.0310e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9969\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.0775e-04 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9971\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.7071e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9969\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.4587e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9969\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.2035e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9971\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.0470e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9971\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.8517e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9971\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.7287e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9971\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.6444e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.5332e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9971\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.3946e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9971\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.3144e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9971\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.2309e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9971\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.1364e-04 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9971\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.0692e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9971\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.9132e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9971\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.3935e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9971\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.8565e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9971\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.2484e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9971\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.8344e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9971\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.2369e-05 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9971\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.8996e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9973\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.5713e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9971\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.1542e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9973\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.7600e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.3963e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.0719e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9971\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.8022e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9971\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.5547e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9971\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.2729e-05 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9971\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.0437e-05 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9971\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.8021e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9973\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.5482e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9971\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_13 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_13 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 13ms/step - loss: 0.6799 - accuracy: 0.5756 - val_loss: 0.6619 - val_accuracy: 0.6352\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6169 - accuracy: 0.7019 - val_loss: 0.5409 - val_accuracy: 0.7642\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4348 - accuracy: 0.8260 - val_loss: 0.3311 - val_accuracy: 0.8848\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.2736 - accuracy: 0.9076 - val_loss: 0.2128 - val_accuracy: 0.9431\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.1752 - accuracy: 0.9486 - val_loss: 0.1335 - val_accuracy: 0.9635\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.1106 - accuracy: 0.9724 - val_loss: 0.0867 - val_accuracy: 0.9804\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0778 - accuracy: 0.9824 - val_loss: 0.0685 - val_accuracy: 0.9869\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0635 - accuracy: 0.9867 - val_loss: 0.0627 - val_accuracy: 0.9860\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0502 - accuracy: 0.9893 - val_loss: 0.0529 - val_accuracy: 0.9896\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0495 - accuracy: 0.9886 - val_loss: 0.0573 - val_accuracy: 0.9867\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0433 - accuracy: 0.9906 - val_loss: 0.0466 - val_accuracy: 0.9902\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0436 - accuracy: 0.9908 - val_loss: 0.0434 - val_accuracy: 0.9908\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0337 - accuracy: 0.9922 - val_loss: 0.0439 - val_accuracy: 0.9910\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0319 - accuracy: 0.9935 - val_loss: 0.0430 - val_accuracy: 0.9908\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0307 - accuracy: 0.9929 - val_loss: 0.0382 - val_accuracy: 0.9915\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0275 - accuracy: 0.9932 - val_loss: 0.0336 - val_accuracy: 0.9927\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0203 - accuracy: 0.9956 - val_loss: 0.0300 - val_accuracy: 0.9931\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0191 - accuracy: 0.9965 - val_loss: 0.0304 - val_accuracy: 0.9933\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.0286 - val_accuracy: 0.9942\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.0296 - val_accuracy: 0.9935\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0119 - accuracy: 0.9981 - val_loss: 0.0306 - val_accuracy: 0.9931\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 0.0293 - val_accuracy: 0.9937\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.0206 - val_accuracy: 0.9960\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0199 - val_accuracy: 0.9965\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0271 - val_accuracy: 0.9935\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.0229 - val_accuracy: 0.9954\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0268 - val_accuracy: 0.9946\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0167 - val_accuracy: 0.9967\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0202 - val_accuracy: 0.9956\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.0166 - val_accuracy: 0.9967\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0210 - val_accuracy: 0.9958\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0207 - val_accuracy: 0.9960\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0207 - val_accuracy: 0.9956\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0169 - val_accuracy: 0.9969\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0154 - val_accuracy: 0.9971\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0177 - val_accuracy: 0.9967\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0159 - val_accuracy: 0.9971\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0168 - val_accuracy: 0.9967\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0146 - val_accuracy: 0.9973\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0134 - val_accuracy: 0.9973\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0137 - val_accuracy: 0.9965\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0192 - val_accuracy: 0.9960\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0173 - val_accuracy: 0.9969\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0152 - val_accuracy: 0.9973\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0146 - val_accuracy: 0.9971\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0144 - val_accuracy: 0.9971\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.0759e-04 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9971\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.5965e-04 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9971\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.4701e-04 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9967\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.9825e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9971\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.5111e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9969\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.1597e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9971\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.8557e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9969\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.5582e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9969\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.3056e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9971\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.0817e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9969\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.8553e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9969\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.6905e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9969\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.5072e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9969\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.3386e-04 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9969\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.1881e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9973\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.0519e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9969\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.9232e-04 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9971\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.8016e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.7004e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9971\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.5860e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9971\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4971e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9971\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4080e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9971\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.3320e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9971\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.2423e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9971\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.1654e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9971\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.0891e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9969\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.0385e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9971\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.7606e-05 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9969\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.1533e-05 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9969\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.6589e-05 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9969\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.1005e-05 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9973\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.6301e-05 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9973\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.1911e-05 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9973\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.7652e-05 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9971\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.4832e-05 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9969\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.0435e-05 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9971\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.6494e-05 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9971\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.3470e-05 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9971\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.0251e-05 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9971\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.7415e-05 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9971\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.4695e-05 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9973\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.1965e-05 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9971\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.9889e-05 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9971\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.7591e-05 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9973\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.5492e-05 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9971\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.3591e-05 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9971\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.9983\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_14 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_14 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 0.6920 - accuracy: 0.5362 - val_loss: 0.6821 - val_accuracy: 0.5765\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6673 - accuracy: 0.6256 - val_loss: 0.6472 - val_accuracy: 0.6602\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.5745 - accuracy: 0.7513 - val_loss: 0.4667 - val_accuracy: 0.8258\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3853 - accuracy: 0.8590 - val_loss: 0.3104 - val_accuracy: 0.9046\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.2692 - accuracy: 0.9103 - val_loss: 0.2181 - val_accuracy: 0.9323\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.1864 - accuracy: 0.9444 - val_loss: 0.1517 - val_accuracy: 0.9527\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.1215 - accuracy: 0.9693 - val_loss: 0.1024 - val_accuracy: 0.9752\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0885 - accuracy: 0.9797 - val_loss: 0.0830 - val_accuracy: 0.9810\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0712 - accuracy: 0.9835 - val_loss: 0.0716 - val_accuracy: 0.9823\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0588 - accuracy: 0.9860 - val_loss: 0.0639 - val_accuracy: 0.9850\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0487 - accuracy: 0.9887 - val_loss: 0.0566 - val_accuracy: 0.9862\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0438 - accuracy: 0.9906 - val_loss: 0.0523 - val_accuracy: 0.9877\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0389 - accuracy: 0.9904 - val_loss: 0.0502 - val_accuracy: 0.9879\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0441 - accuracy: 0.9893 - val_loss: 0.0439 - val_accuracy: 0.9890\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0340 - accuracy: 0.9918 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0262 - accuracy: 0.9940 - val_loss: 0.0367 - val_accuracy: 0.9910\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0243 - accuracy: 0.9944 - val_loss: 0.0604 - val_accuracy: 0.9842\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0240 - accuracy: 0.9943 - val_loss: 0.0349 - val_accuracy: 0.9917\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0190 - accuracy: 0.9960 - val_loss: 0.0350 - val_accuracy: 0.9912\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0187 - accuracy: 0.9958 - val_loss: 0.0307 - val_accuracy: 0.9921\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.0309 - val_accuracy: 0.9929\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0269 - val_accuracy: 0.9927\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0359 - val_accuracy: 0.9912\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0365 - val_accuracy: 0.9915\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 0.0541 - val_accuracy: 0.9875\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0510 - val_accuracy: 0.9896\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.0235 - val_accuracy: 0.9940\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0330 - val_accuracy: 0.9929\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0226 - val_accuracy: 0.9944\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.0468 - val_accuracy: 0.9883\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0194 - val_accuracy: 0.9956\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0167 - val_accuracy: 0.9965\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0168 - val_accuracy: 0.9965\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.0171 - val_accuracy: 0.9960\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0161 - val_accuracy: 0.9954\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0160 - val_accuracy: 0.9967\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.0207 - val_accuracy: 0.9944\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.0191 - val_accuracy: 0.9950\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0200 - val_accuracy: 0.9946\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0178 - val_accuracy: 0.9956\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0307 - val_accuracy: 0.9929\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0185 - val_accuracy: 0.9960\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0125 - val_accuracy: 0.9971\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0142 - val_accuracy: 0.9960\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0116 - val_accuracy: 0.9969\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0114 - val_accuracy: 0.9973\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0099 - val_accuracy: 0.9979\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0137 - val_accuracy: 0.9967\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0118 - val_accuracy: 0.9971\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.8944e-04 - accuracy: 0.9999 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.2462e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0111 - val_accuracy: 0.9971\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0599 - val_accuracy: 0.9873\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0127 - val_accuracy: 0.9979\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.7537e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9973\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.0068e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9975\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.8119e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9969\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.5050e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9973\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.9821e-04 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9971\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.5999e-04 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9973\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.2977e-04 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.0992e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9971\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.8679e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9979\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.5949e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9969\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.4981e-04 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9973\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.3219e-04 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9973\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.1365e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9969\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.0529e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9977\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.8870e-04 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.7592e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.6542e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9977\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.5448e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4668e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9973\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.3586e-04 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9979\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.2823e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9979\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.1949e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9979\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.1162e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9975\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.0749e-04 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9973\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.9476e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9979\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.4480e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9979\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.7789e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9977\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.2226e-05 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9973\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.9663e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9979\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.3846e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9979\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.9024e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9975\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.5083e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9979\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.1278e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9979\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.7717e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9979\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.4009e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9979\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.1969e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9979\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.8463e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9979\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.5772e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9981\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.2773e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9979\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.0904e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9979\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.8278e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9979\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.5525e-05 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9975\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.4023e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9981\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.1836e-05 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9977\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.9729e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9981\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.8379e-05 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9981\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9974\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_15 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_15 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 4s 13ms/step - loss: 0.6853 - accuracy: 0.5622 - val_loss: 0.6735 - val_accuracy: 0.6017\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6491 - accuracy: 0.6667 - val_loss: 0.6191 - val_accuracy: 0.7023\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.5345 - accuracy: 0.7765 - val_loss: 0.4296 - val_accuracy: 0.8415\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3514 - accuracy: 0.8764 - val_loss: 0.2806 - val_accuracy: 0.9062\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.2437 - accuracy: 0.9186 - val_loss: 0.1969 - val_accuracy: 0.9362\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.1679 - accuracy: 0.9511 - val_loss: 0.1342 - val_accuracy: 0.9681\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.1108 - accuracy: 0.9740 - val_loss: 0.0960 - val_accuracy: 0.9808\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0868 - accuracy: 0.9804 - val_loss: 0.0974 - val_accuracy: 0.9712\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0714 - accuracy: 0.9837 - val_loss: 0.0698 - val_accuracy: 0.9810\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0576 - accuracy: 0.9878 - val_loss: 0.0505 - val_accuracy: 0.9910\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0507 - accuracy: 0.9899 - val_loss: 0.0463 - val_accuracy: 0.9912\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0418 - accuracy: 0.9932 - val_loss: 0.0417 - val_accuracy: 0.9923\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0391 - accuracy: 0.9921 - val_loss: 0.0416 - val_accuracy: 0.9921\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0362 - accuracy: 0.9933 - val_loss: 0.0375 - val_accuracy: 0.9944\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0327 - accuracy: 0.9946 - val_loss: 0.0331 - val_accuracy: 0.9946\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0299 - accuracy: 0.9950 - val_loss: 0.0336 - val_accuracy: 0.9940\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0289 - accuracy: 0.9950 - val_loss: 0.0306 - val_accuracy: 0.9944\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0255 - accuracy: 0.9960 - val_loss: 0.0283 - val_accuracy: 0.9956\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0251 - accuracy: 0.9960 - val_loss: 0.0286 - val_accuracy: 0.9948\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0228 - accuracy: 0.9968 - val_loss: 0.0260 - val_accuracy: 0.9962\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0224 - accuracy: 0.9967 - val_loss: 0.0251 - val_accuracy: 0.9962\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0297 - val_accuracy: 0.9946\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0276 - accuracy: 0.9949 - val_loss: 0.0283 - val_accuracy: 0.9948\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0218 - accuracy: 0.9965 - val_loss: 0.0241 - val_accuracy: 0.9958\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0209 - accuracy: 0.9967 - val_loss: 0.0248 - val_accuracy: 0.9958\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 0.0246 - val_accuracy: 0.9954\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.0235 - val_accuracy: 0.9962\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0191 - accuracy: 0.9971 - val_loss: 0.0228 - val_accuracy: 0.9962\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0187 - accuracy: 0.9971 - val_loss: 0.0227 - val_accuracy: 0.9962\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9971 - val_loss: 0.0229 - val_accuracy: 0.9958\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0180 - accuracy: 0.9971 - val_loss: 0.0259 - val_accuracy: 0.9946\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0188 - accuracy: 0.9962 - val_loss: 0.0239 - val_accuracy: 0.9954\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0176 - accuracy: 0.9971 - val_loss: 0.0205 - val_accuracy: 0.9962\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0170 - accuracy: 0.9972 - val_loss: 0.0205 - val_accuracy: 0.9962\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0165 - accuracy: 0.9967 - val_loss: 0.0193 - val_accuracy: 0.9960\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0325 - accuracy: 0.9932 - val_loss: 0.0230 - val_accuracy: 0.9958\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0174 - accuracy: 0.9967 - val_loss: 0.0215 - val_accuracy: 0.9960\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0185 - val_accuracy: 0.9967\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.0206 - val_accuracy: 0.9952\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.0217 - val_accuracy: 0.9956\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.0189 - val_accuracy: 0.9962\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 0.0309 - val_accuracy: 0.9921\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.0283 - val_accuracy: 0.9944\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.0151 - val_accuracy: 0.9973\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0112 - accuracy: 0.9978 - val_loss: 0.0186 - val_accuracy: 0.9967\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.0304 - val_accuracy: 0.9937\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0173 - val_accuracy: 0.9969\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0156 - val_accuracy: 0.9969\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0213 - val_accuracy: 0.9956\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 0.0149 - val_accuracy: 0.9969\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.0301 - val_accuracy: 0.9942\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0159 - val_accuracy: 0.9971\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0173 - val_accuracy: 0.9967\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0312 - val_accuracy: 0.9935\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.0171 - val_accuracy: 0.9965\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0303 - val_accuracy: 0.9942\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0114 - val_accuracy: 0.9973\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0300 - val_accuracy: 0.9946\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.0221 - val_accuracy: 0.9952\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0148 - val_accuracy: 0.9971\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0154 - val_accuracy: 0.9965\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0171 - val_accuracy: 0.9962\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 0.0135 - val_accuracy: 0.9973\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0107 - val_accuracy: 0.9979\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0127 - val_accuracy: 0.9971\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0157 - val_accuracy: 0.9973\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0127 - val_accuracy: 0.9975\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0147 - val_accuracy: 0.9971\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0225 - val_accuracy: 0.9958\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.0153 - val_accuracy: 0.9973\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0152 - val_accuracy: 0.9975\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0101 - val_accuracy: 0.9975\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0166 - val_accuracy: 0.9971\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0112 - val_accuracy: 0.9979\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0094 - val_accuracy: 0.9979\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0097 - val_accuracy: 0.9977\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0110 - val_accuracy: 0.9977\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9977\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0106 - val_accuracy: 0.9977\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0384 - val_accuracy: 0.9929\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.0117 - val_accuracy: 0.9977\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0107 - val_accuracy: 0.9965\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0111 - val_accuracy: 0.9981\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0120 - val_accuracy: 0.9979\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0156 - val_accuracy: 0.9967\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0099 - val_accuracy: 0.9981\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0161 - val_accuracy: 0.9971\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0114 - val_accuracy: 0.9975\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.0161e-04 - accuracy: 0.9999 - val_loss: 0.0131 - val_accuracy: 0.9977\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.3016e-04 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.7689e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.4031e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.8672e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9985\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.5930e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9981\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.3216e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9981\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.1854e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9981\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.0454e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9979\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.9018e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.7327e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9981\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.6426e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9981\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.5427e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9981\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4413e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9981\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.3909e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9979\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.2745e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9981\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.2099e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9981\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.1552e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9981\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.0721e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9979\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.0204e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9981\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.5536e-05 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9981\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.9462e-05 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9983\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.6245e-05 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.0946e-05 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9981\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.4809e-05 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9979\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.1448e-05 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9981\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.9096e-05 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9979\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.3704e-05 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9981\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.0971e-05 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9981\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.7137e-05 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9981\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.3011e-05 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9981\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.2046e-05 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9981\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.8228e-05 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9981\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.5523e-05 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9979\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.2776e-05 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9981\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.0577e-05 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9981\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.8161e-05 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9981\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.5893e-05 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.3932e-05 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.2910e-05 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9981\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.0479e-05 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9979\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.8894e-05 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9979\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.7183e-05 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9979\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.5643e-05 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9979\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.4301e-05 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9977\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.2928e-05 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9979\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.1292e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9979\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.1457e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9979\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.9599e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9977\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.8297e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9977\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.7347e-05 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9979\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.9973\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_16 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_16 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 13ms/step - loss: 0.6831 - accuracy: 0.5728 - val_loss: 0.6660 - val_accuracy: 0.6263\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.6269 - accuracy: 0.7028 - val_loss: 0.5751 - val_accuracy: 0.7423\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4789 - accuracy: 0.8121 - val_loss: 0.3914 - val_accuracy: 0.8610\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3224 - accuracy: 0.8865 - val_loss: 0.2635 - val_accuracy: 0.9127\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.2240 - accuracy: 0.9258 - val_loss: 0.1859 - val_accuracy: 0.9408\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.1428 - accuracy: 0.9601 - val_loss: 0.1067 - val_accuracy: 0.9765\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0817 - accuracy: 0.9836 - val_loss: 0.0791 - val_accuracy: 0.9812\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0597 - accuracy: 0.9889 - val_loss: 0.0608 - val_accuracy: 0.9883\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0465 - accuracy: 0.9914 - val_loss: 0.0514 - val_accuracy: 0.9896\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0369 - accuracy: 0.9937 - val_loss: 0.0491 - val_accuracy: 0.9898\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0327 - accuracy: 0.9944 - val_loss: 0.0389 - val_accuracy: 0.9925\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0289 - accuracy: 0.9946 - val_loss: 0.0361 - val_accuracy: 0.9931\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0247 - accuracy: 0.9962 - val_loss: 0.0330 - val_accuracy: 0.9937\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0267 - accuracy: 0.9947 - val_loss: 0.0815 - val_accuracy: 0.9787\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0250 - accuracy: 0.9956 - val_loss: 0.0292 - val_accuracy: 0.9946\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0173 - accuracy: 0.9974 - val_loss: 0.0271 - val_accuracy: 0.9958\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0181 - accuracy: 0.9967 - val_loss: 0.0280 - val_accuracy: 0.9950\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0225 - accuracy: 0.9953 - val_loss: 0.0256 - val_accuracy: 0.9956\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.0311 - val_accuracy: 0.9925\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.0242 - val_accuracy: 0.9958\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.0267 - val_accuracy: 0.9958\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0234 - val_accuracy: 0.9962\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0248 - val_accuracy: 0.9958\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.0399 - val_accuracy: 0.9912\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.0227 - val_accuracy: 0.9960\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0202 - val_accuracy: 0.9960\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0238 - val_accuracy: 0.9958\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0182 - val_accuracy: 0.9969\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0315 - val_accuracy: 0.9937\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0541 - val_accuracy: 0.9873\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0208 - val_accuracy: 0.9962\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0177 - val_accuracy: 0.9962\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0198 - val_accuracy: 0.9960\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0141 - val_accuracy: 0.9969\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0140 - val_accuracy: 0.9971\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0148 - val_accuracy: 0.9971\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0169 - val_accuracy: 0.9969\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0171 - val_accuracy: 0.9965\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0160 - val_accuracy: 0.9969\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0163 - val_accuracy: 0.9967\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.6128e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9971\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.0456e-04 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9973\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.5268e-04 - accuracy: 0.9999 - val_loss: 0.0155 - val_accuracy: 0.9960\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.1867e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.9846e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9969\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.5339e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9969\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.2601e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9973\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.9415e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9969\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.6168e-04 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9969\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.3774e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9969\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.1792e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9969\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.9397e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9969\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.7430e-04 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9969\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.5687e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9969\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.4128e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9969\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.2405e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9969\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.1017e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9969\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.9622e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9969\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.8417e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9969\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.7209e-04 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9969\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.6406e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9971\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.5199e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9969\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4227e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9969\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.3487e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9971\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.2744e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9971\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.1917e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9969\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.1117e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9969\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.0537e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9971\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.9077e-05 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9971\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.2928e-05 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9971\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.7158e-05 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9969\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.1771e-05 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9969\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.8015e-05 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9971\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.2666e-05 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9971\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.8367e-05 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9971\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.4643e-05 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9973\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 6.0685e-05 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9973\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.7192e-05 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9973\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.3849e-05 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9973\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 5.0854e-05 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9973\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.7651e-05 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9973\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.4973e-05 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9973\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 4.2520e-05 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9973\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.9887e-05 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9973\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.7687e-05 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9973\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.5350e-05 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9973\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.3379e-05 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9973\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 3.1327e-05 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9973\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.9786e-05 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9973\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.7988e-05 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9973\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.6365e-05 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9973\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 2.4933e-05 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9973\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9983\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......masking\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-26 21:14:14        49232\n",
      "config.json                                    2023-03-26 21:14:14         2356\n",
      "metadata.json                                  2023-03-26 21:14:14           64\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_17 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_17 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions (EncodePos  (None, 22, 18)           0         \n",
      " itions)                                                         \n",
      "                                                                 \n",
      " transformer_encoder (Transf  (None, 22, 18)           1718      \n",
      " ormerEncoder)                                                   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 18)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 0.9334 - accuracy: 0.4931 - val_loss: 0.7260 - val_accuracy: 0.5040\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.7048 - accuracy: 0.5415 - val_loss: 0.6935 - val_accuracy: 0.5469\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6768 - accuracy: 0.5953 - val_loss: 0.6653 - val_accuracy: 0.5996\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6508 - accuracy: 0.6212 - val_loss: 0.6438 - val_accuracy: 0.6285\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6326 - accuracy: 0.6411 - val_loss: 0.6240 - val_accuracy: 0.6504\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6110 - accuracy: 0.6646 - val_loss: 0.6027 - val_accuracy: 0.6662\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5970 - accuracy: 0.6775 - val_loss: 0.5960 - val_accuracy: 0.6606\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5891 - accuracy: 0.6839 - val_loss: 0.5822 - val_accuracy: 0.6958\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5764 - accuracy: 0.6978 - val_loss: 0.5692 - val_accuracy: 0.7083\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5637 - accuracy: 0.7126 - val_loss: 0.5571 - val_accuracy: 0.7194\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5461 - accuracy: 0.7372 - val_loss: 0.5360 - val_accuracy: 0.7513\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5255 - accuracy: 0.7651 - val_loss: 0.5154 - val_accuracy: 0.7946\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5039 - accuracy: 0.7904 - val_loss: 0.4945 - val_accuracy: 0.7923\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4874 - accuracy: 0.7982 - val_loss: 0.4715 - val_accuracy: 0.8117\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4609 - accuracy: 0.8175 - val_loss: 0.4534 - val_accuracy: 0.8158\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4444 - accuracy: 0.8238 - val_loss: 0.4382 - val_accuracy: 0.8254\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4266 - accuracy: 0.8276 - val_loss: 0.4202 - val_accuracy: 0.8379\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4137 - accuracy: 0.8363 - val_loss: 0.4114 - val_accuracy: 0.8302\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3969 - accuracy: 0.8397 - val_loss: 0.3946 - val_accuracy: 0.8402\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3811 - accuracy: 0.8435 - val_loss: 0.3753 - val_accuracy: 0.8410\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3686 - accuracy: 0.8476 - val_loss: 0.3647 - val_accuracy: 0.8444\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3589 - accuracy: 0.8549 - val_loss: 0.3526 - val_accuracy: 0.8521\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3436 - accuracy: 0.8603 - val_loss: 0.3468 - val_accuracy: 0.8548\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3348 - accuracy: 0.8675 - val_loss: 0.3373 - val_accuracy: 0.8554\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3252 - accuracy: 0.8708 - val_loss: 0.3217 - val_accuracy: 0.8754\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3168 - accuracy: 0.8749 - val_loss: 0.3120 - val_accuracy: 0.8752\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3083 - accuracy: 0.8810 - val_loss: 0.3181 - val_accuracy: 0.8758\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3046 - accuracy: 0.8818 - val_loss: 0.3025 - val_accuracy: 0.8808\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2995 - accuracy: 0.8828 - val_loss: 0.2985 - val_accuracy: 0.8838\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2921 - accuracy: 0.8871 - val_loss: 0.2973 - val_accuracy: 0.8831\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2845 - accuracy: 0.8888 - val_loss: 0.2906 - val_accuracy: 0.8867\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2845 - accuracy: 0.8919 - val_loss: 0.2860 - val_accuracy: 0.8906\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2771 - accuracy: 0.8944 - val_loss: 0.2822 - val_accuracy: 0.8952\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2743 - accuracy: 0.8969 - val_loss: 0.2832 - val_accuracy: 0.8910\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2720 - accuracy: 0.8949 - val_loss: 0.2771 - val_accuracy: 0.8931\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2696 - accuracy: 0.8968 - val_loss: 0.2758 - val_accuracy: 0.8952\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2650 - accuracy: 0.8976 - val_loss: 0.2771 - val_accuracy: 0.8988\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2639 - accuracy: 0.8971 - val_loss: 0.2687 - val_accuracy: 0.8958\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2578 - accuracy: 0.9026 - val_loss: 0.2644 - val_accuracy: 0.8998\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2579 - accuracy: 0.9013 - val_loss: 0.2677 - val_accuracy: 0.8969\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2550 - accuracy: 0.9015 - val_loss: 0.2651 - val_accuracy: 0.8988\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2550 - accuracy: 0.9004 - val_loss: 0.2598 - val_accuracy: 0.9013\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2519 - accuracy: 0.9032 - val_loss: 0.2648 - val_accuracy: 0.9025\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2473 - accuracy: 0.9039 - val_loss: 0.2603 - val_accuracy: 0.9031\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2442 - accuracy: 0.9072 - val_loss: 0.2529 - val_accuracy: 0.9023\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2423 - accuracy: 0.9068 - val_loss: 0.2521 - val_accuracy: 0.9035\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2371 - accuracy: 0.9101 - val_loss: 0.2545 - val_accuracy: 0.9060\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2358 - accuracy: 0.9119 - val_loss: 0.2534 - val_accuracy: 0.9069\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2357 - accuracy: 0.9101 - val_loss: 0.2479 - val_accuracy: 0.9100\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2296 - accuracy: 0.9125 - val_loss: 0.2473 - val_accuracy: 0.9104\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2248 - accuracy: 0.9157 - val_loss: 0.2427 - val_accuracy: 0.9148\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2225 - accuracy: 0.9161 - val_loss: 0.2432 - val_accuracy: 0.9104\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2246 - accuracy: 0.9142 - val_loss: 0.2561 - val_accuracy: 0.9152\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2176 - accuracy: 0.9181 - val_loss: 0.2385 - val_accuracy: 0.9133\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2148 - accuracy: 0.9228 - val_loss: 0.2338 - val_accuracy: 0.9160\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2132 - accuracy: 0.9251 - val_loss: 0.2320 - val_accuracy: 0.9162\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2102 - accuracy: 0.9251 - val_loss: 0.2400 - val_accuracy: 0.9098\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2074 - accuracy: 0.9276 - val_loss: 0.2315 - val_accuracy: 0.9158\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2076 - accuracy: 0.9281 - val_loss: 0.2275 - val_accuracy: 0.9204\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2014 - accuracy: 0.9292 - val_loss: 0.2164 - val_accuracy: 0.9267\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2014 - accuracy: 0.9275 - val_loss: 0.2167 - val_accuracy: 0.9233\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1954 - accuracy: 0.9304 - val_loss: 0.2151 - val_accuracy: 0.9246\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1940 - accuracy: 0.9310 - val_loss: 0.2124 - val_accuracy: 0.9248\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1913 - accuracy: 0.9304 - val_loss: 0.2072 - val_accuracy: 0.9277\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1863 - accuracy: 0.9331 - val_loss: 0.2043 - val_accuracy: 0.9271\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1834 - accuracy: 0.9350 - val_loss: 0.2239 - val_accuracy: 0.9217\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1838 - accuracy: 0.9328 - val_loss: 0.2001 - val_accuracy: 0.9277\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1801 - accuracy: 0.9329 - val_loss: 0.1965 - val_accuracy: 0.9294\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1754 - accuracy: 0.9356 - val_loss: 0.2050 - val_accuracy: 0.9260\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1730 - accuracy: 0.9374 - val_loss: 0.1910 - val_accuracy: 0.9312\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1704 - accuracy: 0.9397 - val_loss: 0.1972 - val_accuracy: 0.9300\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1720 - accuracy: 0.9374 - val_loss: 0.1923 - val_accuracy: 0.9333\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1666 - accuracy: 0.9413 - val_loss: 0.1829 - val_accuracy: 0.9352\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1664 - accuracy: 0.9418 - val_loss: 0.1907 - val_accuracy: 0.9362\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1654 - accuracy: 0.9400 - val_loss: 0.1828 - val_accuracy: 0.9360\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1651 - accuracy: 0.9407 - val_loss: 0.1930 - val_accuracy: 0.9358\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1625 - accuracy: 0.9424 - val_loss: 0.1820 - val_accuracy: 0.9365\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1568 - accuracy: 0.9460 - val_loss: 0.1785 - val_accuracy: 0.9362\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1585 - accuracy: 0.9453 - val_loss: 0.1797 - val_accuracy: 0.9369\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1571 - accuracy: 0.9457 - val_loss: 0.1826 - val_accuracy: 0.9392\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1575 - accuracy: 0.9442 - val_loss: 0.1822 - val_accuracy: 0.9358\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1546 - accuracy: 0.9460 - val_loss: 0.1808 - val_accuracy: 0.9371\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1541 - accuracy: 0.9460 - val_loss: 0.1850 - val_accuracy: 0.9377\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1549 - accuracy: 0.9479 - val_loss: 0.1804 - val_accuracy: 0.9388\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1493 - accuracy: 0.9499 - val_loss: 0.1718 - val_accuracy: 0.9417\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1486 - accuracy: 0.9494 - val_loss: 0.1670 - val_accuracy: 0.9458\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1504 - accuracy: 0.9490 - val_loss: 0.1738 - val_accuracy: 0.9425\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1449 - accuracy: 0.9496 - val_loss: 0.1746 - val_accuracy: 0.9442\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1456 - accuracy: 0.9524 - val_loss: 0.1772 - val_accuracy: 0.9402\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1445 - accuracy: 0.9507 - val_loss: 0.1707 - val_accuracy: 0.9473\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1426 - accuracy: 0.9521 - val_loss: 0.1702 - val_accuracy: 0.9417\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1423 - accuracy: 0.9521 - val_loss: 0.1690 - val_accuracy: 0.9479\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1387 - accuracy: 0.9538 - val_loss: 0.1653 - val_accuracy: 0.9506\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1385 - accuracy: 0.9550 - val_loss: 0.1801 - val_accuracy: 0.9394\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1408 - accuracy: 0.9529 - val_loss: 0.1752 - val_accuracy: 0.9429\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1376 - accuracy: 0.9543 - val_loss: 0.1707 - val_accuracy: 0.9494\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1357 - accuracy: 0.9535 - val_loss: 0.1722 - val_accuracy: 0.9475\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1373 - accuracy: 0.9540 - val_loss: 0.1669 - val_accuracy: 0.9496\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1320 - accuracy: 0.9564 - val_loss: 0.1697 - val_accuracy: 0.9498\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1325 - accuracy: 0.9569 - val_loss: 0.1677 - val_accuracy: 0.9481\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1380 - accuracy: 0.9546 - val_loss: 0.1742 - val_accuracy: 0.9473\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1347 - accuracy: 0.9564 - val_loss: 0.1657 - val_accuracy: 0.9506\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1338 - accuracy: 0.9571 - val_loss: 0.1646 - val_accuracy: 0.9460\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1346 - accuracy: 0.9553 - val_loss: 0.1653 - val_accuracy: 0.9460\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1322 - accuracy: 0.9567 - val_loss: 0.1741 - val_accuracy: 0.9485\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1292 - accuracy: 0.9571 - val_loss: 0.1662 - val_accuracy: 0.9469\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1276 - accuracy: 0.9586 - val_loss: 0.1630 - val_accuracy: 0.9485\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1304 - accuracy: 0.9575 - val_loss: 0.1666 - val_accuracy: 0.9485\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1276 - accuracy: 0.9601 - val_loss: 0.1626 - val_accuracy: 0.9496\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1307 - accuracy: 0.9569 - val_loss: 0.1641 - val_accuracy: 0.9492\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1279 - accuracy: 0.9586 - val_loss: 0.1752 - val_accuracy: 0.9444\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1296 - accuracy: 0.9567 - val_loss: 0.1653 - val_accuracy: 0.9506\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1299 - accuracy: 0.9572 - val_loss: 0.1689 - val_accuracy: 0.9467\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1278 - accuracy: 0.9614 - val_loss: 0.1635 - val_accuracy: 0.9513\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1240 - accuracy: 0.9588 - val_loss: 0.1668 - val_accuracy: 0.9479\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1266 - accuracy: 0.9614 - val_loss: 0.1684 - val_accuracy: 0.9463\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1261 - accuracy: 0.9589 - val_loss: 0.1628 - val_accuracy: 0.9494\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1243 - accuracy: 0.9588 - val_loss: 0.1633 - val_accuracy: 0.9494\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1258 - accuracy: 0.9600 - val_loss: 0.1621 - val_accuracy: 0.9540\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1215 - accuracy: 0.9599 - val_loss: 0.1599 - val_accuracy: 0.9471\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1220 - accuracy: 0.9597 - val_loss: 0.1628 - val_accuracy: 0.9508\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1236 - accuracy: 0.9607 - val_loss: 0.1579 - val_accuracy: 0.9494\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1225 - accuracy: 0.9611 - val_loss: 0.1595 - val_accuracy: 0.9496\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1218 - accuracy: 0.9604 - val_loss: 0.1602 - val_accuracy: 0.9485\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1218 - accuracy: 0.9613 - val_loss: 0.1599 - val_accuracy: 0.9515\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1189 - accuracy: 0.9615 - val_loss: 0.1692 - val_accuracy: 0.9510\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1218 - accuracy: 0.9618 - val_loss: 0.1707 - val_accuracy: 0.9496\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1213 - accuracy: 0.9621 - val_loss: 0.1668 - val_accuracy: 0.9475\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1210 - accuracy: 0.9599 - val_loss: 0.1642 - val_accuracy: 0.9533\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1168 - accuracy: 0.9622 - val_loss: 0.1578 - val_accuracy: 0.9527\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1162 - accuracy: 0.9615 - val_loss: 0.1580 - val_accuracy: 0.9533\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1188 - accuracy: 0.9615 - val_loss: 0.1574 - val_accuracy: 0.9519\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1205 - accuracy: 0.9622 - val_loss: 0.1669 - val_accuracy: 0.9510\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1191 - accuracy: 0.9614 - val_loss: 0.1675 - val_accuracy: 0.9496\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1203 - accuracy: 0.9610 - val_loss: 0.1572 - val_accuracy: 0.9515\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1155 - accuracy: 0.9636 - val_loss: 0.1627 - val_accuracy: 0.9492\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1205 - accuracy: 0.9622 - val_loss: 0.1781 - val_accuracy: 0.9481\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1186 - accuracy: 0.9614 - val_loss: 0.1726 - val_accuracy: 0.9463\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1192 - accuracy: 0.9624 - val_loss: 0.1622 - val_accuracy: 0.9510\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1188 - accuracy: 0.9625 - val_loss: 0.1721 - val_accuracy: 0.9506\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1171 - accuracy: 0.9614 - val_loss: 0.1598 - val_accuracy: 0.9538\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1141 - accuracy: 0.9621 - val_loss: 0.1624 - val_accuracy: 0.9498\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1167 - accuracy: 0.9622 - val_loss: 0.1588 - val_accuracy: 0.9546\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1156 - accuracy: 0.9611 - val_loss: 0.1610 - val_accuracy: 0.9529\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1198 - accuracy: 0.9619 - val_loss: 0.1611 - val_accuracy: 0.9535\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1179 - accuracy: 0.9628 - val_loss: 0.1577 - val_accuracy: 0.9546\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1116 - accuracy: 0.9654 - val_loss: 0.1642 - val_accuracy: 0.9496\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1165 - accuracy: 0.9638 - val_loss: 0.1585 - val_accuracy: 0.9504\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1262 - accuracy: 0.9578 - val_loss: 0.1669 - val_accuracy: 0.9485\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1156 - accuracy: 0.9626 - val_loss: 0.1617 - val_accuracy: 0.9517\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1124 - accuracy: 0.9632 - val_loss: 0.1588 - val_accuracy: 0.9533\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1109 - accuracy: 0.9660 - val_loss: 0.1648 - val_accuracy: 0.9517\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1135 - accuracy: 0.9632 - val_loss: 0.1623 - val_accuracy: 0.9519\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1137 - accuracy: 0.9647 - val_loss: 0.1691 - val_accuracy: 0.9508\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1199 - accuracy: 0.9608 - val_loss: 0.1617 - val_accuracy: 0.9504\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1116 - accuracy: 0.9646 - val_loss: 0.1667 - val_accuracy: 0.9523\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1143 - accuracy: 0.9643 - val_loss: 0.1670 - val_accuracy: 0.9496\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1104 - accuracy: 0.9649 - val_loss: 0.1655 - val_accuracy: 0.9506\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1091 - accuracy: 0.9653 - val_loss: 0.1704 - val_accuracy: 0.9477\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1077 - accuracy: 0.9660 - val_loss: 0.1636 - val_accuracy: 0.9488\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1101 - accuracy: 0.9646 - val_loss: 0.1646 - val_accuracy: 0.9531\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1110 - accuracy: 0.9647 - val_loss: 0.1596 - val_accuracy: 0.9525\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1084 - accuracy: 0.9657 - val_loss: 0.1589 - val_accuracy: 0.9523\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1132 - accuracy: 0.9640 - val_loss: 0.1700 - val_accuracy: 0.9519\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1066 - accuracy: 0.9682 - val_loss: 0.1582 - val_accuracy: 0.9529\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1087 - accuracy: 0.9628 - val_loss: 0.1668 - val_accuracy: 0.9508\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1087 - accuracy: 0.9668 - val_loss: 0.1653 - val_accuracy: 0.9515\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1060 - accuracy: 0.9674 - val_loss: 0.1699 - val_accuracy: 0.9481\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1096 - accuracy: 0.9653 - val_loss: 0.1576 - val_accuracy: 0.9538\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1067 - accuracy: 0.9667 - val_loss: 0.1630 - val_accuracy: 0.9525\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1086 - accuracy: 0.9669 - val_loss: 0.1611 - val_accuracy: 0.9510\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1131 - accuracy: 0.9640 - val_loss: 0.1691 - val_accuracy: 0.9517\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1084 - accuracy: 0.9672 - val_loss: 0.1629 - val_accuracy: 0.9527\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1064 - accuracy: 0.9664 - val_loss: 0.1648 - val_accuracy: 0.9525\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1066 - accuracy: 0.9679 - val_loss: 0.1650 - val_accuracy: 0.9490\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1103 - accuracy: 0.9651 - val_loss: 0.1657 - val_accuracy: 0.9492\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1062 - accuracy: 0.9653 - val_loss: 0.1565 - val_accuracy: 0.9556\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1040 - accuracy: 0.9679 - val_loss: 0.1606 - val_accuracy: 0.9521\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1050 - accuracy: 0.9664 - val_loss: 0.1643 - val_accuracy: 0.9515\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1059 - accuracy: 0.9651 - val_loss: 0.1627 - val_accuracy: 0.9502\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1052 - accuracy: 0.9661 - val_loss: 0.1692 - val_accuracy: 0.9500\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1041 - accuracy: 0.9667 - val_loss: 0.1603 - val_accuracy: 0.9529\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1064 - accuracy: 0.9663 - val_loss: 0.1630 - val_accuracy: 0.9485\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1073 - accuracy: 0.9660 - val_loss: 0.1698 - val_accuracy: 0.9510\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1034 - accuracy: 0.9665 - val_loss: 0.1618 - val_accuracy: 0.9525\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1039 - accuracy: 0.9681 - val_loss: 0.1735 - val_accuracy: 0.9485\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1040 - accuracy: 0.9669 - val_loss: 0.1727 - val_accuracy: 0.9506\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1050 - accuracy: 0.9650 - val_loss: 0.1611 - val_accuracy: 0.9515\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1006 - accuracy: 0.9686 - val_loss: 0.1594 - val_accuracy: 0.9515\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1022 - accuracy: 0.9690 - val_loss: 0.1582 - val_accuracy: 0.9519\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1031 - accuracy: 0.9665 - val_loss: 0.1639 - val_accuracy: 0.9550\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1029 - accuracy: 0.9661 - val_loss: 0.1624 - val_accuracy: 0.9510\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1081 - accuracy: 0.9675 - val_loss: 0.1637 - val_accuracy: 0.9527\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1044 - accuracy: 0.9676 - val_loss: 0.1591 - val_accuracy: 0.9552\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1022 - accuracy: 0.9697 - val_loss: 0.1761 - val_accuracy: 0.9521\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1067 - accuracy: 0.9639 - val_loss: 0.1686 - val_accuracy: 0.9506\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1073 - accuracy: 0.9643 - val_loss: 0.1808 - val_accuracy: 0.9467\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1054 - accuracy: 0.9675 - val_loss: 0.1580 - val_accuracy: 0.9554\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1002 - accuracy: 0.9704 - val_loss: 0.1578 - val_accuracy: 0.9548\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1020 - accuracy: 0.9686 - val_loss: 0.1625 - val_accuracy: 0.9515\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9496\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_18 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_18 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions_1 (EncodeP  (None, 22, 18)           0         \n",
      " ositions)                                                       \n",
      "                                                                 \n",
      " transformer_encoder_1 (Tran  (None, 22, 18)           1718      \n",
      " sformerEncoder)                                                 \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 18)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 0.8610 - accuracy: 0.5283 - val_loss: 0.7148 - val_accuracy: 0.5446\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6808 - accuracy: 0.5926 - val_loss: 0.6558 - val_accuracy: 0.6317\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6148 - accuracy: 0.6717 - val_loss: 0.5946 - val_accuracy: 0.6735\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5713 - accuracy: 0.6901 - val_loss: 0.5627 - val_accuracy: 0.6902\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5504 - accuracy: 0.6993 - val_loss: 0.5490 - val_accuracy: 0.6958\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5407 - accuracy: 0.7039 - val_loss: 0.5447 - val_accuracy: 0.6950\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5334 - accuracy: 0.7046 - val_loss: 0.5428 - val_accuracy: 0.7017\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5281 - accuracy: 0.7153 - val_loss: 0.5351 - val_accuracy: 0.7083\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5213 - accuracy: 0.7208 - val_loss: 0.5317 - val_accuracy: 0.7125\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5164 - accuracy: 0.7212 - val_loss: 0.5211 - val_accuracy: 0.7235\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5118 - accuracy: 0.7299 - val_loss: 0.5183 - val_accuracy: 0.7215\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5068 - accuracy: 0.7385 - val_loss: 0.5138 - val_accuracy: 0.7294\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5024 - accuracy: 0.7393 - val_loss: 0.5097 - val_accuracy: 0.7317\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4971 - accuracy: 0.7450 - val_loss: 0.5098 - val_accuracy: 0.7335\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4917 - accuracy: 0.7494 - val_loss: 0.5045 - val_accuracy: 0.7417\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4861 - accuracy: 0.7547 - val_loss: 0.4968 - val_accuracy: 0.7485\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4772 - accuracy: 0.7656 - val_loss: 0.4885 - val_accuracy: 0.7650\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4697 - accuracy: 0.7710 - val_loss: 0.4800 - val_accuracy: 0.7650\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4615 - accuracy: 0.7793 - val_loss: 0.4763 - val_accuracy: 0.7690\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4581 - accuracy: 0.7803 - val_loss: 0.4735 - val_accuracy: 0.7694\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4496 - accuracy: 0.7872 - val_loss: 0.4656 - val_accuracy: 0.7831\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4421 - accuracy: 0.7943 - val_loss: 0.4656 - val_accuracy: 0.7783\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4380 - accuracy: 0.7962 - val_loss: 0.4558 - val_accuracy: 0.7783\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4334 - accuracy: 0.7975 - val_loss: 0.4539 - val_accuracy: 0.7835\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4285 - accuracy: 0.8051 - val_loss: 0.4524 - val_accuracy: 0.7840\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4235 - accuracy: 0.8058 - val_loss: 0.4421 - val_accuracy: 0.7892\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4192 - accuracy: 0.8039 - val_loss: 0.4447 - val_accuracy: 0.7900\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4162 - accuracy: 0.8064 - val_loss: 0.4444 - val_accuracy: 0.7973\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4128 - accuracy: 0.8129 - val_loss: 0.4349 - val_accuracy: 0.7952\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4087 - accuracy: 0.8147 - val_loss: 0.4354 - val_accuracy: 0.8023\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4090 - accuracy: 0.8126 - val_loss: 0.4377 - val_accuracy: 0.7958\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4040 - accuracy: 0.8164 - val_loss: 0.4358 - val_accuracy: 0.7971\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3995 - accuracy: 0.8193 - val_loss: 0.4260 - val_accuracy: 0.8050\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3982 - accuracy: 0.8204 - val_loss: 0.4280 - val_accuracy: 0.8027\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3951 - accuracy: 0.8224 - val_loss: 0.4253 - val_accuracy: 0.8017\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3915 - accuracy: 0.8225 - val_loss: 0.4207 - val_accuracy: 0.8112\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3876 - accuracy: 0.8250 - val_loss: 0.4183 - val_accuracy: 0.8106\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3851 - accuracy: 0.8296 - val_loss: 0.4134 - val_accuracy: 0.8069\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3842 - accuracy: 0.8271 - val_loss: 0.4226 - val_accuracy: 0.8044\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3781 - accuracy: 0.8285 - val_loss: 0.4115 - val_accuracy: 0.8117\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3785 - accuracy: 0.8301 - val_loss: 0.4044 - val_accuracy: 0.8171\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3741 - accuracy: 0.8335 - val_loss: 0.4000 - val_accuracy: 0.8163\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3703 - accuracy: 0.8357 - val_loss: 0.4043 - val_accuracy: 0.8163\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3720 - accuracy: 0.8360 - val_loss: 0.4023 - val_accuracy: 0.8169\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3705 - accuracy: 0.8357 - val_loss: 0.3969 - val_accuracy: 0.8215\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3668 - accuracy: 0.8371 - val_loss: 0.4001 - val_accuracy: 0.8188\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3662 - accuracy: 0.8390 - val_loss: 0.3946 - val_accuracy: 0.8242\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3593 - accuracy: 0.8410 - val_loss: 0.3909 - val_accuracy: 0.8219\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3578 - accuracy: 0.8450 - val_loss: 0.3868 - val_accuracy: 0.8252\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3553 - accuracy: 0.8453 - val_loss: 0.3930 - val_accuracy: 0.8242\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3531 - accuracy: 0.8458 - val_loss: 0.3823 - val_accuracy: 0.8342\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3501 - accuracy: 0.8504 - val_loss: 0.3811 - val_accuracy: 0.8319\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3514 - accuracy: 0.8492 - val_loss: 0.3837 - val_accuracy: 0.8283\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3446 - accuracy: 0.8508 - val_loss: 0.3765 - val_accuracy: 0.8360\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3454 - accuracy: 0.8522 - val_loss: 0.3786 - val_accuracy: 0.8344\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3402 - accuracy: 0.8506 - val_loss: 0.3728 - val_accuracy: 0.8371\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3369 - accuracy: 0.8560 - val_loss: 0.3666 - val_accuracy: 0.8394\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3330 - accuracy: 0.8562 - val_loss: 0.3680 - val_accuracy: 0.8413\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3322 - accuracy: 0.8597 - val_loss: 0.3682 - val_accuracy: 0.8442\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3306 - accuracy: 0.8601 - val_loss: 0.3595 - val_accuracy: 0.8427\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3270 - accuracy: 0.8643 - val_loss: 0.3624 - val_accuracy: 0.8427\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3236 - accuracy: 0.8657 - val_loss: 0.3568 - val_accuracy: 0.8435\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3200 - accuracy: 0.8675 - val_loss: 0.3558 - val_accuracy: 0.8454\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3175 - accuracy: 0.8694 - val_loss: 0.3507 - val_accuracy: 0.8529\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3133 - accuracy: 0.8699 - val_loss: 0.3498 - val_accuracy: 0.8502\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3113 - accuracy: 0.8732 - val_loss: 0.3396 - val_accuracy: 0.8573\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3052 - accuracy: 0.8751 - val_loss: 0.3447 - val_accuracy: 0.8535\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3013 - accuracy: 0.8783 - val_loss: 0.3347 - val_accuracy: 0.8527\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2989 - accuracy: 0.8794 - val_loss: 0.3252 - val_accuracy: 0.8602\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2956 - accuracy: 0.8825 - val_loss: 0.3261 - val_accuracy: 0.8619\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2924 - accuracy: 0.8825 - val_loss: 0.3240 - val_accuracy: 0.8633\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2846 - accuracy: 0.8857 - val_loss: 0.3186 - val_accuracy: 0.8656\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2837 - accuracy: 0.8882 - val_loss: 0.3067 - val_accuracy: 0.8679\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2796 - accuracy: 0.8896 - val_loss: 0.3031 - val_accuracy: 0.8725\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2754 - accuracy: 0.8915 - val_loss: 0.3039 - val_accuracy: 0.8742\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2715 - accuracy: 0.8928 - val_loss: 0.2958 - val_accuracy: 0.8710\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2724 - accuracy: 0.8929 - val_loss: 0.3036 - val_accuracy: 0.8748\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2619 - accuracy: 0.8993 - val_loss: 0.2920 - val_accuracy: 0.8763\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2639 - accuracy: 0.8982 - val_loss: 0.2991 - val_accuracy: 0.8700\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2608 - accuracy: 0.8967 - val_loss: 0.2865 - val_accuracy: 0.8827\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2544 - accuracy: 0.9028 - val_loss: 0.2841 - val_accuracy: 0.8825\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2520 - accuracy: 0.9038 - val_loss: 0.2756 - val_accuracy: 0.8910\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2479 - accuracy: 0.9074 - val_loss: 0.2847 - val_accuracy: 0.8835\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2506 - accuracy: 0.9007 - val_loss: 0.2796 - val_accuracy: 0.8869\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2443 - accuracy: 0.9061 - val_loss: 0.2733 - val_accuracy: 0.8927\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2410 - accuracy: 0.9072 - val_loss: 0.2826 - val_accuracy: 0.8881\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2398 - accuracy: 0.9081 - val_loss: 0.2728 - val_accuracy: 0.8894\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2355 - accuracy: 0.9131 - val_loss: 0.2616 - val_accuracy: 0.8985\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2358 - accuracy: 0.9103 - val_loss: 0.2594 - val_accuracy: 0.8938\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2333 - accuracy: 0.9128 - val_loss: 0.2616 - val_accuracy: 0.8965\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2305 - accuracy: 0.9124 - val_loss: 0.2625 - val_accuracy: 0.8908\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2233 - accuracy: 0.9161 - val_loss: 0.2585 - val_accuracy: 0.9019\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2231 - accuracy: 0.9197 - val_loss: 0.2564 - val_accuracy: 0.8990\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2214 - accuracy: 0.9182 - val_loss: 0.2515 - val_accuracy: 0.8992\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2200 - accuracy: 0.9169 - val_loss: 0.2510 - val_accuracy: 0.8983\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2194 - accuracy: 0.9196 - val_loss: 0.2558 - val_accuracy: 0.8979\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2196 - accuracy: 0.9207 - val_loss: 0.2607 - val_accuracy: 0.8969\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2164 - accuracy: 0.9217 - val_loss: 0.2560 - val_accuracy: 0.8994\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2132 - accuracy: 0.9228 - val_loss: 0.2436 - val_accuracy: 0.9027\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2095 - accuracy: 0.9267 - val_loss: 0.2619 - val_accuracy: 0.9013\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2029 - accuracy: 0.9289 - val_loss: 0.2474 - val_accuracy: 0.9052\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2025 - accuracy: 0.9307 - val_loss: 0.2475 - val_accuracy: 0.9006\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2030 - accuracy: 0.9282 - val_loss: 0.2536 - val_accuracy: 0.8990\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2020 - accuracy: 0.9306 - val_loss: 0.2460 - val_accuracy: 0.9015\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1971 - accuracy: 0.9303 - val_loss: 0.2460 - val_accuracy: 0.9092\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1996 - accuracy: 0.9315 - val_loss: 0.2301 - val_accuracy: 0.9127\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1972 - accuracy: 0.9339 - val_loss: 0.2370 - val_accuracy: 0.9154\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1889 - accuracy: 0.9358 - val_loss: 0.2466 - val_accuracy: 0.9125\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1913 - accuracy: 0.9337 - val_loss: 0.2365 - val_accuracy: 0.9081\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1937 - accuracy: 0.9310 - val_loss: 0.2296 - val_accuracy: 0.9127\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1864 - accuracy: 0.9356 - val_loss: 0.2267 - val_accuracy: 0.9146\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1886 - accuracy: 0.9364 - val_loss: 0.2303 - val_accuracy: 0.9142\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1830 - accuracy: 0.9372 - val_loss: 0.2273 - val_accuracy: 0.9146\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1810 - accuracy: 0.9376 - val_loss: 0.2460 - val_accuracy: 0.9062\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1824 - accuracy: 0.9378 - val_loss: 0.2296 - val_accuracy: 0.9173\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1778 - accuracy: 0.9400 - val_loss: 0.2285 - val_accuracy: 0.9177\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1758 - accuracy: 0.9388 - val_loss: 0.2195 - val_accuracy: 0.9246\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1774 - accuracy: 0.9385 - val_loss: 0.2266 - val_accuracy: 0.9173\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1764 - accuracy: 0.9383 - val_loss: 0.2193 - val_accuracy: 0.9208\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1770 - accuracy: 0.9392 - val_loss: 0.2205 - val_accuracy: 0.9183\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1784 - accuracy: 0.9410 - val_loss: 0.2361 - val_accuracy: 0.9192\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1742 - accuracy: 0.9406 - val_loss: 0.2182 - val_accuracy: 0.9254\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1705 - accuracy: 0.9417 - val_loss: 0.2227 - val_accuracy: 0.9185\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1694 - accuracy: 0.9435 - val_loss: 0.2215 - val_accuracy: 0.9202\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1710 - accuracy: 0.9425 - val_loss: 0.2177 - val_accuracy: 0.9248\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1683 - accuracy: 0.9406 - val_loss: 0.2117 - val_accuracy: 0.9258\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1669 - accuracy: 0.9429 - val_loss: 0.2104 - val_accuracy: 0.9275\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1709 - accuracy: 0.9410 - val_loss: 0.2178 - val_accuracy: 0.9237\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1673 - accuracy: 0.9414 - val_loss: 0.2055 - val_accuracy: 0.9267\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1652 - accuracy: 0.9447 - val_loss: 0.2139 - val_accuracy: 0.9250\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1686 - accuracy: 0.9404 - val_loss: 0.2141 - val_accuracy: 0.9256\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1630 - accuracy: 0.9436 - val_loss: 0.2129 - val_accuracy: 0.9229\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1640 - accuracy: 0.9436 - val_loss: 0.2043 - val_accuracy: 0.9279\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1616 - accuracy: 0.9436 - val_loss: 0.2109 - val_accuracy: 0.9223\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1605 - accuracy: 0.9450 - val_loss: 0.2186 - val_accuracy: 0.9206\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1579 - accuracy: 0.9464 - val_loss: 0.2136 - val_accuracy: 0.9252\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1580 - accuracy: 0.9475 - val_loss: 0.2034 - val_accuracy: 0.9273\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1576 - accuracy: 0.9440 - val_loss: 0.2126 - val_accuracy: 0.9273\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1649 - accuracy: 0.9425 - val_loss: 0.2314 - val_accuracy: 0.9177\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1634 - accuracy: 0.9451 - val_loss: 0.2078 - val_accuracy: 0.9292\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1543 - accuracy: 0.9481 - val_loss: 0.2074 - val_accuracy: 0.9283\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1589 - accuracy: 0.9465 - val_loss: 0.2046 - val_accuracy: 0.9290\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1516 - accuracy: 0.9490 - val_loss: 0.2096 - val_accuracy: 0.9277\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1522 - accuracy: 0.9493 - val_loss: 0.2088 - val_accuracy: 0.9269\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1542 - accuracy: 0.9482 - val_loss: 0.2030 - val_accuracy: 0.9285\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1536 - accuracy: 0.9461 - val_loss: 0.1991 - val_accuracy: 0.9315\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1517 - accuracy: 0.9482 - val_loss: 0.2091 - val_accuracy: 0.9294\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1551 - accuracy: 0.9467 - val_loss: 0.1986 - val_accuracy: 0.9348\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1469 - accuracy: 0.9476 - val_loss: 0.1958 - val_accuracy: 0.9340\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1457 - accuracy: 0.9492 - val_loss: 0.2026 - val_accuracy: 0.9292\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1472 - accuracy: 0.9500 - val_loss: 0.1988 - val_accuracy: 0.9277\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1466 - accuracy: 0.9483 - val_loss: 0.1983 - val_accuracy: 0.9319\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1442 - accuracy: 0.9521 - val_loss: 0.1932 - val_accuracy: 0.9331\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1419 - accuracy: 0.9515 - val_loss: 0.1938 - val_accuracy: 0.9342\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1435 - accuracy: 0.9514 - val_loss: 0.2097 - val_accuracy: 0.9290\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1505 - accuracy: 0.9483 - val_loss: 0.1997 - val_accuracy: 0.9350\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1443 - accuracy: 0.9526 - val_loss: 0.2001 - val_accuracy: 0.9333\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1436 - accuracy: 0.9519 - val_loss: 0.1901 - val_accuracy: 0.9390\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1404 - accuracy: 0.9528 - val_loss: 0.1988 - val_accuracy: 0.9317\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1464 - accuracy: 0.9513 - val_loss: 0.1904 - val_accuracy: 0.9365\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1397 - accuracy: 0.9522 - val_loss: 0.2163 - val_accuracy: 0.9317\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1390 - accuracy: 0.9521 - val_loss: 0.1915 - val_accuracy: 0.9356\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1397 - accuracy: 0.9547 - val_loss: 0.2222 - val_accuracy: 0.9271\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1373 - accuracy: 0.9549 - val_loss: 0.1901 - val_accuracy: 0.9371\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1366 - accuracy: 0.9547 - val_loss: 0.1793 - val_accuracy: 0.9381\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1389 - accuracy: 0.9558 - val_loss: 0.1888 - val_accuracy: 0.9360\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1365 - accuracy: 0.9550 - val_loss: 0.1785 - val_accuracy: 0.9396\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1296 - accuracy: 0.9581 - val_loss: 0.1813 - val_accuracy: 0.9346\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1299 - accuracy: 0.9571 - val_loss: 0.1880 - val_accuracy: 0.9373\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1381 - accuracy: 0.9546 - val_loss: 0.2040 - val_accuracy: 0.9323\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1303 - accuracy: 0.9565 - val_loss: 0.1746 - val_accuracy: 0.9435\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1324 - accuracy: 0.9560 - val_loss: 0.1859 - val_accuracy: 0.9335\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1279 - accuracy: 0.9569 - val_loss: 0.1823 - val_accuracy: 0.9371\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1312 - accuracy: 0.9574 - val_loss: 0.1873 - val_accuracy: 0.9356\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1352 - accuracy: 0.9563 - val_loss: 0.1771 - val_accuracy: 0.9375\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1264 - accuracy: 0.9578 - val_loss: 0.1868 - val_accuracy: 0.9369\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1258 - accuracy: 0.9603 - val_loss: 0.1713 - val_accuracy: 0.9404\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1236 - accuracy: 0.9592 - val_loss: 0.1930 - val_accuracy: 0.9356\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1296 - accuracy: 0.9572 - val_loss: 0.1790 - val_accuracy: 0.9421\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1280 - accuracy: 0.9585 - val_loss: 0.1932 - val_accuracy: 0.9365\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1233 - accuracy: 0.9599 - val_loss: 0.1772 - val_accuracy: 0.9406\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1222 - accuracy: 0.9618 - val_loss: 0.1760 - val_accuracy: 0.9410\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1227 - accuracy: 0.9613 - val_loss: 0.1752 - val_accuracy: 0.9400\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1225 - accuracy: 0.9589 - val_loss: 0.1854 - val_accuracy: 0.9369\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1199 - accuracy: 0.9606 - val_loss: 0.1788 - val_accuracy: 0.9377\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1207 - accuracy: 0.9607 - val_loss: 0.1844 - val_accuracy: 0.9350\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1186 - accuracy: 0.9625 - val_loss: 0.1833 - val_accuracy: 0.9369\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1231 - accuracy: 0.9592 - val_loss: 0.1711 - val_accuracy: 0.9410\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1177 - accuracy: 0.9632 - val_loss: 0.1743 - val_accuracy: 0.9400\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1172 - accuracy: 0.9626 - val_loss: 0.1797 - val_accuracy: 0.9425\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1168 - accuracy: 0.9629 - val_loss: 0.1839 - val_accuracy: 0.9398\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1187 - accuracy: 0.9615 - val_loss: 0.1767 - val_accuracy: 0.9425\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1176 - accuracy: 0.9613 - val_loss: 0.1879 - val_accuracy: 0.9348\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1193 - accuracy: 0.9618 - val_loss: 0.1771 - val_accuracy: 0.9396\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1143 - accuracy: 0.9629 - val_loss: 0.1811 - val_accuracy: 0.9415\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1165 - accuracy: 0.9626 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1183 - accuracy: 0.9622 - val_loss: 0.1640 - val_accuracy: 0.9433\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1129 - accuracy: 0.9619 - val_loss: 0.1822 - val_accuracy: 0.9415\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1129 - accuracy: 0.9628 - val_loss: 0.1776 - val_accuracy: 0.9383\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1095 - accuracy: 0.9643 - val_loss: 0.1702 - val_accuracy: 0.9413\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9379\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_19 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_19 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions_2 (EncodeP  (None, 22, 18)           0         \n",
      " ositions)                                                       \n",
      "                                                                 \n",
      " transformer_encoder_2 (Tran  (None, 22, 18)           1718      \n",
      " sformerEncoder)                                                 \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 18)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 0.9038 - accuracy: 0.5024 - val_loss: 0.7525 - val_accuracy: 0.5175\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6867 - accuracy: 0.5886 - val_loss: 0.6412 - val_accuracy: 0.6467\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.6034 - accuracy: 0.6944 - val_loss: 0.5679 - val_accuracy: 0.7246\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5303 - accuracy: 0.7547 - val_loss: 0.5065 - val_accuracy: 0.7675\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4845 - accuracy: 0.7815 - val_loss: 0.4640 - val_accuracy: 0.7948\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4568 - accuracy: 0.7892 - val_loss: 0.4412 - val_accuracy: 0.7969\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4346 - accuracy: 0.8003 - val_loss: 0.4252 - val_accuracy: 0.8037\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4246 - accuracy: 0.8047 - val_loss: 0.4157 - val_accuracy: 0.8087\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4150 - accuracy: 0.8089 - val_loss: 0.4157 - val_accuracy: 0.8085\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4118 - accuracy: 0.8119 - val_loss: 0.4144 - val_accuracy: 0.8046\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4043 - accuracy: 0.8156 - val_loss: 0.4059 - val_accuracy: 0.8098\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4032 - accuracy: 0.8122 - val_loss: 0.4030 - val_accuracy: 0.8154\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3976 - accuracy: 0.8157 - val_loss: 0.4057 - val_accuracy: 0.8110\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3968 - accuracy: 0.8174 - val_loss: 0.3951 - val_accuracy: 0.8202\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3893 - accuracy: 0.8225 - val_loss: 0.3913 - val_accuracy: 0.8204\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3806 - accuracy: 0.8276 - val_loss: 0.3791 - val_accuracy: 0.8344\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3667 - accuracy: 0.8406 - val_loss: 0.3673 - val_accuracy: 0.8465\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3550 - accuracy: 0.8500 - val_loss: 0.3582 - val_accuracy: 0.8504\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3463 - accuracy: 0.8553 - val_loss: 0.3539 - val_accuracy: 0.8529\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3496 - accuracy: 0.8517 - val_loss: 0.3432 - val_accuracy: 0.8602\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3367 - accuracy: 0.8618 - val_loss: 0.3347 - val_accuracy: 0.8669\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3314 - accuracy: 0.8622 - val_loss: 0.3359 - val_accuracy: 0.8625\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3272 - accuracy: 0.8642 - val_loss: 0.3317 - val_accuracy: 0.8648\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3226 - accuracy: 0.8660 - val_loss: 0.3612 - val_accuracy: 0.8406\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3298 - accuracy: 0.8643 - val_loss: 0.3244 - val_accuracy: 0.8660\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3163 - accuracy: 0.8696 - val_loss: 0.3210 - val_accuracy: 0.8683\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3103 - accuracy: 0.8749 - val_loss: 0.3195 - val_accuracy: 0.8708\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3075 - accuracy: 0.8729 - val_loss: 0.3164 - val_accuracy: 0.8704\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3020 - accuracy: 0.8775 - val_loss: 0.3185 - val_accuracy: 0.8700\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3032 - accuracy: 0.8764 - val_loss: 0.3137 - val_accuracy: 0.8719\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3032 - accuracy: 0.8783 - val_loss: 0.3350 - val_accuracy: 0.8629\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2991 - accuracy: 0.8801 - val_loss: 0.3042 - val_accuracy: 0.8779\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2962 - accuracy: 0.8782 - val_loss: 0.3014 - val_accuracy: 0.8796\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2948 - accuracy: 0.8807 - val_loss: 0.3047 - val_accuracy: 0.8773\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2873 - accuracy: 0.8854 - val_loss: 0.3006 - val_accuracy: 0.8806\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2859 - accuracy: 0.8860 - val_loss: 0.2991 - val_accuracy: 0.8821\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2925 - accuracy: 0.8822 - val_loss: 0.2961 - val_accuracy: 0.8842\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2894 - accuracy: 0.8831 - val_loss: 0.2940 - val_accuracy: 0.8854\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2880 - accuracy: 0.8854 - val_loss: 0.2854 - val_accuracy: 0.8881\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2809 - accuracy: 0.8878 - val_loss: 0.2834 - val_accuracy: 0.8898\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2749 - accuracy: 0.8897 - val_loss: 0.2803 - val_accuracy: 0.8908\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2705 - accuracy: 0.8944 - val_loss: 0.2792 - val_accuracy: 0.8896\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2721 - accuracy: 0.8932 - val_loss: 0.3096 - val_accuracy: 0.8804\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2711 - accuracy: 0.8939 - val_loss: 0.2778 - val_accuracy: 0.8944\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2627 - accuracy: 0.8983 - val_loss: 0.2722 - val_accuracy: 0.8923\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2694 - accuracy: 0.8926 - val_loss: 0.2683 - val_accuracy: 0.8973\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2594 - accuracy: 0.8993 - val_loss: 0.2650 - val_accuracy: 0.9000\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2608 - accuracy: 0.8986 - val_loss: 0.2727 - val_accuracy: 0.8938\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2617 - accuracy: 0.8989 - val_loss: 0.2647 - val_accuracy: 0.9006\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2550 - accuracy: 0.9019 - val_loss: 0.2664 - val_accuracy: 0.9010\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2537 - accuracy: 0.9043 - val_loss: 0.2657 - val_accuracy: 0.8983\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2532 - accuracy: 0.9022 - val_loss: 0.2765 - val_accuracy: 0.8965\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2574 - accuracy: 0.9025 - val_loss: 0.2721 - val_accuracy: 0.8956\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2522 - accuracy: 0.9024 - val_loss: 0.2602 - val_accuracy: 0.9010\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2473 - accuracy: 0.9051 - val_loss: 0.2550 - val_accuracy: 0.9038\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2491 - accuracy: 0.9053 - val_loss: 0.2621 - val_accuracy: 0.9002\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2461 - accuracy: 0.9065 - val_loss: 0.2675 - val_accuracy: 0.8929\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2475 - accuracy: 0.9054 - val_loss: 0.2492 - val_accuracy: 0.9073\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2431 - accuracy: 0.9054 - val_loss: 0.2539 - val_accuracy: 0.9071\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2487 - accuracy: 0.9047 - val_loss: 0.2662 - val_accuracy: 0.8935\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2424 - accuracy: 0.9074 - val_loss: 0.2563 - val_accuracy: 0.9065\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2424 - accuracy: 0.9107 - val_loss: 0.2464 - val_accuracy: 0.9077\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2425 - accuracy: 0.9097 - val_loss: 0.2533 - val_accuracy: 0.9062\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2374 - accuracy: 0.9118 - val_loss: 0.2490 - val_accuracy: 0.9090\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2400 - accuracy: 0.9101 - val_loss: 0.2486 - val_accuracy: 0.9085\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2376 - accuracy: 0.9106 - val_loss: 0.2457 - val_accuracy: 0.9069\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2335 - accuracy: 0.9139 - val_loss: 0.2496 - val_accuracy: 0.9081\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2332 - accuracy: 0.9153 - val_loss: 0.2452 - val_accuracy: 0.9083\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2425 - accuracy: 0.9072 - val_loss: 0.2515 - val_accuracy: 0.9075\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2333 - accuracy: 0.9156 - val_loss: 0.2426 - val_accuracy: 0.9102\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2339 - accuracy: 0.9110 - val_loss: 0.2401 - val_accuracy: 0.9121\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2313 - accuracy: 0.9129 - val_loss: 0.2454 - val_accuracy: 0.9062\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2310 - accuracy: 0.9153 - val_loss: 0.2430 - val_accuracy: 0.9079\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2281 - accuracy: 0.9190 - val_loss: 0.2419 - val_accuracy: 0.9100\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2289 - accuracy: 0.9161 - val_loss: 0.2479 - val_accuracy: 0.9081\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2280 - accuracy: 0.9169 - val_loss: 0.2421 - val_accuracy: 0.9060\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2312 - accuracy: 0.9165 - val_loss: 0.2410 - val_accuracy: 0.9137\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2265 - accuracy: 0.9187 - val_loss: 0.2370 - val_accuracy: 0.9158\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2246 - accuracy: 0.9217 - val_loss: 0.2320 - val_accuracy: 0.9160\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2265 - accuracy: 0.9194 - val_loss: 0.2329 - val_accuracy: 0.9177\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2221 - accuracy: 0.9201 - val_loss: 0.2384 - val_accuracy: 0.9123\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2230 - accuracy: 0.9192 - val_loss: 0.2444 - val_accuracy: 0.9062\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2263 - accuracy: 0.9167 - val_loss: 0.2355 - val_accuracy: 0.9140\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2210 - accuracy: 0.9192 - val_loss: 0.2300 - val_accuracy: 0.9179\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2182 - accuracy: 0.9254 - val_loss: 0.2407 - val_accuracy: 0.9100\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2254 - accuracy: 0.9192 - val_loss: 0.2362 - val_accuracy: 0.9162\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2185 - accuracy: 0.9219 - val_loss: 0.2322 - val_accuracy: 0.9202\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2244 - accuracy: 0.9206 - val_loss: 0.2395 - val_accuracy: 0.9108\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2145 - accuracy: 0.9201 - val_loss: 0.2404 - val_accuracy: 0.9167\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2175 - accuracy: 0.9222 - val_loss: 0.2304 - val_accuracy: 0.9156\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2166 - accuracy: 0.9232 - val_loss: 0.2263 - val_accuracy: 0.9198\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2171 - accuracy: 0.9215 - val_loss: 0.2300 - val_accuracy: 0.9215\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2165 - accuracy: 0.9247 - val_loss: 0.2281 - val_accuracy: 0.9198\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2145 - accuracy: 0.9236 - val_loss: 0.2329 - val_accuracy: 0.9154\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2218 - accuracy: 0.9211 - val_loss: 0.2263 - val_accuracy: 0.9210\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2201 - accuracy: 0.9207 - val_loss: 0.2295 - val_accuracy: 0.9198\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2116 - accuracy: 0.9242 - val_loss: 0.2333 - val_accuracy: 0.9210\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2090 - accuracy: 0.9262 - val_loss: 0.2240 - val_accuracy: 0.9233\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2153 - accuracy: 0.9244 - val_loss: 0.2261 - val_accuracy: 0.9200\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2120 - accuracy: 0.9268 - val_loss: 0.2310 - val_accuracy: 0.9192\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2105 - accuracy: 0.9258 - val_loss: 0.2257 - val_accuracy: 0.9160\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2075 - accuracy: 0.9271 - val_loss: 0.2306 - val_accuracy: 0.9171\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2005 - accuracy: 0.9282 - val_loss: 0.2219 - val_accuracy: 0.9235\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2019 - accuracy: 0.9290 - val_loss: 0.2210 - val_accuracy: 0.9185\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1964 - accuracy: 0.9300 - val_loss: 0.2186 - val_accuracy: 0.9240\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1953 - accuracy: 0.9322 - val_loss: 0.2066 - val_accuracy: 0.9306\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1990 - accuracy: 0.9308 - val_loss: 0.2039 - val_accuracy: 0.9285\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1886 - accuracy: 0.9336 - val_loss: 0.1998 - val_accuracy: 0.9310\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1880 - accuracy: 0.9343 - val_loss: 0.1950 - val_accuracy: 0.9348\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1802 - accuracy: 0.9362 - val_loss: 0.1896 - val_accuracy: 0.9298\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1735 - accuracy: 0.9390 - val_loss: 0.1945 - val_accuracy: 0.9252\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1692 - accuracy: 0.9393 - val_loss: 0.1913 - val_accuracy: 0.9331\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1658 - accuracy: 0.9425 - val_loss: 0.1775 - val_accuracy: 0.9358\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1646 - accuracy: 0.9438 - val_loss: 0.1781 - val_accuracy: 0.9373\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1607 - accuracy: 0.9444 - val_loss: 0.1714 - val_accuracy: 0.9381\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1615 - accuracy: 0.9447 - val_loss: 0.1789 - val_accuracy: 0.9360\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1591 - accuracy: 0.9444 - val_loss: 0.1750 - val_accuracy: 0.9421\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1589 - accuracy: 0.9460 - val_loss: 0.1816 - val_accuracy: 0.9392\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1614 - accuracy: 0.9435 - val_loss: 0.1726 - val_accuracy: 0.9398\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1572 - accuracy: 0.9469 - val_loss: 0.1658 - val_accuracy: 0.9413\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1535 - accuracy: 0.9460 - val_loss: 0.1744 - val_accuracy: 0.9381\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1551 - accuracy: 0.9479 - val_loss: 0.1697 - val_accuracy: 0.9458\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1561 - accuracy: 0.9472 - val_loss: 0.1674 - val_accuracy: 0.9456\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1527 - accuracy: 0.9468 - val_loss: 0.1842 - val_accuracy: 0.9390\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1511 - accuracy: 0.9493 - val_loss: 0.1632 - val_accuracy: 0.9471\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1484 - accuracy: 0.9503 - val_loss: 0.1625 - val_accuracy: 0.9473\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1574 - accuracy: 0.9457 - val_loss: 0.1741 - val_accuracy: 0.9396\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1460 - accuracy: 0.9508 - val_loss: 0.1707 - val_accuracy: 0.9454\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1444 - accuracy: 0.9540 - val_loss: 0.1605 - val_accuracy: 0.9496\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1413 - accuracy: 0.9518 - val_loss: 0.1634 - val_accuracy: 0.9442\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1453 - accuracy: 0.9514 - val_loss: 0.1671 - val_accuracy: 0.9452\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1464 - accuracy: 0.9515 - val_loss: 0.1657 - val_accuracy: 0.9463\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1436 - accuracy: 0.9529 - val_loss: 0.1708 - val_accuracy: 0.9429\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1454 - accuracy: 0.9532 - val_loss: 0.1825 - val_accuracy: 0.9398\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1396 - accuracy: 0.9539 - val_loss: 0.1946 - val_accuracy: 0.9273\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1412 - accuracy: 0.9540 - val_loss: 0.1670 - val_accuracy: 0.9467\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1416 - accuracy: 0.9546 - val_loss: 0.1511 - val_accuracy: 0.9508\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1402 - accuracy: 0.9540 - val_loss: 0.1879 - val_accuracy: 0.9375\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1386 - accuracy: 0.9553 - val_loss: 0.1519 - val_accuracy: 0.9531\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1377 - accuracy: 0.9554 - val_loss: 0.1597 - val_accuracy: 0.9479\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1338 - accuracy: 0.9560 - val_loss: 0.1629 - val_accuracy: 0.9521\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1356 - accuracy: 0.9579 - val_loss: 0.1557 - val_accuracy: 0.9463\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1316 - accuracy: 0.9565 - val_loss: 0.1551 - val_accuracy: 0.9481\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1327 - accuracy: 0.9571 - val_loss: 0.1575 - val_accuracy: 0.9496\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1341 - accuracy: 0.9576 - val_loss: 0.1550 - val_accuracy: 0.9508\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1286 - accuracy: 0.9582 - val_loss: 0.1768 - val_accuracy: 0.9448\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1317 - accuracy: 0.9586 - val_loss: 0.1572 - val_accuracy: 0.9492\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1339 - accuracy: 0.9556 - val_loss: 0.1638 - val_accuracy: 0.9444\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1315 - accuracy: 0.9576 - val_loss: 0.1544 - val_accuracy: 0.9504\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1289 - accuracy: 0.9603 - val_loss: 0.1578 - val_accuracy: 0.9463\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1329 - accuracy: 0.9568 - val_loss: 0.1503 - val_accuracy: 0.9508\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1324 - accuracy: 0.9579 - val_loss: 0.1512 - val_accuracy: 0.9510\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1283 - accuracy: 0.9588 - val_loss: 0.1616 - val_accuracy: 0.9469\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1348 - accuracy: 0.9540 - val_loss: 0.1609 - val_accuracy: 0.9508\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1252 - accuracy: 0.9581 - val_loss: 0.1537 - val_accuracy: 0.9508\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1309 - accuracy: 0.9564 - val_loss: 0.1524 - val_accuracy: 0.9500\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1304 - accuracy: 0.9564 - val_loss: 0.1524 - val_accuracy: 0.9506\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1272 - accuracy: 0.9585 - val_loss: 0.1505 - val_accuracy: 0.9500\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1276 - accuracy: 0.9596 - val_loss: 0.1505 - val_accuracy: 0.9500\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1231 - accuracy: 0.9610 - val_loss: 0.1525 - val_accuracy: 0.9498\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1227 - accuracy: 0.9606 - val_loss: 0.1544 - val_accuracy: 0.9494\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1201 - accuracy: 0.9621 - val_loss: 0.1496 - val_accuracy: 0.9500\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1242 - accuracy: 0.9606 - val_loss: 0.1474 - val_accuracy: 0.9504\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1196 - accuracy: 0.9633 - val_loss: 0.1573 - val_accuracy: 0.9525\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1255 - accuracy: 0.9606 - val_loss: 0.1580 - val_accuracy: 0.9481\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1177 - accuracy: 0.9632 - val_loss: 0.1548 - val_accuracy: 0.9446\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1207 - accuracy: 0.9610 - val_loss: 0.1526 - val_accuracy: 0.9510\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1230 - accuracy: 0.9600 - val_loss: 0.1604 - val_accuracy: 0.9483\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1235 - accuracy: 0.9613 - val_loss: 0.1451 - val_accuracy: 0.9513\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1202 - accuracy: 0.9624 - val_loss: 0.1551 - val_accuracy: 0.9483\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1224 - accuracy: 0.9603 - val_loss: 0.1553 - val_accuracy: 0.9460\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1170 - accuracy: 0.9621 - val_loss: 0.1475 - val_accuracy: 0.9525\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1178 - accuracy: 0.9615 - val_loss: 0.1504 - val_accuracy: 0.9513\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1172 - accuracy: 0.9626 - val_loss: 0.1487 - val_accuracy: 0.9498\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1180 - accuracy: 0.9614 - val_loss: 0.1460 - val_accuracy: 0.9513\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1200 - accuracy: 0.9611 - val_loss: 0.1776 - val_accuracy: 0.9350\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1186 - accuracy: 0.9614 - val_loss: 0.1467 - val_accuracy: 0.9504\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1162 - accuracy: 0.9625 - val_loss: 0.1465 - val_accuracy: 0.9521\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1162 - accuracy: 0.9610 - val_loss: 0.1463 - val_accuracy: 0.9531\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1179 - accuracy: 0.9626 - val_loss: 0.1461 - val_accuracy: 0.9546\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1192 - accuracy: 0.9611 - val_loss: 0.1489 - val_accuracy: 0.9508\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1123 - accuracy: 0.9636 - val_loss: 0.1501 - val_accuracy: 0.9515\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1120 - accuracy: 0.9639 - val_loss: 0.1475 - val_accuracy: 0.9533\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1110 - accuracy: 0.9644 - val_loss: 0.1412 - val_accuracy: 0.9548\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1101 - accuracy: 0.9649 - val_loss: 0.1382 - val_accuracy: 0.9560\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1159 - accuracy: 0.9629 - val_loss: 0.1472 - val_accuracy: 0.9531\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1099 - accuracy: 0.9642 - val_loss: 0.1421 - val_accuracy: 0.9548\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1114 - accuracy: 0.9651 - val_loss: 0.1445 - val_accuracy: 0.9508\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1064 - accuracy: 0.9675 - val_loss: 0.1384 - val_accuracy: 0.9554\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1062 - accuracy: 0.9664 - val_loss: 0.1404 - val_accuracy: 0.9525\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1097 - accuracy: 0.9647 - val_loss: 0.1444 - val_accuracy: 0.9544\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1096 - accuracy: 0.9651 - val_loss: 0.1416 - val_accuracy: 0.9515\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1065 - accuracy: 0.9644 - val_loss: 0.1443 - val_accuracy: 0.9548\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1100 - accuracy: 0.9663 - val_loss: 0.1436 - val_accuracy: 0.9510\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1048 - accuracy: 0.9674 - val_loss: 0.1340 - val_accuracy: 0.9565\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1091 - accuracy: 0.9644 - val_loss: 0.1389 - val_accuracy: 0.9538\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1033 - accuracy: 0.9665 - val_loss: 0.1349 - val_accuracy: 0.9560\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1042 - accuracy: 0.9679 - val_loss: 0.1476 - val_accuracy: 0.9502\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1047 - accuracy: 0.9682 - val_loss: 0.1386 - val_accuracy: 0.9540\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1003 - accuracy: 0.9690 - val_loss: 0.1405 - val_accuracy: 0.9527\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1428 - accuracy: 0.9523\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_20 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_20 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions_3 (EncodeP  (None, 22, 18)           0         \n",
      " ositions)                                                       \n",
      "                                                                 \n",
      " transformer_encoder_3 (Tran  (None, 22, 18)           1718      \n",
      " sformerEncoder)                                                 \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 18)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 0.7351 - accuracy: 0.5779 - val_loss: 0.6085 - val_accuracy: 0.6852\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5506 - accuracy: 0.7289 - val_loss: 0.4929 - val_accuracy: 0.7667\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4772 - accuracy: 0.7669 - val_loss: 0.4572 - val_accuracy: 0.7767\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4495 - accuracy: 0.7765 - val_loss: 0.4331 - val_accuracy: 0.7873\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4400 - accuracy: 0.7811 - val_loss: 0.4294 - val_accuracy: 0.7865\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4249 - accuracy: 0.7956 - val_loss: 0.4187 - val_accuracy: 0.8012\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4161 - accuracy: 0.8061 - val_loss: 0.4194 - val_accuracy: 0.7925\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4102 - accuracy: 0.8089 - val_loss: 0.4060 - val_accuracy: 0.8163\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4057 - accuracy: 0.8118 - val_loss: 0.4032 - val_accuracy: 0.8160\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4013 - accuracy: 0.8154 - val_loss: 0.3952 - val_accuracy: 0.8163\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3971 - accuracy: 0.8185 - val_loss: 0.3971 - val_accuracy: 0.8175\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3917 - accuracy: 0.8201 - val_loss: 0.3906 - val_accuracy: 0.8215\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4094 - accuracy: 0.8101 - val_loss: 0.4053 - val_accuracy: 0.8206\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3883 - accuracy: 0.8211 - val_loss: 0.3921 - val_accuracy: 0.8204\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3823 - accuracy: 0.8286 - val_loss: 0.3796 - val_accuracy: 0.8292\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3775 - accuracy: 0.8301 - val_loss: 0.3763 - val_accuracy: 0.8302\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3811 - accuracy: 0.8269 - val_loss: 0.3765 - val_accuracy: 0.8306\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3733 - accuracy: 0.8304 - val_loss: 0.3716 - val_accuracy: 0.8352\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3720 - accuracy: 0.8335 - val_loss: 0.3841 - val_accuracy: 0.8285\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3695 - accuracy: 0.8342 - val_loss: 0.3685 - val_accuracy: 0.8388\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3611 - accuracy: 0.8374 - val_loss: 0.3583 - val_accuracy: 0.8392\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3544 - accuracy: 0.8417 - val_loss: 0.3436 - val_accuracy: 0.8469\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3344 - accuracy: 0.8546 - val_loss: 0.3111 - val_accuracy: 0.8669\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3318 - accuracy: 0.8564 - val_loss: 0.3096 - val_accuracy: 0.8725\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3079 - accuracy: 0.8671 - val_loss: 0.3145 - val_accuracy: 0.8702\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2985 - accuracy: 0.8765 - val_loss: 0.2870 - val_accuracy: 0.8815\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2809 - accuracy: 0.8843 - val_loss: 0.2822 - val_accuracy: 0.8846\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2733 - accuracy: 0.8883 - val_loss: 0.2665 - val_accuracy: 0.8938\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2614 - accuracy: 0.8946 - val_loss: 0.2631 - val_accuracy: 0.8981\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2482 - accuracy: 0.9006 - val_loss: 0.2491 - val_accuracy: 0.9010\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2475 - accuracy: 0.9026 - val_loss: 0.2517 - val_accuracy: 0.9019\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2393 - accuracy: 0.9089 - val_loss: 0.2414 - val_accuracy: 0.9077\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2323 - accuracy: 0.9100 - val_loss: 0.2495 - val_accuracy: 0.9025\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2240 - accuracy: 0.9151 - val_loss: 0.2339 - val_accuracy: 0.9131\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2317 - accuracy: 0.9125 - val_loss: 0.2315 - val_accuracy: 0.9123\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2215 - accuracy: 0.9164 - val_loss: 0.2551 - val_accuracy: 0.9015\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2173 - accuracy: 0.9182 - val_loss: 0.2228 - val_accuracy: 0.9146\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2060 - accuracy: 0.9208 - val_loss: 0.2294 - val_accuracy: 0.9090\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2067 - accuracy: 0.9225 - val_loss: 0.2151 - val_accuracy: 0.9187\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1955 - accuracy: 0.9260 - val_loss: 0.1986 - val_accuracy: 0.9287\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1773 - accuracy: 0.9360 - val_loss: 0.2063 - val_accuracy: 0.9229\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1756 - accuracy: 0.9351 - val_loss: 0.1856 - val_accuracy: 0.9315\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1670 - accuracy: 0.9400 - val_loss: 0.1792 - val_accuracy: 0.9350\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1616 - accuracy: 0.9413 - val_loss: 0.1625 - val_accuracy: 0.9396\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1534 - accuracy: 0.9446 - val_loss: 0.1511 - val_accuracy: 0.9452\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1588 - accuracy: 0.9428 - val_loss: 0.1583 - val_accuracy: 0.9438\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1412 - accuracy: 0.9524 - val_loss: 0.1371 - val_accuracy: 0.9531\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1335 - accuracy: 0.9556 - val_loss: 0.1384 - val_accuracy: 0.9546\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1355 - accuracy: 0.9544 - val_loss: 0.1343 - val_accuracy: 0.9583\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1279 - accuracy: 0.9597 - val_loss: 0.1305 - val_accuracy: 0.9598\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1226 - accuracy: 0.9617 - val_loss: 0.1376 - val_accuracy: 0.9558\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1194 - accuracy: 0.9614 - val_loss: 0.1252 - val_accuracy: 0.9627\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1168 - accuracy: 0.9622 - val_loss: 0.1295 - val_accuracy: 0.9598\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1161 - accuracy: 0.9656 - val_loss: 0.1189 - val_accuracy: 0.9646\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1121 - accuracy: 0.9646 - val_loss: 0.1215 - val_accuracy: 0.9654\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1110 - accuracy: 0.9672 - val_loss: 0.1127 - val_accuracy: 0.9683\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1069 - accuracy: 0.9671 - val_loss: 0.1145 - val_accuracy: 0.9650\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1072 - accuracy: 0.9676 - val_loss: 0.1124 - val_accuracy: 0.9675\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1024 - accuracy: 0.9682 - val_loss: 0.1142 - val_accuracy: 0.9675\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1004 - accuracy: 0.9700 - val_loss: 0.1096 - val_accuracy: 0.9694\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1380 - accuracy: 0.9525 - val_loss: 0.1268 - val_accuracy: 0.9615\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1011 - accuracy: 0.9700 - val_loss: 0.1068 - val_accuracy: 0.9683\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1053 - accuracy: 0.9679 - val_loss: 0.1100 - val_accuracy: 0.9658\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0949 - accuracy: 0.9714 - val_loss: 0.1074 - val_accuracy: 0.9704\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0903 - accuracy: 0.9742 - val_loss: 0.1090 - val_accuracy: 0.9683\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0899 - accuracy: 0.9742 - val_loss: 0.1046 - val_accuracy: 0.9706\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0883 - accuracy: 0.9740 - val_loss: 0.1032 - val_accuracy: 0.9694\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0947 - accuracy: 0.9715 - val_loss: 0.1086 - val_accuracy: 0.9683\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0916 - accuracy: 0.9732 - val_loss: 0.1111 - val_accuracy: 0.9656\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0884 - accuracy: 0.9767 - val_loss: 0.1023 - val_accuracy: 0.9708\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0853 - accuracy: 0.9760 - val_loss: 0.1078 - val_accuracy: 0.9690\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0856 - accuracy: 0.9758 - val_loss: 0.0984 - val_accuracy: 0.9725\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0830 - accuracy: 0.9761 - val_loss: 0.0982 - val_accuracy: 0.9715\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0838 - accuracy: 0.9771 - val_loss: 0.1056 - val_accuracy: 0.9673\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0832 - accuracy: 0.9762 - val_loss: 0.0965 - val_accuracy: 0.9735\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0825 - accuracy: 0.9779 - val_loss: 0.1099 - val_accuracy: 0.9675\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0825 - accuracy: 0.9786 - val_loss: 0.0958 - val_accuracy: 0.9746\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0768 - accuracy: 0.9790 - val_loss: 0.0993 - val_accuracy: 0.9698\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0774 - accuracy: 0.9801 - val_loss: 0.0954 - val_accuracy: 0.9735\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0783 - accuracy: 0.9785 - val_loss: 0.0955 - val_accuracy: 0.9712\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0799 - accuracy: 0.9785 - val_loss: 0.0971 - val_accuracy: 0.9715\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0772 - accuracy: 0.9790 - val_loss: 0.0929 - val_accuracy: 0.9760\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0768 - accuracy: 0.9793 - val_loss: 0.0910 - val_accuracy: 0.9750\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0795 - accuracy: 0.9782 - val_loss: 0.0974 - val_accuracy: 0.9735\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0771 - accuracy: 0.9787 - val_loss: 0.0896 - val_accuracy: 0.9760\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0764 - accuracy: 0.9796 - val_loss: 0.0994 - val_accuracy: 0.9710\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0763 - accuracy: 0.9792 - val_loss: 0.0916 - val_accuracy: 0.9740\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.0908 - val_accuracy: 0.9752\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0786 - accuracy: 0.9776 - val_loss: 0.0956 - val_accuracy: 0.9740\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0762 - accuracy: 0.9799 - val_loss: 0.0903 - val_accuracy: 0.9767\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0731 - accuracy: 0.9806 - val_loss: 0.0906 - val_accuracy: 0.9769\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0760 - accuracy: 0.9794 - val_loss: 0.0892 - val_accuracy: 0.9756\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0722 - accuracy: 0.9811 - val_loss: 0.0944 - val_accuracy: 0.9748\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0735 - accuracy: 0.9808 - val_loss: 0.0931 - val_accuracy: 0.9769\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0730 - accuracy: 0.9792 - val_loss: 0.1012 - val_accuracy: 0.9717\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0752 - accuracy: 0.9796 - val_loss: 0.0959 - val_accuracy: 0.9744\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0743 - accuracy: 0.9812 - val_loss: 0.0889 - val_accuracy: 0.9752\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.0909 - val_accuracy: 0.9754\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0738 - accuracy: 0.9808 - val_loss: 0.0899 - val_accuracy: 0.9752\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0677 - accuracy: 0.9814 - val_loss: 0.0884 - val_accuracy: 0.9769\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0727 - accuracy: 0.9811 - val_loss: 0.0866 - val_accuracy: 0.9758\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0711 - accuracy: 0.9817 - val_loss: 0.0886 - val_accuracy: 0.9756\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0742 - accuracy: 0.9799 - val_loss: 0.0975 - val_accuracy: 0.9740\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0737 - accuracy: 0.9810 - val_loss: 0.0909 - val_accuracy: 0.9771\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0702 - accuracy: 0.9803 - val_loss: 0.0893 - val_accuracy: 0.9752\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0650 - accuracy: 0.9818 - val_loss: 0.0923 - val_accuracy: 0.9760\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0719 - accuracy: 0.9812 - val_loss: 0.0883 - val_accuracy: 0.9758\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0687 - accuracy: 0.9831 - val_loss: 0.0910 - val_accuracy: 0.9742\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0722 - accuracy: 0.9806 - val_loss: 0.0914 - val_accuracy: 0.9737\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0697 - accuracy: 0.9814 - val_loss: 0.0888 - val_accuracy: 0.9750\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0719 - accuracy: 0.9804 - val_loss: 0.1001 - val_accuracy: 0.9702\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0740 - accuracy: 0.9799 - val_loss: 0.0902 - val_accuracy: 0.9742\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0672 - accuracy: 0.9828 - val_loss: 0.0864 - val_accuracy: 0.9767\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0671 - accuracy: 0.9815 - val_loss: 0.0927 - val_accuracy: 0.9756\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0668 - accuracy: 0.9831 - val_loss: 0.0839 - val_accuracy: 0.9777\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0654 - accuracy: 0.9829 - val_loss: 0.0870 - val_accuracy: 0.9767\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0694 - accuracy: 0.9808 - val_loss: 0.0920 - val_accuracy: 0.9762\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 0.0853 - val_accuracy: 0.9765\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0653 - accuracy: 0.9826 - val_loss: 0.0882 - val_accuracy: 0.9765\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0622 - accuracy: 0.9844 - val_loss: 0.0840 - val_accuracy: 0.9758\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0626 - accuracy: 0.9833 - val_loss: 0.0831 - val_accuracy: 0.9773\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0780 - accuracy: 0.9771 - val_loss: 0.1167 - val_accuracy: 0.9654\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0731 - accuracy: 0.9785 - val_loss: 0.1123 - val_accuracy: 0.9656\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0661 - accuracy: 0.9819 - val_loss: 0.0848 - val_accuracy: 0.9771\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0615 - accuracy: 0.9835 - val_loss: 0.0838 - val_accuracy: 0.9767\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0629 - accuracy: 0.9832 - val_loss: 0.0834 - val_accuracy: 0.9765\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0608 - accuracy: 0.9842 - val_loss: 0.0846 - val_accuracy: 0.9773\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0638 - accuracy: 0.9828 - val_loss: 0.0835 - val_accuracy: 0.9781\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0654 - accuracy: 0.9826 - val_loss: 0.0918 - val_accuracy: 0.9758\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0642 - accuracy: 0.9831 - val_loss: 0.0896 - val_accuracy: 0.9767\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0650 - accuracy: 0.9828 - val_loss: 0.0835 - val_accuracy: 0.9783\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0636 - accuracy: 0.9825 - val_loss: 0.0860 - val_accuracy: 0.9785\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0599 - accuracy: 0.9844 - val_loss: 0.0841 - val_accuracy: 0.9777\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0611 - accuracy: 0.9822 - val_loss: 0.0846 - val_accuracy: 0.9750\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0586 - accuracy: 0.9857 - val_loss: 0.0885 - val_accuracy: 0.9742\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0594 - accuracy: 0.9858 - val_loss: 0.0902 - val_accuracy: 0.9767\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0659 - accuracy: 0.9818 - val_loss: 0.0833 - val_accuracy: 0.9777\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0580 - accuracy: 0.9854 - val_loss: 0.0814 - val_accuracy: 0.9779\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0602 - accuracy: 0.9856 - val_loss: 0.0842 - val_accuracy: 0.9785\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0604 - accuracy: 0.9836 - val_loss: 0.0871 - val_accuracy: 0.9779\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0591 - accuracy: 0.9844 - val_loss: 0.0875 - val_accuracy: 0.9762\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0577 - accuracy: 0.9854 - val_loss: 0.0830 - val_accuracy: 0.9798\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0604 - accuracy: 0.9844 - val_loss: 0.0793 - val_accuracy: 0.9796\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0558 - accuracy: 0.9861 - val_loss: 0.0841 - val_accuracy: 0.9783\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0576 - accuracy: 0.9857 - val_loss: 0.0845 - val_accuracy: 0.9790\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0616 - accuracy: 0.9837 - val_loss: 0.0856 - val_accuracy: 0.9779\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0596 - accuracy: 0.9846 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0585 - accuracy: 0.9854 - val_loss: 0.0866 - val_accuracy: 0.9762\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0606 - accuracy: 0.9833 - val_loss: 0.0900 - val_accuracy: 0.9779\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0933 - val_accuracy: 0.9740\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0567 - accuracy: 0.9858 - val_loss: 0.0837 - val_accuracy: 0.9781\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0597 - accuracy: 0.9843 - val_loss: 0.1032 - val_accuracy: 0.9702\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0577 - accuracy: 0.9857 - val_loss: 0.0873 - val_accuracy: 0.9767\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0583 - accuracy: 0.9858 - val_loss: 0.0854 - val_accuracy: 0.9765\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0568 - accuracy: 0.9860 - val_loss: 0.0926 - val_accuracy: 0.9733\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0552 - accuracy: 0.9864 - val_loss: 0.0843 - val_accuracy: 0.9781\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0555 - accuracy: 0.9860 - val_loss: 0.0822 - val_accuracy: 0.9790\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0559 - accuracy: 0.9861 - val_loss: 0.0877 - val_accuracy: 0.9767\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0586 - accuracy: 0.9849 - val_loss: 0.0847 - val_accuracy: 0.9785\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0585 - accuracy: 0.9853 - val_loss: 0.0877 - val_accuracy: 0.9771\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0732 - accuracy: 0.9789 - val_loss: 0.0955 - val_accuracy: 0.9723\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0605 - accuracy: 0.9844 - val_loss: 0.0832 - val_accuracy: 0.9775\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0524 - accuracy: 0.9872 - val_loss: 0.0822 - val_accuracy: 0.9798\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0584 - accuracy: 0.9857 - val_loss: 0.0850 - val_accuracy: 0.9779\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0557 - accuracy: 0.9864 - val_loss: 0.0802 - val_accuracy: 0.9794\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0534 - accuracy: 0.9862 - val_loss: 0.0850 - val_accuracy: 0.9779\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0568 - accuracy: 0.9860 - val_loss: 0.0831 - val_accuracy: 0.9785\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0549 - accuracy: 0.9858 - val_loss: 0.0872 - val_accuracy: 0.9767\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0533 - accuracy: 0.9876 - val_loss: 0.0813 - val_accuracy: 0.9794\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 0.1076 - val_accuracy: 0.9660\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0598 - accuracy: 0.9851 - val_loss: 0.0818 - val_accuracy: 0.9792\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0545 - accuracy: 0.9867 - val_loss: 0.0880 - val_accuracy: 0.9779\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0541 - accuracy: 0.9872 - val_loss: 0.0864 - val_accuracy: 0.9775\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0510 - accuracy: 0.9865 - val_loss: 0.0852 - val_accuracy: 0.9787\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0526 - accuracy: 0.9864 - val_loss: 0.0876 - val_accuracy: 0.9775\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0545 - accuracy: 0.9854 - val_loss: 0.0829 - val_accuracy: 0.9796\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0525 - accuracy: 0.9862 - val_loss: 0.0883 - val_accuracy: 0.9767\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0566 - accuracy: 0.9844 - val_loss: 0.0807 - val_accuracy: 0.9790\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0530 - accuracy: 0.9865 - val_loss: 0.0910 - val_accuracy: 0.9746\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0559 - accuracy: 0.9849 - val_loss: 0.0876 - val_accuracy: 0.9775\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0484 - accuracy: 0.9881 - val_loss: 0.0819 - val_accuracy: 0.9794\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0513 - accuracy: 0.9872 - val_loss: 0.0811 - val_accuracy: 0.9798\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0540 - accuracy: 0.9865 - val_loss: 0.0841 - val_accuracy: 0.9794\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0523 - accuracy: 0.9869 - val_loss: 0.0869 - val_accuracy: 0.9787\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0559 - accuracy: 0.9849 - val_loss: 0.0910 - val_accuracy: 0.9750\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0555 - accuracy: 0.9840 - val_loss: 0.0822 - val_accuracy: 0.9781\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0520 - accuracy: 0.9862 - val_loss: 0.0827 - val_accuracy: 0.9779\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0543 - accuracy: 0.9851 - val_loss: 0.0893 - val_accuracy: 0.9752\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0503 - accuracy: 0.9875 - val_loss: 0.0840 - val_accuracy: 0.9767\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0534 - accuracy: 0.9861 - val_loss: 0.0831 - val_accuracy: 0.9785\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0564 - accuracy: 0.9853 - val_loss: 0.0856 - val_accuracy: 0.9771\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0516 - accuracy: 0.9871 - val_loss: 0.0824 - val_accuracy: 0.9773\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0514 - accuracy: 0.9865 - val_loss: 0.0863 - val_accuracy: 0.9781\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0817 - accuracy: 0.9791\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_21 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_21 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions_4 (EncodeP  (None, 22, 18)           0         \n",
      " ositions)                                                       \n",
      "                                                                 \n",
      " transformer_encoder_4 (Tran  (None, 22, 18)           1718      \n",
      " sformerEncoder)                                                 \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Glo  (None, 18)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 4s 13ms/step - loss: 0.7456 - accuracy: 0.5790 - val_loss: 0.6277 - val_accuracy: 0.6415\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5766 - accuracy: 0.6985 - val_loss: 0.5312 - val_accuracy: 0.7400\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.5146 - accuracy: 0.7456 - val_loss: 0.4860 - val_accuracy: 0.7629\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4653 - accuracy: 0.7788 - val_loss: 0.4520 - val_accuracy: 0.7850\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4433 - accuracy: 0.7875 - val_loss: 0.4325 - val_accuracy: 0.7979\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4148 - accuracy: 0.8057 - val_loss: 0.4050 - val_accuracy: 0.8133\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4032 - accuracy: 0.8143 - val_loss: 0.3921 - val_accuracy: 0.8213\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3998 - accuracy: 0.8150 - val_loss: 0.3829 - val_accuracy: 0.8285\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3917 - accuracy: 0.8190 - val_loss: 0.3767 - val_accuracy: 0.8325\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3771 - accuracy: 0.8294 - val_loss: 0.3706 - val_accuracy: 0.8323\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3775 - accuracy: 0.8285 - val_loss: 0.3623 - val_accuracy: 0.8369\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3692 - accuracy: 0.8317 - val_loss: 0.3798 - val_accuracy: 0.8321\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3603 - accuracy: 0.8388 - val_loss: 0.3506 - val_accuracy: 0.8448\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3591 - accuracy: 0.8404 - val_loss: 0.5083 - val_accuracy: 0.8052\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3662 - accuracy: 0.8338 - val_loss: 0.3715 - val_accuracy: 0.8298\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3565 - accuracy: 0.8418 - val_loss: 0.3256 - val_accuracy: 0.8654\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3261 - accuracy: 0.8619 - val_loss: 0.3163 - val_accuracy: 0.8692\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3123 - accuracy: 0.8706 - val_loss: 0.3009 - val_accuracy: 0.8777\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2914 - accuracy: 0.8799 - val_loss: 0.3029 - val_accuracy: 0.8792\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2802 - accuracy: 0.8881 - val_loss: 0.2885 - val_accuracy: 0.8798\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2667 - accuracy: 0.8915 - val_loss: 0.2767 - val_accuracy: 0.8883\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2672 - accuracy: 0.8928 - val_loss: 0.2693 - val_accuracy: 0.8923\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2587 - accuracy: 0.8967 - val_loss: 0.2676 - val_accuracy: 0.8935\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2462 - accuracy: 0.9032 - val_loss: 0.3284 - val_accuracy: 0.8729\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2797 - accuracy: 0.8889 - val_loss: 0.2526 - val_accuracy: 0.9021\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2373 - accuracy: 0.9083 - val_loss: 0.2478 - val_accuracy: 0.9035\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2336 - accuracy: 0.9110 - val_loss: 0.2364 - val_accuracy: 0.9094\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2235 - accuracy: 0.9165 - val_loss: 0.2368 - val_accuracy: 0.9087\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2202 - accuracy: 0.9193 - val_loss: 0.2363 - val_accuracy: 0.9119\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2184 - accuracy: 0.9217 - val_loss: 0.2301 - val_accuracy: 0.9196\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2088 - accuracy: 0.9264 - val_loss: 0.2218 - val_accuracy: 0.9179\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2064 - accuracy: 0.9276 - val_loss: 0.2194 - val_accuracy: 0.9167\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2012 - accuracy: 0.9281 - val_loss: 0.2105 - val_accuracy: 0.9212\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2069 - accuracy: 0.9282 - val_loss: 0.2099 - val_accuracy: 0.9244\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1967 - accuracy: 0.9314 - val_loss: 0.2040 - val_accuracy: 0.9269\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.2024 - accuracy: 0.9294 - val_loss: 0.2099 - val_accuracy: 0.9273\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1928 - accuracy: 0.9322 - val_loss: 0.1993 - val_accuracy: 0.9283\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1928 - accuracy: 0.9312 - val_loss: 0.1981 - val_accuracy: 0.9315\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1860 - accuracy: 0.9343 - val_loss: 0.1984 - val_accuracy: 0.9294\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1839 - accuracy: 0.9350 - val_loss: 0.1965 - val_accuracy: 0.9331\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1846 - accuracy: 0.9351 - val_loss: 0.2197 - val_accuracy: 0.9250\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1841 - accuracy: 0.9362 - val_loss: 0.1987 - val_accuracy: 0.9325\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1816 - accuracy: 0.9368 - val_loss: 0.1918 - val_accuracy: 0.9331\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1793 - accuracy: 0.9390 - val_loss: 0.1880 - val_accuracy: 0.9352\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1889 - accuracy: 0.9342 - val_loss: 0.1917 - val_accuracy: 0.9379\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1737 - accuracy: 0.9394 - val_loss: 0.1814 - val_accuracy: 0.9400\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1704 - accuracy: 0.9415 - val_loss: 0.1941 - val_accuracy: 0.9421\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1680 - accuracy: 0.9431 - val_loss: 0.1814 - val_accuracy: 0.9390\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1715 - accuracy: 0.9447 - val_loss: 0.1892 - val_accuracy: 0.9429\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1666 - accuracy: 0.9464 - val_loss: 0.1767 - val_accuracy: 0.9496\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1677 - accuracy: 0.9456 - val_loss: 0.1793 - val_accuracy: 0.9456\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1616 - accuracy: 0.9478 - val_loss: 0.1748 - val_accuracy: 0.9471\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1631 - accuracy: 0.9489 - val_loss: 0.1842 - val_accuracy: 0.9381\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1613 - accuracy: 0.9488 - val_loss: 0.1790 - val_accuracy: 0.9398\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1596 - accuracy: 0.9497 - val_loss: 0.1698 - val_accuracy: 0.9498\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1565 - accuracy: 0.9501 - val_loss: 0.1827 - val_accuracy: 0.9425\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1598 - accuracy: 0.9508 - val_loss: 0.1777 - val_accuracy: 0.9435\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1545 - accuracy: 0.9521 - val_loss: 0.1709 - val_accuracy: 0.9471\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1531 - accuracy: 0.9526 - val_loss: 0.1767 - val_accuracy: 0.9458\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1534 - accuracy: 0.9532 - val_loss: 0.1723 - val_accuracy: 0.9481\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1517 - accuracy: 0.9533 - val_loss: 0.1652 - val_accuracy: 0.9500\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1507 - accuracy: 0.9539 - val_loss: 0.1692 - val_accuracy: 0.9496\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1563 - accuracy: 0.9507 - val_loss: 0.1655 - val_accuracy: 0.9508\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1515 - accuracy: 0.9535 - val_loss: 0.1660 - val_accuracy: 0.9504\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1482 - accuracy: 0.9550 - val_loss: 0.1644 - val_accuracy: 0.9508\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1498 - accuracy: 0.9547 - val_loss: 0.1695 - val_accuracy: 0.9490\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1485 - accuracy: 0.9528 - val_loss: 0.1638 - val_accuracy: 0.9510\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1461 - accuracy: 0.9561 - val_loss: 0.1653 - val_accuracy: 0.9496\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1453 - accuracy: 0.9550 - val_loss: 0.1628 - val_accuracy: 0.9510\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1487 - accuracy: 0.9539 - val_loss: 0.1707 - val_accuracy: 0.9504\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1439 - accuracy: 0.9569 - val_loss: 0.1656 - val_accuracy: 0.9494\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1435 - accuracy: 0.9554 - val_loss: 0.1635 - val_accuracy: 0.9515\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1481 - accuracy: 0.9542 - val_loss: 0.1793 - val_accuracy: 0.9458\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1466 - accuracy: 0.9550 - val_loss: 0.1604 - val_accuracy: 0.9540\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1443 - accuracy: 0.9563 - val_loss: 0.1651 - val_accuracy: 0.9498\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1414 - accuracy: 0.9560 - val_loss: 0.1627 - val_accuracy: 0.9500\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1429 - accuracy: 0.9567 - val_loss: 0.1710 - val_accuracy: 0.9494\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1402 - accuracy: 0.9567 - val_loss: 0.1578 - val_accuracy: 0.9535\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1367 - accuracy: 0.9590 - val_loss: 0.1564 - val_accuracy: 0.9544\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1420 - accuracy: 0.9560 - val_loss: 0.1547 - val_accuracy: 0.9538\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1366 - accuracy: 0.9588 - val_loss: 0.1568 - val_accuracy: 0.9540\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1377 - accuracy: 0.9590 - val_loss: 0.1638 - val_accuracy: 0.9506\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1416 - accuracy: 0.9569 - val_loss: 0.1654 - val_accuracy: 0.9496\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1385 - accuracy: 0.9579 - val_loss: 0.1595 - val_accuracy: 0.9529\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1347 - accuracy: 0.9590 - val_loss: 0.1538 - val_accuracy: 0.9548\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1361 - accuracy: 0.9588 - val_loss: 0.1536 - val_accuracy: 0.9554\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1313 - accuracy: 0.9606 - val_loss: 0.1589 - val_accuracy: 0.9519\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1319 - accuracy: 0.9603 - val_loss: 0.1500 - val_accuracy: 0.9569\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1337 - accuracy: 0.9604 - val_loss: 0.1617 - val_accuracy: 0.9519\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1303 - accuracy: 0.9613 - val_loss: 0.1531 - val_accuracy: 0.9563\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1294 - accuracy: 0.9611 - val_loss: 0.1537 - val_accuracy: 0.9565\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1706 - accuracy: 0.9443 - val_loss: 0.1848 - val_accuracy: 0.9419\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1476 - accuracy: 0.9542 - val_loss: 0.1577 - val_accuracy: 0.9533\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1292 - accuracy: 0.9603 - val_loss: 0.1509 - val_accuracy: 0.9556\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1275 - accuracy: 0.9618 - val_loss: 0.1579 - val_accuracy: 0.9540\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1266 - accuracy: 0.9624 - val_loss: 0.1520 - val_accuracy: 0.9556\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1290 - accuracy: 0.9601 - val_loss: 0.1525 - val_accuracy: 0.9567\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1244 - accuracy: 0.9636 - val_loss: 0.1491 - val_accuracy: 0.9569\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1260 - accuracy: 0.9621 - val_loss: 0.1516 - val_accuracy: 0.9565\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1257 - accuracy: 0.9619 - val_loss: 0.1576 - val_accuracy: 0.9525\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1249 - accuracy: 0.9629 - val_loss: 0.1519 - val_accuracy: 0.9550\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1311 - accuracy: 0.9603 - val_loss: 0.1472 - val_accuracy: 0.9575\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1238 - accuracy: 0.9613 - val_loss: 0.1503 - val_accuracy: 0.9558\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1310 - accuracy: 0.9596 - val_loss: 0.1523 - val_accuracy: 0.9563\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1244 - accuracy: 0.9643 - val_loss: 0.1472 - val_accuracy: 0.9577\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1196 - accuracy: 0.9653 - val_loss: 0.1432 - val_accuracy: 0.9590\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1210 - accuracy: 0.9636 - val_loss: 0.1512 - val_accuracy: 0.9563\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1201 - accuracy: 0.9647 - val_loss: 0.1480 - val_accuracy: 0.9569\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1203 - accuracy: 0.9635 - val_loss: 0.1495 - val_accuracy: 0.9585\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1201 - accuracy: 0.9639 - val_loss: 0.1536 - val_accuracy: 0.9571\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1226 - accuracy: 0.9632 - val_loss: 0.1561 - val_accuracy: 0.9538\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1241 - accuracy: 0.9622 - val_loss: 0.1444 - val_accuracy: 0.9577\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1204 - accuracy: 0.9640 - val_loss: 0.1558 - val_accuracy: 0.9552\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1187 - accuracy: 0.9650 - val_loss: 0.1450 - val_accuracy: 0.9573\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1206 - accuracy: 0.9647 - val_loss: 0.1492 - val_accuracy: 0.9563\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1240 - accuracy: 0.9624 - val_loss: 0.1506 - val_accuracy: 0.9583\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1240 - accuracy: 0.9626 - val_loss: 0.1498 - val_accuracy: 0.9575\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1154 - accuracy: 0.9644 - val_loss: 0.1558 - val_accuracy: 0.9558\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1199 - accuracy: 0.9642 - val_loss: 0.1520 - val_accuracy: 0.9538\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1164 - accuracy: 0.9646 - val_loss: 0.1587 - val_accuracy: 0.9540\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1180 - accuracy: 0.9654 - val_loss: 0.1390 - val_accuracy: 0.9596\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1149 - accuracy: 0.9658 - val_loss: 0.1458 - val_accuracy: 0.9575\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1143 - accuracy: 0.9668 - val_loss: 0.1443 - val_accuracy: 0.9583\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1153 - accuracy: 0.9647 - val_loss: 0.1477 - val_accuracy: 0.9558\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1156 - accuracy: 0.9665 - val_loss: 0.1451 - val_accuracy: 0.9579\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1220 - accuracy: 0.9638 - val_loss: 0.1480 - val_accuracy: 0.9575\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1161 - accuracy: 0.9646 - val_loss: 0.1415 - val_accuracy: 0.9585\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1128 - accuracy: 0.9676 - val_loss: 0.1486 - val_accuracy: 0.9594\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1133 - accuracy: 0.9665 - val_loss: 0.1437 - val_accuracy: 0.9592\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1143 - accuracy: 0.9663 - val_loss: 0.1478 - val_accuracy: 0.9567\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1169 - accuracy: 0.9642 - val_loss: 0.1381 - val_accuracy: 0.9590\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1118 - accuracy: 0.9671 - val_loss: 0.1475 - val_accuracy: 0.9581\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1111 - accuracy: 0.9668 - val_loss: 0.1463 - val_accuracy: 0.9575\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1118 - accuracy: 0.9657 - val_loss: 0.1383 - val_accuracy: 0.9598\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1091 - accuracy: 0.9688 - val_loss: 0.1474 - val_accuracy: 0.9583\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1100 - accuracy: 0.9688 - val_loss: 0.1423 - val_accuracy: 0.9590\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1101 - accuracy: 0.9693 - val_loss: 0.1428 - val_accuracy: 0.9602\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1150 - accuracy: 0.9668 - val_loss: 0.1524 - val_accuracy: 0.9588\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1146 - accuracy: 0.9671 - val_loss: 0.1401 - val_accuracy: 0.9594\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1119 - accuracy: 0.9686 - val_loss: 0.1437 - val_accuracy: 0.9579\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1130 - accuracy: 0.9661 - val_loss: 0.1471 - val_accuracy: 0.9585\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1104 - accuracy: 0.9681 - val_loss: 0.1407 - val_accuracy: 0.9600\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1081 - accuracy: 0.9682 - val_loss: 0.1409 - val_accuracy: 0.9606\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1091 - accuracy: 0.9675 - val_loss: 0.1373 - val_accuracy: 0.9598\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1094 - accuracy: 0.9686 - val_loss: 0.1477 - val_accuracy: 0.9569\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1128 - accuracy: 0.9674 - val_loss: 0.1401 - val_accuracy: 0.9581\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1079 - accuracy: 0.9675 - val_loss: 0.1412 - val_accuracy: 0.9585\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1186 - accuracy: 0.9665 - val_loss: 0.1403 - val_accuracy: 0.9613\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1114 - accuracy: 0.9683 - val_loss: 0.1405 - val_accuracy: 0.9604\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1065 - accuracy: 0.9688 - val_loss: 0.1386 - val_accuracy: 0.9602\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1059 - accuracy: 0.9689 - val_loss: 0.1384 - val_accuracy: 0.9600\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1040 - accuracy: 0.9699 - val_loss: 0.1487 - val_accuracy: 0.9588\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1064 - accuracy: 0.9690 - val_loss: 0.1429 - val_accuracy: 0.9615\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1045 - accuracy: 0.9701 - val_loss: 0.1396 - val_accuracy: 0.9606\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1061 - accuracy: 0.9688 - val_loss: 0.1446 - val_accuracy: 0.9590\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1053 - accuracy: 0.9693 - val_loss: 0.1549 - val_accuracy: 0.9554\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1069 - accuracy: 0.9693 - val_loss: 0.1603 - val_accuracy: 0.9540\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1103 - accuracy: 0.9683 - val_loss: 0.1449 - val_accuracy: 0.9596\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1042 - accuracy: 0.9686 - val_loss: 0.1413 - val_accuracy: 0.9594\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1026 - accuracy: 0.9699 - val_loss: 0.1383 - val_accuracy: 0.9594\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1068 - accuracy: 0.9686 - val_loss: 0.1414 - val_accuracy: 0.9581\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1025 - accuracy: 0.9699 - val_loss: 0.1428 - val_accuracy: 0.9596\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1030 - accuracy: 0.9708 - val_loss: 0.1455 - val_accuracy: 0.9575\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1078 - accuracy: 0.9678 - val_loss: 0.1381 - val_accuracy: 0.9598\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1028 - accuracy: 0.9711 - val_loss: 0.1384 - val_accuracy: 0.9608\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1152 - accuracy: 0.9653 - val_loss: 0.1640 - val_accuracy: 0.9498\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1032 - accuracy: 0.9690 - val_loss: 0.1368 - val_accuracy: 0.9621\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1007 - accuracy: 0.9722 - val_loss: 0.1375 - val_accuracy: 0.9610\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1011 - accuracy: 0.9704 - val_loss: 0.1351 - val_accuracy: 0.9623\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1001 - accuracy: 0.9699 - val_loss: 0.1372 - val_accuracy: 0.9610\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0996 - accuracy: 0.9712 - val_loss: 0.1478 - val_accuracy: 0.9600\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0997 - accuracy: 0.9708 - val_loss: 0.1443 - val_accuracy: 0.9577\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0985 - accuracy: 0.9715 - val_loss: 0.1422 - val_accuracy: 0.9602\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1006 - accuracy: 0.9718 - val_loss: 0.1399 - val_accuracy: 0.9608\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0995 - accuracy: 0.9703 - val_loss: 0.1443 - val_accuracy: 0.9594\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1001 - accuracy: 0.9710 - val_loss: 0.1473 - val_accuracy: 0.9600\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1006 - accuracy: 0.9704 - val_loss: 0.1374 - val_accuracy: 0.9615\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0990 - accuracy: 0.9731 - val_loss: 0.1449 - val_accuracy: 0.9594\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1026 - accuracy: 0.9685 - val_loss: 0.1369 - val_accuracy: 0.9606\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1048 - accuracy: 0.9699 - val_loss: 0.1360 - val_accuracy: 0.9631\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1027 - accuracy: 0.9692 - val_loss: 0.1471 - val_accuracy: 0.9573\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1011 - accuracy: 0.9704 - val_loss: 0.1401 - val_accuracy: 0.9615\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0991 - accuracy: 0.9696 - val_loss: 0.1478 - val_accuracy: 0.9585\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1000 - accuracy: 0.9704 - val_loss: 0.1387 - val_accuracy: 0.9594\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1011 - accuracy: 0.9706 - val_loss: 0.1404 - val_accuracy: 0.9613\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0986 - accuracy: 0.9718 - val_loss: 0.1436 - val_accuracy: 0.9583\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0998 - accuracy: 0.9710 - val_loss: 0.1448 - val_accuracy: 0.9598\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0984 - accuracy: 0.9714 - val_loss: 0.1387 - val_accuracy: 0.9604\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0996 - accuracy: 0.9708 - val_loss: 0.1465 - val_accuracy: 0.9604\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0976 - accuracy: 0.9708 - val_loss: 0.1383 - val_accuracy: 0.9617\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0963 - accuracy: 0.9715 - val_loss: 0.1369 - val_accuracy: 0.9610\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0976 - accuracy: 0.9701 - val_loss: 0.1387 - val_accuracy: 0.9619\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1018 - accuracy: 0.9692 - val_loss: 0.1555 - val_accuracy: 0.9581\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0964 - accuracy: 0.9719 - val_loss: 0.1333 - val_accuracy: 0.9638\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0971 - accuracy: 0.9701 - val_loss: 0.1348 - val_accuracy: 0.9594\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0971 - accuracy: 0.9714 - val_loss: 0.1533 - val_accuracy: 0.9594\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0962 - accuracy: 0.9714 - val_loss: 0.1494 - val_accuracy: 0.9560\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0961 - accuracy: 0.9722 - val_loss: 0.1473 - val_accuracy: 0.9585\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.1060 - accuracy: 0.9667 - val_loss: 0.1385 - val_accuracy: 0.9619\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0956 - accuracy: 0.9725 - val_loss: 0.1489 - val_accuracy: 0.9604\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1497 - accuracy: 0.9591\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......encode_positions\n",
      ".........vars\n",
      "......global_max_pooling1d\n",
      ".........vars\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......masking\n",
      ".........vars\n",
      "......transformer_encoder\n",
      ".........encoder_layers\n",
      "............transformer_encoder_block\n",
      "..............._attention_dropout\n",
      "..................vars\n",
      "..............._attention_layer\n",
      ".................._dropout_layer\n",
      ".....................vars\n",
      ".................._key_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._output_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._query_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._softmax\n",
      ".....................vars\n",
      ".................._value_dense\n",
      ".....................vars\n",
      "........................0\n",
      "..................vars\n",
      "..............._attention_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._inner_dropout_layer\n",
      "..................vars\n",
      "..............._intermediate_activation_layer\n",
      "..................vars\n",
      "..............._intermediate_dense\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._output_dense\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._output_dropout\n",
      "..................vars\n",
      "..............._output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      ".........output_normalization\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........33\n",
      ".........34\n",
      ".........35\n",
      ".........36\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-26 21:35:32        98024\n",
      "config.json                                    2023-03-26 21:35:32         2169\n",
      "metadata.json                                  2023-03-26 21:35:32           64\n",
      "250/250 [==============================] - 50s 199ms/step - loss: 0.0157 - accuracy: 0.9969\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9983\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0817 - accuracy: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Large training dataset with low holdout share, 7200 examples\n",
    "experiment(1, time_task, 0.4, input_shape=(22, 18), output_shape=2, activation='softmax')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 2: Limited available data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 22, 18)\n",
      "y_train shape: (800, 2)\n",
      "X_val shape: (3200, 22, 18)\n",
      "y_val shape: (3200, 2)\n",
      "X_test shape: (16000, 22, 18)\n",
      "y_test shape: (16000, 2)\n",
      "X_train example: [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "y_train example: [1. 0.]\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_38 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_38 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 8s 195ms/step - loss: 0.7037 - accuracy: 0.4425 - val_loss: 0.7005 - val_accuracy: 0.4516\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6983 - accuracy: 0.4712 - val_loss: 0.6973 - val_accuracy: 0.4728\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6946 - accuracy: 0.4988 - val_loss: 0.6945 - val_accuracy: 0.5247\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6910 - accuracy: 0.5462 - val_loss: 0.6919 - val_accuracy: 0.5484\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6875 - accuracy: 0.5813 - val_loss: 0.6893 - val_accuracy: 0.5666\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6836 - accuracy: 0.5975 - val_loss: 0.6866 - val_accuracy: 0.5797\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6796 - accuracy: 0.6062 - val_loss: 0.6837 - val_accuracy: 0.5906\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6752 - accuracy: 0.6137 - val_loss: 0.6804 - val_accuracy: 0.5997\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6702 - accuracy: 0.6325 - val_loss: 0.6764 - val_accuracy: 0.6106\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6646 - accuracy: 0.6375 - val_loss: 0.6719 - val_accuracy: 0.6219\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6580 - accuracy: 0.6538 - val_loss: 0.6667 - val_accuracy: 0.6275\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6503 - accuracy: 0.6650 - val_loss: 0.6607 - val_accuracy: 0.6344\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6415 - accuracy: 0.6700 - val_loss: 0.6536 - val_accuracy: 0.6450\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6312 - accuracy: 0.6725 - val_loss: 0.6446 - val_accuracy: 0.6525\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6178 - accuracy: 0.6662 - val_loss: 0.6324 - val_accuracy: 0.6650\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.6001 - accuracy: 0.6850 - val_loss: 0.6139 - val_accuracy: 0.6884\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.5746 - accuracy: 0.7088 - val_loss: 0.5884 - val_accuracy: 0.7191\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5424 - accuracy: 0.7312 - val_loss: 0.5593 - val_accuracy: 0.7372\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.5076 - accuracy: 0.7688 - val_loss: 0.5287 - val_accuracy: 0.7503\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.4806 - accuracy: 0.7837 - val_loss: 0.5067 - val_accuracy: 0.7622\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.4477 - accuracy: 0.8263 - val_loss: 0.4651 - val_accuracy: 0.7941\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.4180 - accuracy: 0.8250 - val_loss: 0.4411 - val_accuracy: 0.8112\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3930 - accuracy: 0.8413 - val_loss: 0.4187 - val_accuracy: 0.8250\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.3690 - accuracy: 0.8512 - val_loss: 0.4021 - val_accuracy: 0.8309\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3498 - accuracy: 0.8550 - val_loss: 0.3801 - val_accuracy: 0.8456\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.3311 - accuracy: 0.8637 - val_loss: 0.3610 - val_accuracy: 0.8575\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.3143 - accuracy: 0.8700 - val_loss: 0.3482 - val_accuracy: 0.8625\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.2986 - accuracy: 0.8737 - val_loss: 0.3454 - val_accuracy: 0.8656\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2821 - accuracy: 0.8863 - val_loss: 0.3265 - val_accuracy: 0.8703\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.2700 - accuracy: 0.8875 - val_loss: 0.3188 - val_accuracy: 0.8753\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2634 - accuracy: 0.8950 - val_loss: 0.3224 - val_accuracy: 0.8784\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.2405 - accuracy: 0.9062 - val_loss: 0.3073 - val_accuracy: 0.8797\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 2s 150ms/step - loss: 0.2297 - accuracy: 0.9100 - val_loss: 0.3234 - val_accuracy: 0.8781\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2180 - accuracy: 0.9200 - val_loss: 0.2951 - val_accuracy: 0.8850\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2149 - accuracy: 0.9162 - val_loss: 0.2944 - val_accuracy: 0.8894\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.2055 - accuracy: 0.9175 - val_loss: 0.3052 - val_accuracy: 0.8919\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.1951 - accuracy: 0.9262 - val_loss: 0.3057 - val_accuracy: 0.8906\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.1895 - accuracy: 0.9262 - val_loss: 0.2831 - val_accuracy: 0.8978\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1832 - accuracy: 0.9375 - val_loss: 0.2855 - val_accuracy: 0.8994\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1697 - accuracy: 0.9400 - val_loss: 0.2948 - val_accuracy: 0.8922\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1621 - accuracy: 0.9413 - val_loss: 0.2975 - val_accuracy: 0.8934\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1580 - accuracy: 0.9463 - val_loss: 0.2876 - val_accuracy: 0.8963\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.1486 - accuracy: 0.9488 - val_loss: 0.2869 - val_accuracy: 0.8991\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1406 - accuracy: 0.9513 - val_loss: 0.2893 - val_accuracy: 0.9000\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1352 - accuracy: 0.9513 - val_loss: 0.2963 - val_accuracy: 0.8972\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1287 - accuracy: 0.9563 - val_loss: 0.2918 - val_accuracy: 0.9009\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1246 - accuracy: 0.9650 - val_loss: 0.2765 - val_accuracy: 0.9072\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1140 - accuracy: 0.9688 - val_loss: 0.3031 - val_accuracy: 0.9006\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1121 - accuracy: 0.9675 - val_loss: 0.2823 - val_accuracy: 0.9072\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1060 - accuracy: 0.9663 - val_loss: 0.2832 - val_accuracy: 0.9100\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1039 - accuracy: 0.9737 - val_loss: 0.2762 - val_accuracy: 0.9081\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0950 - accuracy: 0.9725 - val_loss: 0.2781 - val_accuracy: 0.9137\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.0904 - accuracy: 0.9750 - val_loss: 0.2933 - val_accuracy: 0.9131\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0873 - accuracy: 0.9737 - val_loss: 0.2828 - val_accuracy: 0.9162\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0789 - accuracy: 0.9812 - val_loss: 0.2728 - val_accuracy: 0.9166\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0802 - accuracy: 0.9750 - val_loss: 0.2868 - val_accuracy: 0.9197\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0739 - accuracy: 0.9787 - val_loss: 0.2795 - val_accuracy: 0.9216\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0642 - accuracy: 0.9812 - val_loss: 0.2711 - val_accuracy: 0.9247\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0578 - accuracy: 0.9837 - val_loss: 0.2615 - val_accuracy: 0.9284\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0556 - accuracy: 0.9875 - val_loss: 0.2624 - val_accuracy: 0.9284\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.2615 - val_accuracy: 0.9300\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0435 - accuracy: 0.9875 - val_loss: 0.2662 - val_accuracy: 0.9319\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0396 - accuracy: 0.9912 - val_loss: 0.2577 - val_accuracy: 0.9331\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.0365 - accuracy: 0.9925 - val_loss: 0.2683 - val_accuracy: 0.9344\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0360 - accuracy: 0.9925 - val_loss: 0.2624 - val_accuracy: 0.9331\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0327 - accuracy: 0.9937 - val_loss: 0.2690 - val_accuracy: 0.9347\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 0.2608 - val_accuracy: 0.9366\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0268 - accuracy: 0.9962 - val_loss: 0.2736 - val_accuracy: 0.9369\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0253 - accuracy: 0.9962 - val_loss: 0.2602 - val_accuracy: 0.9391\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0238 - accuracy: 0.9962 - val_loss: 0.2707 - val_accuracy: 0.9403\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0241 - accuracy: 0.9962 - val_loss: 0.2881 - val_accuracy: 0.9384\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0240 - accuracy: 0.9950 - val_loss: 0.2687 - val_accuracy: 0.9400\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 0.2778 - val_accuracy: 0.9394\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0192 - accuracy: 0.9962 - val_loss: 0.2782 - val_accuracy: 0.9391\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0175 - accuracy: 0.9987 - val_loss: 0.2756 - val_accuracy: 0.9406\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0170 - accuracy: 0.9987 - val_loss: 0.2794 - val_accuracy: 0.9406\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0152 - accuracy: 0.9987 - val_loss: 0.2803 - val_accuracy: 0.9425\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0145 - accuracy: 0.9987 - val_loss: 0.2824 - val_accuracy: 0.9428\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0140 - accuracy: 0.9987 - val_loss: 0.2783 - val_accuracy: 0.9441\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0135 - accuracy: 0.9987 - val_loss: 0.2856 - val_accuracy: 0.9416\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0126 - accuracy: 0.9987 - val_loss: 0.2899 - val_accuracy: 0.9409\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0118 - accuracy: 0.9987 - val_loss: 0.2916 - val_accuracy: 0.9416\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.2879 - val_accuracy: 0.9422\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 2s 156ms/step - loss: 0.0109 - accuracy: 0.9987 - val_loss: 0.2925 - val_accuracy: 0.9422\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.2942 - val_accuracy: 0.9428\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0097 - accuracy: 0.9987 - val_loss: 0.2957 - val_accuracy: 0.9425\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0093 - accuracy: 0.9987 - val_loss: 0.2984 - val_accuracy: 0.9428\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0090 - accuracy: 0.9987 - val_loss: 0.2979 - val_accuracy: 0.9431\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0086 - accuracy: 0.9987 - val_loss: 0.3045 - val_accuracy: 0.9428\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.2961 - val_accuracy: 0.9456\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.3359 - val_accuracy: 0.9428\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0267 - accuracy: 0.9937 - val_loss: 0.2756 - val_accuracy: 0.9472\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0337 - accuracy: 0.9862 - val_loss: 0.2847 - val_accuracy: 0.9409\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 0.2569 - val_accuracy: 0.9453\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 0.2971 - val_accuracy: 0.9422\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.2762 - val_accuracy: 0.9463\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 0.2799 - val_accuracy: 0.9472\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.2797 - val_accuracy: 0.9475\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 2s 156ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.2814 - val_accuracy: 0.9481\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.2864 - val_accuracy: 0.9469\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.2892 - val_accuracy: 0.9466\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.2847 - val_accuracy: 0.9469\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.2892 - val_accuracy: 0.9475\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.2961 - val_accuracy: 0.9481\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.2960 - val_accuracy: 0.9469\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.2987 - val_accuracy: 0.9472\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.3029 - val_accuracy: 0.9475\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.3044 - val_accuracy: 0.9494\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.3045 - val_accuracy: 0.9475\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.3075 - val_accuracy: 0.9491\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.3088 - val_accuracy: 0.9484\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.3115 - val_accuracy: 0.9472\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.3146 - val_accuracy: 0.9484\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 2s 156ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.3142 - val_accuracy: 0.9494\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.3158 - val_accuracy: 0.9478\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.3169 - val_accuracy: 0.9478\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.3181 - val_accuracy: 0.9494\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.3195 - val_accuracy: 0.9491\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.3215 - val_accuracy: 0.9494\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.3230 - val_accuracy: 0.9494\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.3242 - val_accuracy: 0.9497\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.9494\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9491\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3290 - val_accuracy: 0.9491\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9491\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9488\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9491\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9491\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9494\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9494\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9494\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9497\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9497\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9497\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9491\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9500\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9503\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9488\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9497\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9500\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9503\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9497\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9500\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9497\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.2185 - accuracy: 0.9532\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_39 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_39 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 8s 197ms/step - loss: 0.6947 - accuracy: 0.5175 - val_loss: 0.6915 - val_accuracy: 0.5484\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6916 - accuracy: 0.5238 - val_loss: 0.6897 - val_accuracy: 0.5606\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6890 - accuracy: 0.5387 - val_loss: 0.6881 - val_accuracy: 0.5700\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6866 - accuracy: 0.5462 - val_loss: 0.6861 - val_accuracy: 0.5738\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6839 - accuracy: 0.5537 - val_loss: 0.6842 - val_accuracy: 0.5806\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6812 - accuracy: 0.5612 - val_loss: 0.6817 - val_accuracy: 0.5916\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6778 - accuracy: 0.5688 - val_loss: 0.6791 - val_accuracy: 0.5969\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6741 - accuracy: 0.5875 - val_loss: 0.6763 - val_accuracy: 0.6025\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6702 - accuracy: 0.5975 - val_loss: 0.6731 - val_accuracy: 0.6041\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6659 - accuracy: 0.6137 - val_loss: 0.6693 - val_accuracy: 0.6150\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6602 - accuracy: 0.6150 - val_loss: 0.6655 - val_accuracy: 0.6159\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6542 - accuracy: 0.6237 - val_loss: 0.6606 - val_accuracy: 0.6203\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6465 - accuracy: 0.6350 - val_loss: 0.6553 - val_accuracy: 0.6256\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6387 - accuracy: 0.6488 - val_loss: 0.6489 - val_accuracy: 0.6319\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6299 - accuracy: 0.6525 - val_loss: 0.6418 - val_accuracy: 0.6369\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6185 - accuracy: 0.6637 - val_loss: 0.6318 - val_accuracy: 0.6559\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6060 - accuracy: 0.6787 - val_loss: 0.6214 - val_accuracy: 0.6622\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5898 - accuracy: 0.6913 - val_loss: 0.6068 - val_accuracy: 0.6831\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5715 - accuracy: 0.7075 - val_loss: 0.5968 - val_accuracy: 0.6856\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5499 - accuracy: 0.7362 - val_loss: 0.5755 - val_accuracy: 0.7084\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5286 - accuracy: 0.7525 - val_loss: 0.5607 - val_accuracy: 0.7209\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5069 - accuracy: 0.7663 - val_loss: 0.5446 - val_accuracy: 0.7328\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4838 - accuracy: 0.7837 - val_loss: 0.5211 - val_accuracy: 0.7487\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4612 - accuracy: 0.7937 - val_loss: 0.5024 - val_accuracy: 0.7697\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4428 - accuracy: 0.8050 - val_loss: 0.4877 - val_accuracy: 0.7763\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.4159 - accuracy: 0.8250 - val_loss: 0.4631 - val_accuracy: 0.7931\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.3952 - accuracy: 0.8350 - val_loss: 0.4489 - val_accuracy: 0.8050\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.3747 - accuracy: 0.8475 - val_loss: 0.4310 - val_accuracy: 0.8206\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3607 - accuracy: 0.8562 - val_loss: 0.4125 - val_accuracy: 0.8294\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3415 - accuracy: 0.8600 - val_loss: 0.4127 - val_accuracy: 0.8219\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3245 - accuracy: 0.8712 - val_loss: 0.3918 - val_accuracy: 0.8409\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3024 - accuracy: 0.8813 - val_loss: 0.3866 - val_accuracy: 0.8413\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.2869 - accuracy: 0.8863 - val_loss: 0.3735 - val_accuracy: 0.8537\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2736 - accuracy: 0.8888 - val_loss: 0.3635 - val_accuracy: 0.8600\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2573 - accuracy: 0.9050 - val_loss: 0.3510 - val_accuracy: 0.8672\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2443 - accuracy: 0.9025 - val_loss: 0.3537 - val_accuracy: 0.8634\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2346 - accuracy: 0.9112 - val_loss: 0.3406 - val_accuracy: 0.8716\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2165 - accuracy: 0.9225 - val_loss: 0.3564 - val_accuracy: 0.8659\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2129 - accuracy: 0.9175 - val_loss: 0.3351 - val_accuracy: 0.8816\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1965 - accuracy: 0.9250 - val_loss: 0.3278 - val_accuracy: 0.8784\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1828 - accuracy: 0.9362 - val_loss: 0.3265 - val_accuracy: 0.8847\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1714 - accuracy: 0.9400 - val_loss: 0.3269 - val_accuracy: 0.8834\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1629 - accuracy: 0.9450 - val_loss: 0.3269 - val_accuracy: 0.8841\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1572 - accuracy: 0.9488 - val_loss: 0.3306 - val_accuracy: 0.8913\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1518 - accuracy: 0.9500 - val_loss: 0.3148 - val_accuracy: 0.8919\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1350 - accuracy: 0.9550 - val_loss: 0.3181 - val_accuracy: 0.8919\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1267 - accuracy: 0.9638 - val_loss: 0.3130 - val_accuracy: 0.8981\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1194 - accuracy: 0.9575 - val_loss: 0.3126 - val_accuracy: 0.9000\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1109 - accuracy: 0.9638 - val_loss: 0.3236 - val_accuracy: 0.8944\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1033 - accuracy: 0.9688 - val_loss: 0.3158 - val_accuracy: 0.9009\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0953 - accuracy: 0.9737 - val_loss: 0.3154 - val_accuracy: 0.9038\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0911 - accuracy: 0.9675 - val_loss: 0.3182 - val_accuracy: 0.9062\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0882 - accuracy: 0.9725 - val_loss: 0.3123 - val_accuracy: 0.9059\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0799 - accuracy: 0.9762 - val_loss: 0.3144 - val_accuracy: 0.9084\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0716 - accuracy: 0.9787 - val_loss: 0.3293 - val_accuracy: 0.9034\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0684 - accuracy: 0.9825 - val_loss: 0.3271 - val_accuracy: 0.9100\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0676 - accuracy: 0.9850 - val_loss: 0.3246 - val_accuracy: 0.9119\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1025 - accuracy: 0.9712 - val_loss: 0.3013 - val_accuracy: 0.9119\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0880 - accuracy: 0.9737 - val_loss: 0.3059 - val_accuracy: 0.9075\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0740 - accuracy: 0.9737 - val_loss: 0.2818 - val_accuracy: 0.9137\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0666 - accuracy: 0.9812 - val_loss: 0.2767 - val_accuracy: 0.9175\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0579 - accuracy: 0.9887 - val_loss: 0.2764 - val_accuracy: 0.9222\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0529 - accuracy: 0.9875 - val_loss: 0.2781 - val_accuracy: 0.9206\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0504 - accuracy: 0.9887 - val_loss: 0.3229 - val_accuracy: 0.9087\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0513 - accuracy: 0.9887 - val_loss: 0.2803 - val_accuracy: 0.9266\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0453 - accuracy: 0.9912 - val_loss: 0.2742 - val_accuracy: 0.9272\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0422 - accuracy: 0.9912 - val_loss: 0.2756 - val_accuracy: 0.9241\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0341 - accuracy: 0.9950 - val_loss: 0.2815 - val_accuracy: 0.9250\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0327 - accuracy: 0.9950 - val_loss: 0.2825 - val_accuracy: 0.9253\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0302 - accuracy: 0.9962 - val_loss: 0.2773 - val_accuracy: 0.9303\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0266 - accuracy: 0.9975 - val_loss: 0.2916 - val_accuracy: 0.9291\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0249 - accuracy: 0.9975 - val_loss: 0.3133 - val_accuracy: 0.9250\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0231 - accuracy: 0.9975 - val_loss: 0.2907 - val_accuracy: 0.9291\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0203 - accuracy: 0.9987 - val_loss: 0.3045 - val_accuracy: 0.9284\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9316\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9319\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0179 - accuracy: 0.9975 - val_loss: 0.2922 - val_accuracy: 0.9362\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9331\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0162 - accuracy: 0.9975 - val_loss: 0.2953 - val_accuracy: 0.9388\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9341\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9397\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9416\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9409\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9406\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9419\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9425\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9431\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9422\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9438\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9438\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9431\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9447\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9444\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9434\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3260 - val_accuracy: 0.9434\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9444\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9428\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9431\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9441\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9431\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9434\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9441\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9444\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9444\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9434\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9441\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9438\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9441\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3483 - val_accuracy: 0.9438\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9431\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9434\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9438\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9438\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9441\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9441\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9444\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.3175 - accuracy: 0.9226\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_40 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_40 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 8s 197ms/step - loss: 0.6925 - accuracy: 0.5225 - val_loss: 0.6932 - val_accuracy: 0.5072\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6901 - accuracy: 0.5412 - val_loss: 0.6914 - val_accuracy: 0.5356\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6881 - accuracy: 0.5562 - val_loss: 0.6897 - val_accuracy: 0.5431\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6858 - accuracy: 0.5738 - val_loss: 0.6880 - val_accuracy: 0.5544\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6832 - accuracy: 0.5775 - val_loss: 0.6861 - val_accuracy: 0.5622\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6801 - accuracy: 0.5938 - val_loss: 0.6839 - val_accuracy: 0.5653\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6765 - accuracy: 0.6037 - val_loss: 0.6811 - val_accuracy: 0.5722\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6724 - accuracy: 0.6187 - val_loss: 0.6778 - val_accuracy: 0.5838\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6667 - accuracy: 0.6288 - val_loss: 0.6741 - val_accuracy: 0.5922\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6609 - accuracy: 0.6288 - val_loss: 0.6704 - val_accuracy: 0.6056\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6538 - accuracy: 0.6413 - val_loss: 0.6640 - val_accuracy: 0.6134\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6455 - accuracy: 0.6525 - val_loss: 0.6580 - val_accuracy: 0.6203\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.6348 - accuracy: 0.6612 - val_loss: 0.6502 - val_accuracy: 0.6325\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6240 - accuracy: 0.6725 - val_loss: 0.6424 - val_accuracy: 0.6375\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6107 - accuracy: 0.6900 - val_loss: 0.6323 - val_accuracy: 0.6525\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5961 - accuracy: 0.7075 - val_loss: 0.6223 - val_accuracy: 0.6566\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5797 - accuracy: 0.7100 - val_loss: 0.6089 - val_accuracy: 0.6756\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5632 - accuracy: 0.7287 - val_loss: 0.5944 - val_accuracy: 0.6859\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5444 - accuracy: 0.7425 - val_loss: 0.5786 - val_accuracy: 0.6994\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5260 - accuracy: 0.7650 - val_loss: 0.5587 - val_accuracy: 0.7222\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5093 - accuracy: 0.7713 - val_loss: 0.5376 - val_accuracy: 0.7431\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4830 - accuracy: 0.7887 - val_loss: 0.5171 - val_accuracy: 0.7575\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.4624 - accuracy: 0.8025 - val_loss: 0.4975 - val_accuracy: 0.7672\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4391 - accuracy: 0.8175 - val_loss: 0.4782 - val_accuracy: 0.7850\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.4220 - accuracy: 0.8288 - val_loss: 0.4619 - val_accuracy: 0.8019\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4057 - accuracy: 0.8325 - val_loss: 0.4471 - val_accuracy: 0.8122\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3847 - accuracy: 0.8525 - val_loss: 0.4305 - val_accuracy: 0.8231\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3753 - accuracy: 0.8512 - val_loss: 0.4256 - val_accuracy: 0.8247\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3545 - accuracy: 0.8650 - val_loss: 0.4081 - val_accuracy: 0.8363\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.3420 - accuracy: 0.8662 - val_loss: 0.4036 - val_accuracy: 0.8409\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.3255 - accuracy: 0.8800 - val_loss: 0.3908 - val_accuracy: 0.8469\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3081 - accuracy: 0.8825 - val_loss: 0.3832 - val_accuracy: 0.8491\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3083 - accuracy: 0.8875 - val_loss: 0.3768 - val_accuracy: 0.8544\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.2873 - accuracy: 0.8950 - val_loss: 0.3774 - val_accuracy: 0.8512\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2696 - accuracy: 0.9087 - val_loss: 0.3638 - val_accuracy: 0.8594\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.2589 - accuracy: 0.9112 - val_loss: 0.3636 - val_accuracy: 0.8625\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2455 - accuracy: 0.9125 - val_loss: 0.3697 - val_accuracy: 0.8625\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2416 - accuracy: 0.9200 - val_loss: 0.3527 - val_accuracy: 0.8706\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2249 - accuracy: 0.9200 - val_loss: 0.3526 - val_accuracy: 0.8731\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2188 - accuracy: 0.9275 - val_loss: 0.3791 - val_accuracy: 0.8594\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.2184 - accuracy: 0.9225 - val_loss: 0.3447 - val_accuracy: 0.8778\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2007 - accuracy: 0.9362 - val_loss: 0.3447 - val_accuracy: 0.8791\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1910 - accuracy: 0.9375 - val_loss: 0.3510 - val_accuracy: 0.8803\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1892 - accuracy: 0.9375 - val_loss: 0.3585 - val_accuracy: 0.8781\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1763 - accuracy: 0.9413 - val_loss: 0.3525 - val_accuracy: 0.8766\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.2421 - accuracy: 0.9187 - val_loss: 0.3532 - val_accuracy: 0.8822\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2339 - accuracy: 0.9300 - val_loss: 0.3393 - val_accuracy: 0.8844\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2151 - accuracy: 0.9300 - val_loss: 0.3404 - val_accuracy: 0.8778\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1976 - accuracy: 0.9438 - val_loss: 0.3244 - val_accuracy: 0.8891\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1806 - accuracy: 0.9425 - val_loss: 0.3271 - val_accuracy: 0.8888\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1704 - accuracy: 0.9488 - val_loss: 0.3276 - val_accuracy: 0.8903\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1627 - accuracy: 0.9513 - val_loss: 0.3347 - val_accuracy: 0.8916\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1520 - accuracy: 0.9525 - val_loss: 0.3375 - val_accuracy: 0.8925\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1410 - accuracy: 0.9538 - val_loss: 0.3413 - val_accuracy: 0.8919\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1355 - accuracy: 0.9563 - val_loss: 0.3534 - val_accuracy: 0.8884\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1298 - accuracy: 0.9613 - val_loss: 0.3594 - val_accuracy: 0.8891\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1252 - accuracy: 0.9625 - val_loss: 0.3553 - val_accuracy: 0.8934\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1184 - accuracy: 0.9638 - val_loss: 0.3891 - val_accuracy: 0.8819\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1201 - accuracy: 0.9663 - val_loss: 0.3613 - val_accuracy: 0.8931\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1171 - accuracy: 0.9638 - val_loss: 0.3570 - val_accuracy: 0.8963\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1150 - accuracy: 0.9613 - val_loss: 0.4162 - val_accuracy: 0.8763\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1261 - accuracy: 0.9538 - val_loss: 0.3678 - val_accuracy: 0.8928\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1094 - accuracy: 0.9700 - val_loss: 0.3707 - val_accuracy: 0.8934\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1074 - accuracy: 0.9650 - val_loss: 0.3747 - val_accuracy: 0.8881\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0994 - accuracy: 0.9700 - val_loss: 0.3868 - val_accuracy: 0.8903\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0951 - accuracy: 0.9712 - val_loss: 0.3729 - val_accuracy: 0.8991\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0869 - accuracy: 0.9787 - val_loss: 0.3810 - val_accuracy: 0.8972\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0827 - accuracy: 0.9787 - val_loss: 0.3848 - val_accuracy: 0.8984\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0793 - accuracy: 0.9787 - val_loss: 0.4110 - val_accuracy: 0.8909\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0777 - accuracy: 0.9787 - val_loss: 0.3957 - val_accuracy: 0.8991\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0768 - accuracy: 0.9787 - val_loss: 0.4329 - val_accuracy: 0.8878\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1699 - accuracy: 0.9463 - val_loss: 0.4208 - val_accuracy: 0.8853\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1384 - accuracy: 0.9525 - val_loss: 0.3749 - val_accuracy: 0.8891\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1139 - accuracy: 0.9625 - val_loss: 0.3566 - val_accuracy: 0.8941\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1052 - accuracy: 0.9675 - val_loss: 0.3603 - val_accuracy: 0.8944\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0905 - accuracy: 0.9737 - val_loss: 0.3762 - val_accuracy: 0.8975\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0860 - accuracy: 0.9762 - val_loss: 0.3706 - val_accuracy: 0.8991\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0790 - accuracy: 0.9775 - val_loss: 0.3853 - val_accuracy: 0.8947\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0812 - accuracy: 0.9775 - val_loss: 0.3756 - val_accuracy: 0.9006\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0737 - accuracy: 0.9800 - val_loss: 0.3896 - val_accuracy: 0.9047\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 0.4091 - val_accuracy: 0.8969\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0694 - accuracy: 0.9800 - val_loss: 0.3942 - val_accuracy: 0.9031\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0665 - accuracy: 0.9837 - val_loss: 0.3910 - val_accuracy: 0.9028\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0650 - accuracy: 0.9825 - val_loss: 0.4072 - val_accuracy: 0.9025\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0605 - accuracy: 0.9812 - val_loss: 0.4557 - val_accuracy: 0.8900\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0563 - accuracy: 0.9837 - val_loss: 0.4288 - val_accuracy: 0.9022\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0530 - accuracy: 0.9850 - val_loss: 0.4236 - val_accuracy: 0.8994\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0519 - accuracy: 0.9887 - val_loss: 0.4219 - val_accuracy: 0.9013\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0504 - accuracy: 0.9887 - val_loss: 0.4521 - val_accuracy: 0.8959\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0485 - accuracy: 0.9875 - val_loss: 0.4563 - val_accuracy: 0.8991\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0465 - accuracy: 0.9862 - val_loss: 0.4536 - val_accuracy: 0.9034\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0450 - accuracy: 0.9887 - val_loss: 0.4608 - val_accuracy: 0.9044\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0412 - accuracy: 0.9900 - val_loss: 0.4717 - val_accuracy: 0.9022\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0394 - accuracy: 0.9900 - val_loss: 0.4765 - val_accuracy: 0.9028\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.4751 - val_accuracy: 0.9034\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0373 - accuracy: 0.9900 - val_loss: 0.4850 - val_accuracy: 0.9025\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 0.4985 - val_accuracy: 0.9044\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0360 - accuracy: 0.9925 - val_loss: 0.4922 - val_accuracy: 0.9028\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0459 - accuracy: 0.9887 - val_loss: 0.4916 - val_accuracy: 0.9016\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.3257 - accuracy: 0.8879\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_41 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_41 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 9s 197ms/step - loss: 0.6908 - accuracy: 0.5612 - val_loss: 0.6891 - val_accuracy: 0.5806\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.6875 - accuracy: 0.5800 - val_loss: 0.6871 - val_accuracy: 0.5922\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6845 - accuracy: 0.6012 - val_loss: 0.6849 - val_accuracy: 0.6012\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6811 - accuracy: 0.6137 - val_loss: 0.6825 - val_accuracy: 0.6066\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6775 - accuracy: 0.6150 - val_loss: 0.6798 - val_accuracy: 0.6084\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6735 - accuracy: 0.6150 - val_loss: 0.6769 - val_accuracy: 0.6128\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6689 - accuracy: 0.6225 - val_loss: 0.6735 - val_accuracy: 0.6184\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6636 - accuracy: 0.6250 - val_loss: 0.6698 - val_accuracy: 0.6200\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6576 - accuracy: 0.6300 - val_loss: 0.6657 - val_accuracy: 0.6181\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6519 - accuracy: 0.6363 - val_loss: 0.6613 - val_accuracy: 0.6166\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6446 - accuracy: 0.6388 - val_loss: 0.6563 - val_accuracy: 0.6234\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6369 - accuracy: 0.6413 - val_loss: 0.6510 - val_accuracy: 0.6288\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6288 - accuracy: 0.6488 - val_loss: 0.6454 - val_accuracy: 0.6313\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6199 - accuracy: 0.6562 - val_loss: 0.6392 - val_accuracy: 0.6313\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6115 - accuracy: 0.6662 - val_loss: 0.6319 - val_accuracy: 0.6438\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6005 - accuracy: 0.6787 - val_loss: 0.6240 - val_accuracy: 0.6469\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5911 - accuracy: 0.6787 - val_loss: 0.6134 - val_accuracy: 0.6625\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5764 - accuracy: 0.7025 - val_loss: 0.6010 - val_accuracy: 0.6722\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5592 - accuracy: 0.7212 - val_loss: 0.5840 - val_accuracy: 0.6966\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5387 - accuracy: 0.7462 - val_loss: 0.5613 - val_accuracy: 0.7175\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5126 - accuracy: 0.7600 - val_loss: 0.5305 - val_accuracy: 0.7419\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4809 - accuracy: 0.7775 - val_loss: 0.4948 - val_accuracy: 0.7669\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4492 - accuracy: 0.7925 - val_loss: 0.4642 - val_accuracy: 0.7950\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.4177 - accuracy: 0.8288 - val_loss: 0.4512 - val_accuracy: 0.8009\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3843 - accuracy: 0.8462 - val_loss: 0.4205 - val_accuracy: 0.8266\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3582 - accuracy: 0.8650 - val_loss: 0.4060 - val_accuracy: 0.8341\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.3305 - accuracy: 0.8838 - val_loss: 0.3740 - val_accuracy: 0.8531\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.3002 - accuracy: 0.8925 - val_loss: 0.3785 - val_accuracy: 0.8509\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2928 - accuracy: 0.8875 - val_loss: 0.3440 - val_accuracy: 0.8672\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2626 - accuracy: 0.9162 - val_loss: 0.3276 - val_accuracy: 0.8753\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2440 - accuracy: 0.9112 - val_loss: 0.3252 - val_accuracy: 0.8769\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2262 - accuracy: 0.9275 - val_loss: 0.3087 - val_accuracy: 0.8878\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2076 - accuracy: 0.9300 - val_loss: 0.3206 - val_accuracy: 0.8850\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2015 - accuracy: 0.9375 - val_loss: 0.3014 - val_accuracy: 0.8931\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1874 - accuracy: 0.9425 - val_loss: 0.2850 - val_accuracy: 0.9003\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1766 - accuracy: 0.9475 - val_loss: 0.2801 - val_accuracy: 0.9038\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1686 - accuracy: 0.9425 - val_loss: 0.2895 - val_accuracy: 0.8984\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1528 - accuracy: 0.9500 - val_loss: 0.2691 - val_accuracy: 0.9081\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1491 - accuracy: 0.9525 - val_loss: 0.2720 - val_accuracy: 0.9094\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1398 - accuracy: 0.9538 - val_loss: 0.2666 - val_accuracy: 0.9081\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1300 - accuracy: 0.9563 - val_loss: 0.2548 - val_accuracy: 0.9153\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1202 - accuracy: 0.9600 - val_loss: 0.2528 - val_accuracy: 0.9184\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1153 - accuracy: 0.9650 - val_loss: 0.2478 - val_accuracy: 0.9184\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1078 - accuracy: 0.9625 - val_loss: 0.2490 - val_accuracy: 0.9203\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0976 - accuracy: 0.9688 - val_loss: 0.2413 - val_accuracy: 0.9231\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0939 - accuracy: 0.9725 - val_loss: 0.2374 - val_accuracy: 0.9275\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0830 - accuracy: 0.9737 - val_loss: 0.2391 - val_accuracy: 0.9269\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0808 - accuracy: 0.9750 - val_loss: 0.2324 - val_accuracy: 0.9250\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0707 - accuracy: 0.9787 - val_loss: 0.2301 - val_accuracy: 0.9278\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.2320 - val_accuracy: 0.9287\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0581 - accuracy: 0.9787 - val_loss: 0.2259 - val_accuracy: 0.9303\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0568 - accuracy: 0.9850 - val_loss: 0.2251 - val_accuracy: 0.9362\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0490 - accuracy: 0.9862 - val_loss: 0.2452 - val_accuracy: 0.9316\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0464 - accuracy: 0.9912 - val_loss: 0.2266 - val_accuracy: 0.9350\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0431 - accuracy: 0.9812 - val_loss: 0.2242 - val_accuracy: 0.9381\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0400 - accuracy: 0.9875 - val_loss: 0.2290 - val_accuracy: 0.9319\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0351 - accuracy: 0.9875 - val_loss: 0.2324 - val_accuracy: 0.9378\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0314 - accuracy: 0.9937 - val_loss: 0.2219 - val_accuracy: 0.9409\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0266 - accuracy: 0.9975 - val_loss: 0.2213 - val_accuracy: 0.9409\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0248 - accuracy: 0.9987 - val_loss: 0.2255 - val_accuracy: 0.9422\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0229 - accuracy: 0.9987 - val_loss: 0.2262 - val_accuracy: 0.9444\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0223 - accuracy: 0.9975 - val_loss: 0.2198 - val_accuracy: 0.9447\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0227 - accuracy: 0.9950 - val_loss: 0.2412 - val_accuracy: 0.9425\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0217 - accuracy: 0.9987 - val_loss: 0.2371 - val_accuracy: 0.9447\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.2255 - val_accuracy: 0.9481\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0153 - accuracy: 0.9987 - val_loss: 0.2302 - val_accuracy: 0.9469\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0150 - accuracy: 0.9987 - val_loss: 0.2326 - val_accuracy: 0.9481\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0140 - accuracy: 0.9987 - val_loss: 0.2532 - val_accuracy: 0.9447\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0139 - accuracy: 0.9987 - val_loss: 0.2310 - val_accuracy: 0.9484\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0127 - accuracy: 0.9987 - val_loss: 0.2337 - val_accuracy: 0.9472\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0117 - accuracy: 0.9987 - val_loss: 0.2367 - val_accuracy: 0.9478\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 0.2492 - val_accuracy: 0.9478\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0093 - accuracy: 0.9987 - val_loss: 0.2473 - val_accuracy: 0.9469\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0090 - accuracy: 0.9987 - val_loss: 0.2375 - val_accuracy: 0.9484\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.2403 - val_accuracy: 0.9497\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.2421 - val_accuracy: 0.9491\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9488\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9506\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9488\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9503\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9503\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9497\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9503\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9519\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9500\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9506\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9500\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9491\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9506\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9500\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9497\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9500\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9497\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9500\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9506\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9509\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9509\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9503\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9506\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9506\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9503\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9513\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9513\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9509\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9509\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9513\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9519\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.9525\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9506\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9516\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9516\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9519\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.2476 - accuracy: 0.9365\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_42 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_42 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                1942      \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,996\n",
      "Trainable params: 1,740\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 984, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 8s 197ms/step - loss: 0.6977 - accuracy: 0.4825 - val_loss: 0.6946 - val_accuracy: 0.4991\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6945 - accuracy: 0.4863 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6906 - val_accuracy: 0.5369\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6897 - accuracy: 0.5450 - val_loss: 0.6889 - val_accuracy: 0.5556\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6875 - accuracy: 0.5675 - val_loss: 0.6871 - val_accuracy: 0.5706\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.6850 - accuracy: 0.5800 - val_loss: 0.6852 - val_accuracy: 0.5747\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6819 - accuracy: 0.5938 - val_loss: 0.6828 - val_accuracy: 0.5809\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6786 - accuracy: 0.6037 - val_loss: 0.6800 - val_accuracy: 0.5903\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6742 - accuracy: 0.6100 - val_loss: 0.6768 - val_accuracy: 0.5959\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6691 - accuracy: 0.6187 - val_loss: 0.6729 - val_accuracy: 0.6091\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6630 - accuracy: 0.6450 - val_loss: 0.6680 - val_accuracy: 0.6172\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6562 - accuracy: 0.6500 - val_loss: 0.6624 - val_accuracy: 0.6194\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6467 - accuracy: 0.6525 - val_loss: 0.6553 - val_accuracy: 0.6284\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.6365 - accuracy: 0.6587 - val_loss: 0.6469 - val_accuracy: 0.6400\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6233 - accuracy: 0.6650 - val_loss: 0.6377 - val_accuracy: 0.6425\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.6100 - accuracy: 0.6837 - val_loss: 0.6274 - val_accuracy: 0.6444\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.5959 - accuracy: 0.6913 - val_loss: 0.6143 - val_accuracy: 0.6634\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5800 - accuracy: 0.7025 - val_loss: 0.6041 - val_accuracy: 0.6716\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5613 - accuracy: 0.7237 - val_loss: 0.5886 - val_accuracy: 0.6891\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5429 - accuracy: 0.7387 - val_loss: 0.5773 - val_accuracy: 0.6944\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5238 - accuracy: 0.7575 - val_loss: 0.5607 - val_accuracy: 0.7088\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.5043 - accuracy: 0.7588 - val_loss: 0.5458 - val_accuracy: 0.7200\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4831 - accuracy: 0.7788 - val_loss: 0.5329 - val_accuracy: 0.7344\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.4619 - accuracy: 0.7862 - val_loss: 0.5202 - val_accuracy: 0.7456\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4410 - accuracy: 0.7987 - val_loss: 0.5047 - val_accuracy: 0.7597\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.4206 - accuracy: 0.8200 - val_loss: 0.4896 - val_accuracy: 0.7719\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.3999 - accuracy: 0.8250 - val_loss: 0.4731 - val_accuracy: 0.7837\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.3814 - accuracy: 0.8388 - val_loss: 0.4536 - val_accuracy: 0.7978\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.3627 - accuracy: 0.8450 - val_loss: 0.4460 - val_accuracy: 0.8047\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.3459 - accuracy: 0.8562 - val_loss: 0.4310 - val_accuracy: 0.8156\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3276 - accuracy: 0.8675 - val_loss: 0.4130 - val_accuracy: 0.8316\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.3139 - accuracy: 0.8712 - val_loss: 0.4088 - val_accuracy: 0.8325\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2958 - accuracy: 0.8800 - val_loss: 0.3844 - val_accuracy: 0.8497\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.2797 - accuracy: 0.8888 - val_loss: 0.3906 - val_accuracy: 0.8484\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2699 - accuracy: 0.9000 - val_loss: 0.3736 - val_accuracy: 0.8547\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.2553 - accuracy: 0.9013 - val_loss: 0.3563 - val_accuracy: 0.8678\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.2441 - accuracy: 0.9100 - val_loss: 0.3502 - val_accuracy: 0.8712\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.2273 - accuracy: 0.9212 - val_loss: 0.3366 - val_accuracy: 0.8784\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2128 - accuracy: 0.9200 - val_loss: 0.3423 - val_accuracy: 0.8747\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2022 - accuracy: 0.9325 - val_loss: 0.3168 - val_accuracy: 0.8859\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.2013 - accuracy: 0.9350 - val_loss: 0.3119 - val_accuracy: 0.8872\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1918 - accuracy: 0.9337 - val_loss: 0.3053 - val_accuracy: 0.8900\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1823 - accuracy: 0.9413 - val_loss: 0.3368 - val_accuracy: 0.8791\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1713 - accuracy: 0.9450 - val_loss: 0.3030 - val_accuracy: 0.8950\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1671 - accuracy: 0.9450 - val_loss: 0.3121 - val_accuracy: 0.8878\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1580 - accuracy: 0.9488 - val_loss: 0.3219 - val_accuracy: 0.8863\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1583 - accuracy: 0.9475 - val_loss: 0.2872 - val_accuracy: 0.8984\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1461 - accuracy: 0.9525 - val_loss: 0.2876 - val_accuracy: 0.8978\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1429 - accuracy: 0.9513 - val_loss: 0.3167 - val_accuracy: 0.8881\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1331 - accuracy: 0.9538 - val_loss: 0.3060 - val_accuracy: 0.8938\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.1265 - accuracy: 0.9513 - val_loss: 0.3042 - val_accuracy: 0.8991\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1317 - accuracy: 0.9563 - val_loss: 0.2913 - val_accuracy: 0.9028\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1200 - accuracy: 0.9638 - val_loss: 0.2849 - val_accuracy: 0.9031\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.1123 - accuracy: 0.9650 - val_loss: 0.3287 - val_accuracy: 0.8922\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.1047 - accuracy: 0.9650 - val_loss: 0.2960 - val_accuracy: 0.9050\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0954 - accuracy: 0.9737 - val_loss: 0.2905 - val_accuracy: 0.9097\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0920 - accuracy: 0.9700 - val_loss: 0.3116 - val_accuracy: 0.9059\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0872 - accuracy: 0.9737 - val_loss: 0.3112 - val_accuracy: 0.9041\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 0.2977 - val_accuracy: 0.9091\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0774 - accuracy: 0.9775 - val_loss: 0.3094 - val_accuracy: 0.9062\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0753 - accuracy: 0.9775 - val_loss: 0.3022 - val_accuracy: 0.9100\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0690 - accuracy: 0.9812 - val_loss: 0.3018 - val_accuracy: 0.9116\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0682 - accuracy: 0.9762 - val_loss: 0.3070 - val_accuracy: 0.9109\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0708 - accuracy: 0.9825 - val_loss: 0.3053 - val_accuracy: 0.9109\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 2s 166ms/step - loss: 0.0638 - accuracy: 0.9850 - val_loss: 0.3024 - val_accuracy: 0.9134\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 2s 157ms/step - loss: 0.0586 - accuracy: 0.9862 - val_loss: 0.3084 - val_accuracy: 0.9150\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.0549 - accuracy: 0.9850 - val_loss: 0.3412 - val_accuracy: 0.9075\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0591 - accuracy: 0.9862 - val_loss: 0.3076 - val_accuracy: 0.9166\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0511 - accuracy: 0.9875 - val_loss: 0.3105 - val_accuracy: 0.9141\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0500 - accuracy: 0.9887 - val_loss: 0.3200 - val_accuracy: 0.9147\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0470 - accuracy: 0.9862 - val_loss: 0.3375 - val_accuracy: 0.9106\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0442 - accuracy: 0.9900 - val_loss: 0.3203 - val_accuracy: 0.9184\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 0.3239 - val_accuracy: 0.9181\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0398 - accuracy: 0.9925 - val_loss: 0.3190 - val_accuracy: 0.9203\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0374 - accuracy: 0.9950 - val_loss: 0.3236 - val_accuracy: 0.9216\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0357 - accuracy: 0.9950 - val_loss: 0.3236 - val_accuracy: 0.9197\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0351 - accuracy: 0.9925 - val_loss: 0.3254 - val_accuracy: 0.9222\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0340 - accuracy: 0.9925 - val_loss: 0.3504 - val_accuracy: 0.9144\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0324 - accuracy: 0.9925 - val_loss: 0.3405 - val_accuracy: 0.9178\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0325 - accuracy: 0.9950 - val_loss: 0.3421 - val_accuracy: 0.9178\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0303 - accuracy: 0.9962 - val_loss: 0.3478 - val_accuracy: 0.9197\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0280 - accuracy: 0.9975 - val_loss: 0.3463 - val_accuracy: 0.9206\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0260 - accuracy: 0.9987 - val_loss: 0.3487 - val_accuracy: 0.9222\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0245 - accuracy: 0.9975 - val_loss: 0.3563 - val_accuracy: 0.9197\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0240 - accuracy: 0.9975 - val_loss: 0.3531 - val_accuracy: 0.9216\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.3583 - val_accuracy: 0.9200\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0225 - accuracy: 0.9975 - val_loss: 0.3605 - val_accuracy: 0.9203\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0214 - accuracy: 0.9975 - val_loss: 0.3681 - val_accuracy: 0.9184\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0203 - accuracy: 0.9987 - val_loss: 0.3630 - val_accuracy: 0.9209\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0201 - accuracy: 0.9987 - val_loss: 0.3668 - val_accuracy: 0.9209\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0203 - accuracy: 0.9987 - val_loss: 0.3796 - val_accuracy: 0.9219\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0194 - accuracy: 0.9987 - val_loss: 0.3739 - val_accuracy: 0.9191\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0179 - accuracy: 0.9987 - val_loss: 0.3768 - val_accuracy: 0.9206\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0173 - accuracy: 0.9975 - val_loss: 0.3811 - val_accuracy: 0.9191\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0166 - accuracy: 0.9987 - val_loss: 0.3825 - val_accuracy: 0.9194\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0167 - accuracy: 0.9987 - val_loss: 0.3829 - val_accuracy: 0.9184\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0152 - accuracy: 0.9987 - val_loss: 0.3820 - val_accuracy: 0.9194\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0154 - accuracy: 0.9987 - val_loss: 0.3875 - val_accuracy: 0.9178\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0143 - accuracy: 0.9987 - val_loss: 0.3921 - val_accuracy: 0.9191\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.0140 - accuracy: 0.9987 - val_loss: 0.3969 - val_accuracy: 0.9184\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0136 - accuracy: 0.9987 - val_loss: 0.3955 - val_accuracy: 0.9187\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0133 - accuracy: 0.9987 - val_loss: 0.3936 - val_accuracy: 0.9203\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 2s 153ms/step - loss: 0.0131 - accuracy: 0.9987 - val_loss: 0.3978 - val_accuracy: 0.9187\n",
      "500/500 [==============================] - 9s 17ms/step - loss: 0.3033 - accuracy: 0.9019\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......masking\n",
      ".........vars\n",
      "......rnn\n",
      ".........cell\n",
      "............controller\n",
      "...............cells\n",
      "..................lstm_cell\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "........................2\n",
      "...............vars\n",
      "............output_layer\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............parameters_layer\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............read_layers\n",
      "...............dense\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_1\n",
      "..................vars\n",
      ".....................0\n",
      "............vars\n",
      "...............0\n",
      "............w_layers\n",
      "...............dense\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_1\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_2\n",
      "..................vars\n",
      ".....................0\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-26 22:24:20        80720\n",
      "config.json                                    2023-03-26 22:24:20         2124\n",
      "metadata.json                                  2023-03-26 22:24:20           64\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_43 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_43 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 50ms/step - loss: 0.7048 - accuracy: 0.4750 - val_loss: 0.7030 - val_accuracy: 0.4641\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6967 - accuracy: 0.5213 - val_loss: 0.6982 - val_accuracy: 0.4903\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6912 - accuracy: 0.5475 - val_loss: 0.6939 - val_accuracy: 0.5234\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6860 - accuracy: 0.5663 - val_loss: 0.6903 - val_accuracy: 0.5491\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6811 - accuracy: 0.5863 - val_loss: 0.6870 - val_accuracy: 0.5597\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6767 - accuracy: 0.6000 - val_loss: 0.6835 - val_accuracy: 0.5759\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6722 - accuracy: 0.6050 - val_loss: 0.6804 - val_accuracy: 0.5763\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6671 - accuracy: 0.6125 - val_loss: 0.6772 - val_accuracy: 0.5878\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6625 - accuracy: 0.6237 - val_loss: 0.6737 - val_accuracy: 0.6003\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6573 - accuracy: 0.6363 - val_loss: 0.6701 - val_accuracy: 0.6122\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6517 - accuracy: 0.6438 - val_loss: 0.6655 - val_accuracy: 0.6181\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6455 - accuracy: 0.6612 - val_loss: 0.6608 - val_accuracy: 0.6297\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6388 - accuracy: 0.6712 - val_loss: 0.6556 - val_accuracy: 0.6375\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6310 - accuracy: 0.6737 - val_loss: 0.6492 - val_accuracy: 0.6481\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6222 - accuracy: 0.6800 - val_loss: 0.6421 - val_accuracy: 0.6584\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6125 - accuracy: 0.6988 - val_loss: 0.6336 - val_accuracy: 0.6669\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6007 - accuracy: 0.7125 - val_loss: 0.6230 - val_accuracy: 0.6841\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.5874 - accuracy: 0.7237 - val_loss: 0.6106 - val_accuracy: 0.7022\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5715 - accuracy: 0.7375 - val_loss: 0.5961 - val_accuracy: 0.7144\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5538 - accuracy: 0.7500 - val_loss: 0.5772 - val_accuracy: 0.7269\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5321 - accuracy: 0.7675 - val_loss: 0.5568 - val_accuracy: 0.7437\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5079 - accuracy: 0.7937 - val_loss: 0.5325 - val_accuracy: 0.7631\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4806 - accuracy: 0.8100 - val_loss: 0.5062 - val_accuracy: 0.7828\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4513 - accuracy: 0.8300 - val_loss: 0.4791 - val_accuracy: 0.7997\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4222 - accuracy: 0.8450 - val_loss: 0.4498 - val_accuracy: 0.8250\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3980 - accuracy: 0.8575 - val_loss: 0.4300 - val_accuracy: 0.8266\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3663 - accuracy: 0.8750 - val_loss: 0.4002 - val_accuracy: 0.8500\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3441 - accuracy: 0.8788 - val_loss: 0.3769 - val_accuracy: 0.8606\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3176 - accuracy: 0.8950 - val_loss: 0.3631 - val_accuracy: 0.8616\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2938 - accuracy: 0.9062 - val_loss: 0.3392 - val_accuracy: 0.8763\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2766 - accuracy: 0.9075 - val_loss: 0.3272 - val_accuracy: 0.8797\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2547 - accuracy: 0.9225 - val_loss: 0.3113 - val_accuracy: 0.8878\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2390 - accuracy: 0.9350 - val_loss: 0.2975 - val_accuracy: 0.8941\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2210 - accuracy: 0.9350 - val_loss: 0.2862 - val_accuracy: 0.8994\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2074 - accuracy: 0.9413 - val_loss: 0.2794 - val_accuracy: 0.8972\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1943 - accuracy: 0.9425 - val_loss: 0.2673 - val_accuracy: 0.9031\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1832 - accuracy: 0.9488 - val_loss: 0.2600 - val_accuracy: 0.9066\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1705 - accuracy: 0.9525 - val_loss: 0.2484 - val_accuracy: 0.9119\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1581 - accuracy: 0.9600 - val_loss: 0.2401 - val_accuracy: 0.9147\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1467 - accuracy: 0.9613 - val_loss: 0.2314 - val_accuracy: 0.9194\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1355 - accuracy: 0.9675 - val_loss: 0.2220 - val_accuracy: 0.9222\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1245 - accuracy: 0.9700 - val_loss: 0.2169 - val_accuracy: 0.9262\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1157 - accuracy: 0.9750 - val_loss: 0.2073 - val_accuracy: 0.9269\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1086 - accuracy: 0.9750 - val_loss: 0.2017 - val_accuracy: 0.9341\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1004 - accuracy: 0.9750 - val_loss: 0.2012 - val_accuracy: 0.9337\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0919 - accuracy: 0.9837 - val_loss: 0.1909 - val_accuracy: 0.9372\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0867 - accuracy: 0.9837 - val_loss: 0.1821 - val_accuracy: 0.9409\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0803 - accuracy: 0.9837 - val_loss: 0.1828 - val_accuracy: 0.9422\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0747 - accuracy: 0.9887 - val_loss: 0.1785 - val_accuracy: 0.9434\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0698 - accuracy: 0.9875 - val_loss: 0.1768 - val_accuracy: 0.9431\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0670 - accuracy: 0.9875 - val_loss: 0.1723 - val_accuracy: 0.9444\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0625 - accuracy: 0.9887 - val_loss: 0.1677 - val_accuracy: 0.9481\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0570 - accuracy: 0.9887 - val_loss: 0.1694 - val_accuracy: 0.9459\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0533 - accuracy: 0.9925 - val_loss: 0.1613 - val_accuracy: 0.9481\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0511 - accuracy: 0.9925 - val_loss: 0.1597 - val_accuracy: 0.9506\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0470 - accuracy: 0.9912 - val_loss: 0.1629 - val_accuracy: 0.9500\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0453 - accuracy: 0.9937 - val_loss: 0.1600 - val_accuracy: 0.9491\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0428 - accuracy: 0.9937 - val_loss: 0.1602 - val_accuracy: 0.9494\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0409 - accuracy: 0.9937 - val_loss: 0.1573 - val_accuracy: 0.9509\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0390 - accuracy: 0.9937 - val_loss: 0.1561 - val_accuracy: 0.9528\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0371 - accuracy: 0.9937 - val_loss: 0.1558 - val_accuracy: 0.9513\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0358 - accuracy: 0.9937 - val_loss: 0.1556 - val_accuracy: 0.9509\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0341 - accuracy: 0.9950 - val_loss: 0.1541 - val_accuracy: 0.9519\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0342 - accuracy: 0.9950 - val_loss: 0.1545 - val_accuracy: 0.9528\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0327 - accuracy: 0.9937 - val_loss: 0.1547 - val_accuracy: 0.9525\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0335 - accuracy: 0.9950 - val_loss: 0.1537 - val_accuracy: 0.9522\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.1547 - val_accuracy: 0.9531\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0281 - accuracy: 0.9950 - val_loss: 0.1534 - val_accuracy: 0.9528\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0268 - accuracy: 0.9950 - val_loss: 0.1512 - val_accuracy: 0.9556\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0262 - accuracy: 0.9962 - val_loss: 0.1525 - val_accuracy: 0.9553\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0253 - accuracy: 0.9962 - val_loss: 0.1495 - val_accuracy: 0.9559\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0246 - accuracy: 0.9962 - val_loss: 0.1493 - val_accuracy: 0.9566\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0234 - accuracy: 0.9962 - val_loss: 0.1476 - val_accuracy: 0.9578\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0225 - accuracy: 0.9962 - val_loss: 0.1462 - val_accuracy: 0.9584\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0216 - accuracy: 0.9962 - val_loss: 0.1462 - val_accuracy: 0.9578\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0213 - accuracy: 0.9962 - val_loss: 0.1469 - val_accuracy: 0.9588\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0205 - accuracy: 0.9962 - val_loss: 0.1450 - val_accuracy: 0.9584\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0195 - accuracy: 0.9962 - val_loss: 0.1451 - val_accuracy: 0.9594\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.1467 - val_accuracy: 0.9588\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 0.1446 - val_accuracy: 0.9600\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.1448 - val_accuracy: 0.9588\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 0.1461 - val_accuracy: 0.9594\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.1443 - val_accuracy: 0.9600\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.1437 - val_accuracy: 0.9606\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.1447 - val_accuracy: 0.9613\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.1458 - val_accuracy: 0.9600\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.1436 - val_accuracy: 0.9603\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 0.1443 - val_accuracy: 0.9613\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.1445 - val_accuracy: 0.9616\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.1430 - val_accuracy: 0.9619\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.1599 - val_accuracy: 0.9559\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0147 - accuracy: 0.9975 - val_loss: 0.1530 - val_accuracy: 0.9569\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 0.1463 - val_accuracy: 0.9606\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.1424 - val_accuracy: 0.9603\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9616\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9616\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9628\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9616\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9622\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9616\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9625\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9616\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9625\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9613\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9619\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9588\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9609\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9603\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9613\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9603\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9606\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9588\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9600\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9581\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9581\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9588\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9581\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9578\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9575\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9572\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9578\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9588\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9581\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9575\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9572\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9569\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9556\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9566\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9559\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9559\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9563\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9566\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9563\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9566\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9563\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9563\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9559\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9563\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9563\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9572\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9559\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9563\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9563\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9559\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.1670 - accuracy: 0.9538\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_44 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_44 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 3s 51ms/step - loss: 0.6966 - accuracy: 0.5138 - val_loss: 0.6981 - val_accuracy: 0.4906\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6909 - accuracy: 0.5400 - val_loss: 0.6934 - val_accuracy: 0.5125\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6855 - accuracy: 0.5650 - val_loss: 0.6899 - val_accuracy: 0.5375\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6812 - accuracy: 0.5788 - val_loss: 0.6868 - val_accuracy: 0.5534\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6774 - accuracy: 0.5925 - val_loss: 0.6838 - val_accuracy: 0.5713\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6733 - accuracy: 0.6050 - val_loss: 0.6809 - val_accuracy: 0.5875\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6692 - accuracy: 0.6112 - val_loss: 0.6776 - val_accuracy: 0.5994\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6644 - accuracy: 0.6212 - val_loss: 0.6742 - val_accuracy: 0.6084\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6595 - accuracy: 0.6288 - val_loss: 0.6704 - val_accuracy: 0.6153\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6537 - accuracy: 0.6375 - val_loss: 0.6662 - val_accuracy: 0.6234\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6472 - accuracy: 0.6475 - val_loss: 0.6610 - val_accuracy: 0.6325\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6399 - accuracy: 0.6600 - val_loss: 0.6551 - val_accuracy: 0.6400\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6320 - accuracy: 0.6712 - val_loss: 0.6485 - val_accuracy: 0.6553\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6224 - accuracy: 0.6850 - val_loss: 0.6411 - val_accuracy: 0.6681\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6125 - accuracy: 0.6913 - val_loss: 0.6317 - val_accuracy: 0.6809\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5997 - accuracy: 0.7113 - val_loss: 0.6206 - val_accuracy: 0.6928\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5862 - accuracy: 0.7225 - val_loss: 0.6071 - val_accuracy: 0.7081\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5705 - accuracy: 0.7350 - val_loss: 0.5922 - val_accuracy: 0.7200\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5529 - accuracy: 0.7462 - val_loss: 0.5746 - val_accuracy: 0.7403\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5344 - accuracy: 0.7588 - val_loss: 0.5557 - val_accuracy: 0.7500\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5142 - accuracy: 0.7625 - val_loss: 0.5366 - val_accuracy: 0.7625\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4937 - accuracy: 0.7937 - val_loss: 0.5174 - val_accuracy: 0.7728\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4752 - accuracy: 0.8050 - val_loss: 0.4986 - val_accuracy: 0.7784\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4528 - accuracy: 0.8175 - val_loss: 0.4805 - val_accuracy: 0.7903\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4314 - accuracy: 0.8363 - val_loss: 0.4638 - val_accuracy: 0.8009\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4089 - accuracy: 0.8462 - val_loss: 0.4442 - val_accuracy: 0.8122\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3847 - accuracy: 0.8637 - val_loss: 0.4308 - val_accuracy: 0.8194\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3638 - accuracy: 0.8675 - val_loss: 0.4119 - val_accuracy: 0.8325\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3446 - accuracy: 0.8788 - val_loss: 0.3947 - val_accuracy: 0.8419\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3207 - accuracy: 0.8888 - val_loss: 0.3782 - val_accuracy: 0.8525\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3027 - accuracy: 0.8988 - val_loss: 0.3638 - val_accuracy: 0.8597\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2832 - accuracy: 0.9112 - val_loss: 0.3515 - val_accuracy: 0.8656\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2670 - accuracy: 0.9162 - val_loss: 0.3397 - val_accuracy: 0.8716\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2509 - accuracy: 0.9225 - val_loss: 0.3270 - val_accuracy: 0.8781\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.2339 - accuracy: 0.9312 - val_loss: 0.3160 - val_accuracy: 0.8822\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2198 - accuracy: 0.9362 - val_loss: 0.3071 - val_accuracy: 0.8875\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2094 - accuracy: 0.9488 - val_loss: 0.3001 - val_accuracy: 0.8881\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1954 - accuracy: 0.9538 - val_loss: 0.2914 - val_accuracy: 0.8928\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1852 - accuracy: 0.9550 - val_loss: 0.2878 - val_accuracy: 0.8947\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1790 - accuracy: 0.9563 - val_loss: 0.2801 - val_accuracy: 0.8959\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1686 - accuracy: 0.9588 - val_loss: 0.2767 - val_accuracy: 0.8994\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1624 - accuracy: 0.9563 - val_loss: 0.2728 - val_accuracy: 0.8994\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1544 - accuracy: 0.9613 - val_loss: 0.2620 - val_accuracy: 0.9041\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1412 - accuracy: 0.9638 - val_loss: 0.2657 - val_accuracy: 0.9062\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1328 - accuracy: 0.9675 - val_loss: 0.2558 - val_accuracy: 0.9078\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1243 - accuracy: 0.9712 - val_loss: 0.2512 - val_accuracy: 0.9097\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1173 - accuracy: 0.9725 - val_loss: 0.2483 - val_accuracy: 0.9125\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1126 - accuracy: 0.9737 - val_loss: 0.2446 - val_accuracy: 0.9125\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1073 - accuracy: 0.9737 - val_loss: 0.2414 - val_accuracy: 0.9134\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1012 - accuracy: 0.9750 - val_loss: 0.2373 - val_accuracy: 0.9134\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0982 - accuracy: 0.9787 - val_loss: 0.2316 - val_accuracy: 0.9169\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0960 - accuracy: 0.9787 - val_loss: 0.2398 - val_accuracy: 0.9150\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0897 - accuracy: 0.9775 - val_loss: 0.2267 - val_accuracy: 0.9203\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0836 - accuracy: 0.9812 - val_loss: 0.2234 - val_accuracy: 0.9212\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0801 - accuracy: 0.9862 - val_loss: 0.2193 - val_accuracy: 0.9225\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0762 - accuracy: 0.9875 - val_loss: 0.2161 - val_accuracy: 0.9247\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0719 - accuracy: 0.9887 - val_loss: 0.2163 - val_accuracy: 0.9247\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0691 - accuracy: 0.9875 - val_loss: 0.2265 - val_accuracy: 0.9197\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0751 - accuracy: 0.9825 - val_loss: 0.2103 - val_accuracy: 0.9278\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0646 - accuracy: 0.9887 - val_loss: 0.1996 - val_accuracy: 0.9303\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0600 - accuracy: 0.9900 - val_loss: 0.2009 - val_accuracy: 0.9312\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0551 - accuracy: 0.9925 - val_loss: 0.2089 - val_accuracy: 0.9325\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0541 - accuracy: 0.9925 - val_loss: 0.2132 - val_accuracy: 0.9272\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0498 - accuracy: 0.9937 - val_loss: 0.2036 - val_accuracy: 0.9322\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0509 - accuracy: 0.9912 - val_loss: 0.2079 - val_accuracy: 0.9300\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0477 - accuracy: 0.9925 - val_loss: 0.2208 - val_accuracy: 0.9294\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0476 - accuracy: 0.9912 - val_loss: 0.2078 - val_accuracy: 0.9319\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0430 - accuracy: 0.9962 - val_loss: 0.2102 - val_accuracy: 0.9334\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0423 - accuracy: 0.9925 - val_loss: 0.2136 - val_accuracy: 0.9325\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0401 - accuracy: 0.9950 - val_loss: 0.2096 - val_accuracy: 0.9337\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0383 - accuracy: 0.9962 - val_loss: 0.2112 - val_accuracy: 0.9341\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0372 - accuracy: 0.9962 - val_loss: 0.2144 - val_accuracy: 0.9328\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0363 - accuracy: 0.9962 - val_loss: 0.2125 - val_accuracy: 0.9350\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0350 - accuracy: 0.9962 - val_loss: 0.2115 - val_accuracy: 0.9347\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0343 - accuracy: 0.9962 - val_loss: 0.2112 - val_accuracy: 0.9353\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0335 - accuracy: 0.9962 - val_loss: 0.2121 - val_accuracy: 0.9372\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0327 - accuracy: 0.9962 - val_loss: 0.2116 - val_accuracy: 0.9375\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0322 - accuracy: 0.9962 - val_loss: 0.2130 - val_accuracy: 0.9375\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0315 - accuracy: 0.9962 - val_loss: 0.2126 - val_accuracy: 0.9388\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0309 - accuracy: 0.9962 - val_loss: 0.2117 - val_accuracy: 0.9381\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0303 - accuracy: 0.9962 - val_loss: 0.2136 - val_accuracy: 0.9388\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0298 - accuracy: 0.9962 - val_loss: 0.2143 - val_accuracy: 0.9384\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0294 - accuracy: 0.9962 - val_loss: 0.2140 - val_accuracy: 0.9397\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0288 - accuracy: 0.9962 - val_loss: 0.2147 - val_accuracy: 0.9394\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0285 - accuracy: 0.9962 - val_loss: 0.2177 - val_accuracy: 0.9375\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0280 - accuracy: 0.9962 - val_loss: 0.2160 - val_accuracy: 0.9397\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0276 - accuracy: 0.9962 - val_loss: 0.2179 - val_accuracy: 0.9391\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0271 - accuracy: 0.9962 - val_loss: 0.2164 - val_accuracy: 0.9397\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0269 - accuracy: 0.9962 - val_loss: 0.2166 - val_accuracy: 0.9394\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0264 - accuracy: 0.9962 - val_loss: 0.2171 - val_accuracy: 0.9400\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0261 - accuracy: 0.9962 - val_loss: 0.2183 - val_accuracy: 0.9416\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0260 - accuracy: 0.9962 - val_loss: 0.2200 - val_accuracy: 0.9403\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0255 - accuracy: 0.9962 - val_loss: 0.2197 - val_accuracy: 0.9391\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0252 - accuracy: 0.9962 - val_loss: 0.2187 - val_accuracy: 0.9422\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0252 - accuracy: 0.9962 - val_loss: 0.2214 - val_accuracy: 0.9409\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0247 - accuracy: 0.9962 - val_loss: 0.2219 - val_accuracy: 0.9409\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0243 - accuracy: 0.9962 - val_loss: 0.2213 - val_accuracy: 0.9422\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0242 - accuracy: 0.9962 - val_loss: 0.2218 - val_accuracy: 0.9397\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0238 - accuracy: 0.9962 - val_loss: 0.2213 - val_accuracy: 0.9413\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0236 - accuracy: 0.9962 - val_loss: 0.2225 - val_accuracy: 0.9425\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0233 - accuracy: 0.9962 - val_loss: 0.2231 - val_accuracy: 0.9416\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0232 - accuracy: 0.9962 - val_loss: 0.2225 - val_accuracy: 0.9416\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0228 - accuracy: 0.9962 - val_loss: 0.2239 - val_accuracy: 0.9413\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0226 - accuracy: 0.9962 - val_loss: 0.2252 - val_accuracy: 0.9400\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0223 - accuracy: 0.9962 - val_loss: 0.2265 - val_accuracy: 0.9403\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 0.2269 - val_accuracy: 0.9406\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0220 - accuracy: 0.9962 - val_loss: 0.2272 - val_accuracy: 0.9406\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0220 - accuracy: 0.9962 - val_loss: 0.2265 - val_accuracy: 0.9416\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0216 - accuracy: 0.9962 - val_loss: 0.2279 - val_accuracy: 0.9416\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0214 - accuracy: 0.9962 - val_loss: 0.2275 - val_accuracy: 0.9425\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.2047 - accuracy: 0.9342\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_45 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_45 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 50ms/step - loss: 0.7211 - accuracy: 0.4550 - val_loss: 0.7105 - val_accuracy: 0.4631\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.7079 - accuracy: 0.4663 - val_loss: 0.7030 - val_accuracy: 0.4844\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.7004 - accuracy: 0.4913 - val_loss: 0.6964 - val_accuracy: 0.5106\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6930 - accuracy: 0.5312 - val_loss: 0.6918 - val_accuracy: 0.5431\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6871 - accuracy: 0.5612 - val_loss: 0.6875 - val_accuracy: 0.5647\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6815 - accuracy: 0.5975 - val_loss: 0.6835 - val_accuracy: 0.5769\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6761 - accuracy: 0.6075 - val_loss: 0.6798 - val_accuracy: 0.5888\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6706 - accuracy: 0.6288 - val_loss: 0.6760 - val_accuracy: 0.5950\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6654 - accuracy: 0.6313 - val_loss: 0.6719 - val_accuracy: 0.6066\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6595 - accuracy: 0.6413 - val_loss: 0.6680 - val_accuracy: 0.6162\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6536 - accuracy: 0.6500 - val_loss: 0.6637 - val_accuracy: 0.6256\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6468 - accuracy: 0.6575 - val_loss: 0.6586 - val_accuracy: 0.6341\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6397 - accuracy: 0.6712 - val_loss: 0.6527 - val_accuracy: 0.6422\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6312 - accuracy: 0.6775 - val_loss: 0.6463 - val_accuracy: 0.6519\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6220 - accuracy: 0.6775 - val_loss: 0.6386 - val_accuracy: 0.6634\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6115 - accuracy: 0.6963 - val_loss: 0.6298 - val_accuracy: 0.6759\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6000 - accuracy: 0.7100 - val_loss: 0.6184 - val_accuracy: 0.6881\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5849 - accuracy: 0.7250 - val_loss: 0.6063 - val_accuracy: 0.7063\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.5687 - accuracy: 0.7538 - val_loss: 0.5900 - val_accuracy: 0.7237\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5494 - accuracy: 0.7688 - val_loss: 0.5723 - val_accuracy: 0.7344\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5282 - accuracy: 0.7800 - val_loss: 0.5519 - val_accuracy: 0.7534\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5055 - accuracy: 0.7987 - val_loss: 0.5283 - val_accuracy: 0.7728\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4812 - accuracy: 0.8037 - val_loss: 0.5055 - val_accuracy: 0.7900\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4591 - accuracy: 0.8200 - val_loss: 0.4871 - val_accuracy: 0.7994\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4407 - accuracy: 0.8250 - val_loss: 0.4591 - val_accuracy: 0.8250\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4185 - accuracy: 0.8450 - val_loss: 0.4425 - val_accuracy: 0.8334\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3994 - accuracy: 0.8400 - val_loss: 0.4237 - val_accuracy: 0.8416\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3801 - accuracy: 0.8637 - val_loss: 0.4160 - val_accuracy: 0.8347\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3627 - accuracy: 0.8662 - val_loss: 0.3952 - val_accuracy: 0.8547\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3514 - accuracy: 0.8650 - val_loss: 0.3971 - val_accuracy: 0.8444\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3313 - accuracy: 0.8838 - val_loss: 0.3717 - val_accuracy: 0.8641\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3186 - accuracy: 0.8825 - val_loss: 0.3623 - val_accuracy: 0.8644\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3064 - accuracy: 0.8875 - val_loss: 0.3611 - val_accuracy: 0.8587\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2886 - accuracy: 0.8900 - val_loss: 0.3494 - val_accuracy: 0.8653\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2731 - accuracy: 0.9025 - val_loss: 0.3345 - val_accuracy: 0.8737\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.2628 - accuracy: 0.9100 - val_loss: 0.3449 - val_accuracy: 0.8675\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.2545 - accuracy: 0.9075 - val_loss: 0.3487 - val_accuracy: 0.8653\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2424 - accuracy: 0.9187 - val_loss: 0.3234 - val_accuracy: 0.8784\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2445 - accuracy: 0.9125 - val_loss: 0.3085 - val_accuracy: 0.8881\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2161 - accuracy: 0.9350 - val_loss: 0.3140 - val_accuracy: 0.8831\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2058 - accuracy: 0.9375 - val_loss: 0.3002 - val_accuracy: 0.8888\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1977 - accuracy: 0.9362 - val_loss: 0.2994 - val_accuracy: 0.8894\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1862 - accuracy: 0.9425 - val_loss: 0.2944 - val_accuracy: 0.8906\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1789 - accuracy: 0.9425 - val_loss: 0.2912 - val_accuracy: 0.8947\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1708 - accuracy: 0.9450 - val_loss: 0.2877 - val_accuracy: 0.8978\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1603 - accuracy: 0.9488 - val_loss: 0.2994 - val_accuracy: 0.8903\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1556 - accuracy: 0.9513 - val_loss: 0.2776 - val_accuracy: 0.9000\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1454 - accuracy: 0.9500 - val_loss: 0.2823 - val_accuracy: 0.9000\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1391 - accuracy: 0.9613 - val_loss: 0.3117 - val_accuracy: 0.8797\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1419 - accuracy: 0.9525 - val_loss: 0.2675 - val_accuracy: 0.9056\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1255 - accuracy: 0.9638 - val_loss: 0.2569 - val_accuracy: 0.9097\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1163 - accuracy: 0.9700 - val_loss: 0.2539 - val_accuracy: 0.9131\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1146 - accuracy: 0.9725 - val_loss: 0.2657 - val_accuracy: 0.9059\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1006 - accuracy: 0.9750 - val_loss: 0.2558 - val_accuracy: 0.9106\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0974 - accuracy: 0.9812 - val_loss: 0.2539 - val_accuracy: 0.9125\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0894 - accuracy: 0.9812 - val_loss: 0.2620 - val_accuracy: 0.9081\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0859 - accuracy: 0.9800 - val_loss: 0.2486 - val_accuracy: 0.9150\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0800 - accuracy: 0.9875 - val_loss: 0.2408 - val_accuracy: 0.9184\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0761 - accuracy: 0.9862 - val_loss: 0.2441 - val_accuracy: 0.9153\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0714 - accuracy: 0.9900 - val_loss: 0.2465 - val_accuracy: 0.9162\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0682 - accuracy: 0.9912 - val_loss: 0.2368 - val_accuracy: 0.9194\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0645 - accuracy: 0.9925 - val_loss: 0.2323 - val_accuracy: 0.9212\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0631 - accuracy: 0.9875 - val_loss: 0.2481 - val_accuracy: 0.9159\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0576 - accuracy: 0.9925 - val_loss: 0.2321 - val_accuracy: 0.9216\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0529 - accuracy: 0.9937 - val_loss: 0.2327 - val_accuracy: 0.9197\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0499 - accuracy: 0.9937 - val_loss: 0.2289 - val_accuracy: 0.9212\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0463 - accuracy: 0.9937 - val_loss: 0.2242 - val_accuracy: 0.9231\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0443 - accuracy: 0.9950 - val_loss: 0.2205 - val_accuracy: 0.9241\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0442 - accuracy: 0.9937 - val_loss: 0.2351 - val_accuracy: 0.9194\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0411 - accuracy: 0.9962 - val_loss: 0.2208 - val_accuracy: 0.9237\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0374 - accuracy: 0.9962 - val_loss: 0.2157 - val_accuracy: 0.9272\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0366 - accuracy: 0.9937 - val_loss: 0.2163 - val_accuracy: 0.9306\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0355 - accuracy: 0.9950 - val_loss: 0.2329 - val_accuracy: 0.9222\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0336 - accuracy: 0.9962 - val_loss: 0.2184 - val_accuracy: 0.9291\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0304 - accuracy: 0.9962 - val_loss: 0.2167 - val_accuracy: 0.9278\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0279 - accuracy: 0.9987 - val_loss: 0.2136 - val_accuracy: 0.9275\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0264 - accuracy: 0.9987 - val_loss: 0.2143 - val_accuracy: 0.9278\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9331\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9322\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9312\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9312\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9337\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9287\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9344\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9337\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9356\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9344\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9362\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9341\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9372\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9344\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9372\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9356\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9362\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9372\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9375\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9372\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9391\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9359\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9384\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9378\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9381\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9391\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9384\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9381\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9378\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9394\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9391\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9388\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9394\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9397\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9394\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9397\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9397\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9391\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9397\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9403\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9391\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9400\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9403\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9400\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9406\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9406\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9400\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9400\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9400\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9413\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9403\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9403\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9406\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9406\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9413\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9416\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9409\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9409\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9409\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.1912 - accuracy: 0.9427\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_46 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_46 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 50ms/step - loss: 0.7012 - accuracy: 0.4725 - val_loss: 0.6951 - val_accuracy: 0.5238\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6927 - accuracy: 0.5238 - val_loss: 0.6899 - val_accuracy: 0.5544\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6872 - accuracy: 0.5562 - val_loss: 0.6857 - val_accuracy: 0.5809\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6823 - accuracy: 0.5788 - val_loss: 0.6821 - val_accuracy: 0.5934\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6779 - accuracy: 0.6000 - val_loss: 0.6792 - val_accuracy: 0.6044\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6734 - accuracy: 0.6137 - val_loss: 0.6759 - val_accuracy: 0.6037\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6687 - accuracy: 0.6263 - val_loss: 0.6725 - val_accuracy: 0.6059\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6636 - accuracy: 0.6263 - val_loss: 0.6689 - val_accuracy: 0.6147\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6583 - accuracy: 0.6400 - val_loss: 0.6647 - val_accuracy: 0.6263\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6522 - accuracy: 0.6550 - val_loss: 0.6597 - val_accuracy: 0.6363\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6450 - accuracy: 0.6687 - val_loss: 0.6539 - val_accuracy: 0.6450\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6368 - accuracy: 0.6862 - val_loss: 0.6466 - val_accuracy: 0.6550\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6271 - accuracy: 0.7000 - val_loss: 0.6380 - val_accuracy: 0.6725\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6154 - accuracy: 0.7075 - val_loss: 0.6266 - val_accuracy: 0.6884\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6011 - accuracy: 0.7212 - val_loss: 0.6125 - val_accuracy: 0.7009\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5834 - accuracy: 0.7412 - val_loss: 0.5944 - val_accuracy: 0.7231\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5622 - accuracy: 0.7600 - val_loss: 0.5719 - val_accuracy: 0.7472\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5371 - accuracy: 0.7788 - val_loss: 0.5479 - val_accuracy: 0.7772\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5091 - accuracy: 0.8025 - val_loss: 0.5183 - val_accuracy: 0.7919\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4783 - accuracy: 0.8225 - val_loss: 0.4889 - val_accuracy: 0.8053\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4490 - accuracy: 0.8363 - val_loss: 0.4632 - val_accuracy: 0.8159\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4203 - accuracy: 0.8450 - val_loss: 0.4441 - val_accuracy: 0.8338\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4010 - accuracy: 0.8462 - val_loss: 0.4227 - val_accuracy: 0.8356\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3700 - accuracy: 0.8775 - val_loss: 0.3953 - val_accuracy: 0.8494\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3459 - accuracy: 0.8900 - val_loss: 0.3777 - val_accuracy: 0.8569\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3281 - accuracy: 0.8925 - val_loss: 0.3630 - val_accuracy: 0.8616\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3140 - accuracy: 0.8950 - val_loss: 0.3607 - val_accuracy: 0.8650\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2940 - accuracy: 0.9075 - val_loss: 0.3380 - val_accuracy: 0.8744\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2804 - accuracy: 0.9125 - val_loss: 0.3293 - val_accuracy: 0.8781\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2675 - accuracy: 0.9162 - val_loss: 0.3181 - val_accuracy: 0.8834\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2565 - accuracy: 0.9187 - val_loss: 0.3204 - val_accuracy: 0.8838\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2432 - accuracy: 0.9287 - val_loss: 0.3084 - val_accuracy: 0.8913\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2297 - accuracy: 0.9300 - val_loss: 0.2901 - val_accuracy: 0.8972\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2224 - accuracy: 0.9275 - val_loss: 0.3032 - val_accuracy: 0.8909\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2062 - accuracy: 0.9362 - val_loss: 0.2781 - val_accuracy: 0.9003\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2005 - accuracy: 0.9388 - val_loss: 0.2647 - val_accuracy: 0.9072\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1919 - accuracy: 0.9450 - val_loss: 0.2592 - val_accuracy: 0.9087\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1755 - accuracy: 0.9538 - val_loss: 0.2532 - val_accuracy: 0.9112\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1620 - accuracy: 0.9575 - val_loss: 0.2410 - val_accuracy: 0.9172\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1496 - accuracy: 0.9588 - val_loss: 0.2291 - val_accuracy: 0.9187\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1406 - accuracy: 0.9638 - val_loss: 0.2202 - val_accuracy: 0.9231\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1340 - accuracy: 0.9650 - val_loss: 0.2154 - val_accuracy: 0.9241\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1301 - accuracy: 0.9650 - val_loss: 0.2068 - val_accuracy: 0.9287\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1195 - accuracy: 0.9688 - val_loss: 0.2015 - val_accuracy: 0.9303\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1090 - accuracy: 0.9787 - val_loss: 0.1926 - val_accuracy: 0.9328\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1018 - accuracy: 0.9787 - val_loss: 0.1885 - val_accuracy: 0.9359\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0992 - accuracy: 0.9775 - val_loss: 0.1832 - val_accuracy: 0.9391\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0941 - accuracy: 0.9775 - val_loss: 0.1767 - val_accuracy: 0.9406\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0858 - accuracy: 0.9825 - val_loss: 0.1740 - val_accuracy: 0.9431\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0815 - accuracy: 0.9837 - val_loss: 0.1726 - val_accuracy: 0.9438\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0768 - accuracy: 0.9875 - val_loss: 0.1672 - val_accuracy: 0.9453\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0725 - accuracy: 0.9862 - val_loss: 0.1643 - val_accuracy: 0.9488\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0685 - accuracy: 0.9875 - val_loss: 0.1598 - val_accuracy: 0.9491\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0657 - accuracy: 0.9875 - val_loss: 0.1587 - val_accuracy: 0.9484\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0613 - accuracy: 0.9937 - val_loss: 0.1558 - val_accuracy: 0.9506\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0575 - accuracy: 0.9925 - val_loss: 0.1540 - val_accuracy: 0.9522\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0560 - accuracy: 0.9925 - val_loss: 0.1499 - val_accuracy: 0.9531\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0522 - accuracy: 0.9925 - val_loss: 0.1460 - val_accuracy: 0.9550\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0501 - accuracy: 0.9925 - val_loss: 0.1429 - val_accuracy: 0.9566\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0459 - accuracy: 0.9937 - val_loss: 0.1436 - val_accuracy: 0.9553\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0439 - accuracy: 0.9925 - val_loss: 0.1464 - val_accuracy: 0.9559\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0427 - accuracy: 0.9937 - val_loss: 0.1517 - val_accuracy: 0.9550\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0462 - accuracy: 0.9900 - val_loss: 0.1495 - val_accuracy: 0.9544\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0430 - accuracy: 0.9925 - val_loss: 0.1392 - val_accuracy: 0.9594\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0365 - accuracy: 0.9937 - val_loss: 0.1396 - val_accuracy: 0.9584\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0340 - accuracy: 0.9937 - val_loss: 0.1372 - val_accuracy: 0.9581\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0316 - accuracy: 0.9962 - val_loss: 0.1360 - val_accuracy: 0.9588\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0299 - accuracy: 0.9950 - val_loss: 0.1353 - val_accuracy: 0.9591\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0320 - accuracy: 0.9950 - val_loss: 0.1394 - val_accuracy: 0.9578\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0281 - accuracy: 0.9962 - val_loss: 0.1341 - val_accuracy: 0.9613\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0248 - accuracy: 0.9975 - val_loss: 0.1357 - val_accuracy: 0.9597\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9581\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0238 - accuracy: 0.9987 - val_loss: 0.1358 - val_accuracy: 0.9609\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0244 - accuracy: 0.9962 - val_loss: 0.1326 - val_accuracy: 0.9616\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0209 - accuracy: 0.9987 - val_loss: 0.1389 - val_accuracy: 0.9591\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9625\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9628\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9625\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9625\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9634\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9638\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9641\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9644\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9638\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9644\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9644\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9644\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9647\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9647\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9650\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9644\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9644\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9650\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9641\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9647\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9647\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9653\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9656\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9650\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9656\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9656\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9653\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9653\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9653\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9644\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9650\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9653\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9653\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9656\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9656\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9650\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9650\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9653\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9653\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9653\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9656\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9653\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9656\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9653\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9653\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9653\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9653\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9650\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9653\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.1399 - accuracy: 0.9574\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_47 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_47 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 13)                1664      \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 50ms/step - loss: 0.6915 - accuracy: 0.5650 - val_loss: 0.6876 - val_accuracy: 0.5919\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6858 - accuracy: 0.5975 - val_loss: 0.6839 - val_accuracy: 0.6044\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6811 - accuracy: 0.6125 - val_loss: 0.6803 - val_accuracy: 0.6134\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6760 - accuracy: 0.6388 - val_loss: 0.6770 - val_accuracy: 0.6169\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6710 - accuracy: 0.6513 - val_loss: 0.6735 - val_accuracy: 0.6237\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6660 - accuracy: 0.6612 - val_loss: 0.6697 - val_accuracy: 0.6297\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6603 - accuracy: 0.6750 - val_loss: 0.6655 - val_accuracy: 0.6394\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6545 - accuracy: 0.6825 - val_loss: 0.6609 - val_accuracy: 0.6409\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6482 - accuracy: 0.6862 - val_loss: 0.6559 - val_accuracy: 0.6497\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6409 - accuracy: 0.6925 - val_loss: 0.6504 - val_accuracy: 0.6597\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6333 - accuracy: 0.6925 - val_loss: 0.6442 - val_accuracy: 0.6656\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6247 - accuracy: 0.6900 - val_loss: 0.6371 - val_accuracy: 0.6731\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6155 - accuracy: 0.6975 - val_loss: 0.6287 - val_accuracy: 0.6806\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.6041 - accuracy: 0.7175 - val_loss: 0.6190 - val_accuracy: 0.6919\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.5917 - accuracy: 0.7262 - val_loss: 0.6076 - val_accuracy: 0.7013\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5779 - accuracy: 0.7387 - val_loss: 0.5921 - val_accuracy: 0.7219\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5604 - accuracy: 0.7538 - val_loss: 0.5746 - val_accuracy: 0.7347\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5421 - accuracy: 0.7650 - val_loss: 0.5541 - val_accuracy: 0.7581\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5186 - accuracy: 0.7800 - val_loss: 0.5334 - val_accuracy: 0.7691\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4966 - accuracy: 0.7900 - val_loss: 0.5065 - val_accuracy: 0.7903\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4711 - accuracy: 0.8025 - val_loss: 0.4810 - val_accuracy: 0.8031\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.4445 - accuracy: 0.8138 - val_loss: 0.4521 - val_accuracy: 0.8228\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.4192 - accuracy: 0.8288 - val_loss: 0.4288 - val_accuracy: 0.8325\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3915 - accuracy: 0.8537 - val_loss: 0.3991 - val_accuracy: 0.8544\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3682 - accuracy: 0.8625 - val_loss: 0.3858 - val_accuracy: 0.8503\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3449 - accuracy: 0.8813 - val_loss: 0.3581 - val_accuracy: 0.8709\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3253 - accuracy: 0.8838 - val_loss: 0.3415 - val_accuracy: 0.8769\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3053 - accuracy: 0.8950 - val_loss: 0.3357 - val_accuracy: 0.8766\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2990 - accuracy: 0.8975 - val_loss: 0.3158 - val_accuracy: 0.8878\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2738 - accuracy: 0.9137 - val_loss: 0.2980 - val_accuracy: 0.8963\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2599 - accuracy: 0.9212 - val_loss: 0.2860 - val_accuracy: 0.9009\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2514 - accuracy: 0.9125 - val_loss: 0.2837 - val_accuracy: 0.9016\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2279 - accuracy: 0.9362 - val_loss: 0.2652 - val_accuracy: 0.9094\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2162 - accuracy: 0.9400 - val_loss: 0.2578 - val_accuracy: 0.9119\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1991 - accuracy: 0.9538 - val_loss: 0.2460 - val_accuracy: 0.9181\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1880 - accuracy: 0.9538 - val_loss: 0.2394 - val_accuracy: 0.9200\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1766 - accuracy: 0.9575 - val_loss: 0.2284 - val_accuracy: 0.9250\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1661 - accuracy: 0.9613 - val_loss: 0.2196 - val_accuracy: 0.9269\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1563 - accuracy: 0.9638 - val_loss: 0.2116 - val_accuracy: 0.9312\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1466 - accuracy: 0.9688 - val_loss: 0.2043 - val_accuracy: 0.9341\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1397 - accuracy: 0.9663 - val_loss: 0.2015 - val_accuracy: 0.9331\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1342 - accuracy: 0.9700 - val_loss: 0.2039 - val_accuracy: 0.9303\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1201 - accuracy: 0.9762 - val_loss: 0.1910 - val_accuracy: 0.9378\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1101 - accuracy: 0.9787 - val_loss: 0.1893 - val_accuracy: 0.9372\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1070 - accuracy: 0.9812 - val_loss: 0.1830 - val_accuracy: 0.9400\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0974 - accuracy: 0.9837 - val_loss: 0.1737 - val_accuracy: 0.9419\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0974 - accuracy: 0.9787 - val_loss: 0.1761 - val_accuracy: 0.9459\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0914 - accuracy: 0.9812 - val_loss: 0.1795 - val_accuracy: 0.9438\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0846 - accuracy: 0.9862 - val_loss: 0.1767 - val_accuracy: 0.9438\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0794 - accuracy: 0.9875 - val_loss: 0.1664 - val_accuracy: 0.9469\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0733 - accuracy: 0.9875 - val_loss: 0.1605 - val_accuracy: 0.9497\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0691 - accuracy: 0.9875 - val_loss: 0.1615 - val_accuracy: 0.9488\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0652 - accuracy: 0.9887 - val_loss: 0.1625 - val_accuracy: 0.9478\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0631 - accuracy: 0.9887 - val_loss: 0.1529 - val_accuracy: 0.9519\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0610 - accuracy: 0.9887 - val_loss: 0.1541 - val_accuracy: 0.9503\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0604 - accuracy: 0.9900 - val_loss: 0.1524 - val_accuracy: 0.9497\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0583 - accuracy: 0.9912 - val_loss: 0.1438 - val_accuracy: 0.9553\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0547 - accuracy: 0.9887 - val_loss: 0.1513 - val_accuracy: 0.9528\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0562 - accuracy: 0.9925 - val_loss: 0.1518 - val_accuracy: 0.9522\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0505 - accuracy: 0.9925 - val_loss: 0.1471 - val_accuracy: 0.9528\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0504 - accuracy: 0.9912 - val_loss: 0.1562 - val_accuracy: 0.9528\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0488 - accuracy: 0.9950 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0467 - accuracy: 0.9925 - val_loss: 0.1462 - val_accuracy: 0.9566\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0454 - accuracy: 0.9937 - val_loss: 0.1431 - val_accuracy: 0.9563\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0437 - accuracy: 0.9937 - val_loss: 0.1427 - val_accuracy: 0.9578\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0426 - accuracy: 0.9937 - val_loss: 0.1364 - val_accuracy: 0.9603\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0414 - accuracy: 0.9950 - val_loss: 0.1402 - val_accuracy: 0.9584\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0406 - accuracy: 0.9937 - val_loss: 0.1403 - val_accuracy: 0.9575\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0396 - accuracy: 0.9937 - val_loss: 0.1398 - val_accuracy: 0.9584\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0388 - accuracy: 0.9937 - val_loss: 0.1374 - val_accuracy: 0.9597\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0382 - accuracy: 0.9950 - val_loss: 0.1369 - val_accuracy: 0.9606\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0372 - accuracy: 0.9950 - val_loss: 0.1362 - val_accuracy: 0.9616\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0365 - accuracy: 0.9950 - val_loss: 0.1367 - val_accuracy: 0.9597\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0360 - accuracy: 0.9950 - val_loss: 0.1366 - val_accuracy: 0.9619\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0355 - accuracy: 0.9937 - val_loss: 0.1350 - val_accuracy: 0.9603\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0348 - accuracy: 0.9950 - val_loss: 0.1330 - val_accuracy: 0.9628\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0341 - accuracy: 0.9950 - val_loss: 0.1350 - val_accuracy: 0.9616\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0335 - accuracy: 0.9950 - val_loss: 0.1348 - val_accuracy: 0.9622\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0330 - accuracy: 0.9950 - val_loss: 0.1340 - val_accuracy: 0.9625\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0328 - accuracy: 0.9950 - val_loss: 0.1337 - val_accuracy: 0.9631\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0322 - accuracy: 0.9950 - val_loss: 0.1331 - val_accuracy: 0.9634\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0317 - accuracy: 0.9950 - val_loss: 0.1329 - val_accuracy: 0.9622\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0311 - accuracy: 0.9950 - val_loss: 0.1333 - val_accuracy: 0.9622\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 0.1309 - val_accuracy: 0.9625\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0303 - accuracy: 0.9950 - val_loss: 0.1305 - val_accuracy: 0.9634\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0299 - accuracy: 0.9950 - val_loss: 0.1308 - val_accuracy: 0.9631\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0292 - accuracy: 0.9950 - val_loss: 0.1299 - val_accuracy: 0.9638\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0288 - accuracy: 0.9950 - val_loss: 0.1293 - val_accuracy: 0.9641\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0283 - accuracy: 0.9950 - val_loss: 0.1297 - val_accuracy: 0.9650\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0279 - accuracy: 0.9950 - val_loss: 0.1273 - val_accuracy: 0.9650\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0293 - accuracy: 0.9937 - val_loss: 0.1481 - val_accuracy: 0.9569\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0324 - accuracy: 0.9937 - val_loss: 0.1822 - val_accuracy: 0.9481\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.1327 - val_accuracy: 0.9628\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0288 - accuracy: 0.9937 - val_loss: 0.1232 - val_accuracy: 0.9656\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0262 - accuracy: 0.9950 - val_loss: 0.1162 - val_accuracy: 0.9675\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0258 - accuracy: 0.9950 - val_loss: 0.1152 - val_accuracy: 0.9681\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0239 - accuracy: 0.9962 - val_loss: 0.1140 - val_accuracy: 0.9688\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0232 - accuracy: 0.9962 - val_loss: 0.1144 - val_accuracy: 0.9688\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 0.1164 - val_accuracy: 0.9678\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0203 - accuracy: 0.9975 - val_loss: 0.1165 - val_accuracy: 0.9675\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0184 - accuracy: 0.9987 - val_loss: 0.1185 - val_accuracy: 0.9684\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0193 - accuracy: 0.9975 - val_loss: 0.1405 - val_accuracy: 0.9603\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0221 - accuracy: 0.9975 - val_loss: 0.1079 - val_accuracy: 0.9725\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0170 - accuracy: 0.9987 - val_loss: 0.1139 - val_accuracy: 0.9694\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0167 - accuracy: 0.9987 - val_loss: 0.1145 - val_accuracy: 0.9697\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0155 - accuracy: 0.9987 - val_loss: 0.1192 - val_accuracy: 0.9681\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0150 - accuracy: 0.9987 - val_loss: 0.1164 - val_accuracy: 0.9700\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0145 - accuracy: 0.9987 - val_loss: 0.1176 - val_accuracy: 0.9688\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0139 - accuracy: 0.9987 - val_loss: 0.1158 - val_accuracy: 0.9691\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0135 - accuracy: 0.9987 - val_loss: 0.1155 - val_accuracy: 0.9688\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0129 - accuracy: 0.9987 - val_loss: 0.1143 - val_accuracy: 0.9703\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: 0.1156 - val_accuracy: 0.9703\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.1141 - val_accuracy: 0.9716\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.1157 - val_accuracy: 0.9716\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9719\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9725\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9719\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9722\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9728\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9728\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9731\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9737\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9725\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9722\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9716\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9725\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9722\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9719\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9716\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9709\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9728\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9716\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9719\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9719\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9716\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9719\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9709\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9722\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9709\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9709\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9709\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9709\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9709\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9709\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9709\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9706\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9709\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9703\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9709\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9703\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9706\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9703\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9709\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.1222 - accuracy: 0.9662\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......masking\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-26 22:27:33        49232\n",
      "config.json                                    2023-03-26 22:27:33         2358\n",
      "metadata.json                                  2023-03-26 22:27:33           64\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_48 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_48 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions_10 (Encode  (None, 22, 18)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_10 (Tra  (None, 22, 18)           1718      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_10 (Gl  (None, 18)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 32ms/step - loss: 1.3529 - accuracy: 0.4913 - val_loss: 1.1084 - val_accuracy: 0.4959\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9495 - accuracy: 0.5025 - val_loss: 0.8454 - val_accuracy: 0.5069\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7901 - accuracy: 0.5075 - val_loss: 0.7663 - val_accuracy: 0.5169\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7467 - accuracy: 0.5075 - val_loss: 0.7440 - val_accuracy: 0.5238\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7316 - accuracy: 0.5325 - val_loss: 0.7294 - val_accuracy: 0.5234\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7192 - accuracy: 0.5425 - val_loss: 0.7199 - val_accuracy: 0.5387\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7112 - accuracy: 0.5600 - val_loss: 0.7138 - val_accuracy: 0.5428\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7057 - accuracy: 0.5625 - val_loss: 0.7084 - val_accuracy: 0.5506\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7003 - accuracy: 0.5713 - val_loss: 0.7036 - val_accuracy: 0.5462\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6958 - accuracy: 0.5688 - val_loss: 0.6995 - val_accuracy: 0.5569\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6895 - accuracy: 0.5813 - val_loss: 0.6955 - val_accuracy: 0.5609\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6888 - accuracy: 0.5738 - val_loss: 0.6917 - val_accuracy: 0.5703\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6835 - accuracy: 0.5750 - val_loss: 0.6903 - val_accuracy: 0.5612\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6767 - accuracy: 0.6012 - val_loss: 0.6845 - val_accuracy: 0.5881\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6714 - accuracy: 0.5987 - val_loss: 0.6794 - val_accuracy: 0.5934\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6656 - accuracy: 0.6112 - val_loss: 0.6734 - val_accuracy: 0.6053\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6566 - accuracy: 0.6263 - val_loss: 0.6657 - val_accuracy: 0.6231\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6481 - accuracy: 0.6425 - val_loss: 0.6593 - val_accuracy: 0.6350\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6402 - accuracy: 0.6575 - val_loss: 0.6528 - val_accuracy: 0.6472\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6313 - accuracy: 0.6700 - val_loss: 0.6444 - val_accuracy: 0.6603\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6222 - accuracy: 0.6712 - val_loss: 0.6350 - val_accuracy: 0.6703\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6129 - accuracy: 0.6875 - val_loss: 0.6270 - val_accuracy: 0.6716\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6030 - accuracy: 0.6988 - val_loss: 0.6198 - val_accuracy: 0.6762\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5943 - accuracy: 0.7025 - val_loss: 0.6124 - val_accuracy: 0.6766\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5868 - accuracy: 0.7175 - val_loss: 0.6076 - val_accuracy: 0.6816\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5836 - accuracy: 0.7050 - val_loss: 0.6025 - val_accuracy: 0.6809\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5751 - accuracy: 0.7150 - val_loss: 0.5986 - val_accuracy: 0.6900\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5734 - accuracy: 0.7138 - val_loss: 0.5964 - val_accuracy: 0.6872\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5665 - accuracy: 0.7200 - val_loss: 0.5909 - val_accuracy: 0.6947\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5599 - accuracy: 0.7337 - val_loss: 0.5877 - val_accuracy: 0.6928\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5544 - accuracy: 0.7262 - val_loss: 0.5826 - val_accuracy: 0.7003\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5506 - accuracy: 0.7400 - val_loss: 0.5808 - val_accuracy: 0.6988\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5487 - accuracy: 0.7275 - val_loss: 0.5752 - val_accuracy: 0.7031\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5438 - accuracy: 0.7287 - val_loss: 0.5714 - val_accuracy: 0.7044\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5401 - accuracy: 0.7350 - val_loss: 0.5699 - val_accuracy: 0.7059\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5361 - accuracy: 0.7350 - val_loss: 0.5666 - val_accuracy: 0.7084\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5338 - accuracy: 0.7350 - val_loss: 0.5640 - val_accuracy: 0.7078\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5351 - accuracy: 0.7350 - val_loss: 0.5629 - val_accuracy: 0.7081\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5293 - accuracy: 0.7437 - val_loss: 0.5615 - val_accuracy: 0.7103\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5296 - accuracy: 0.7375 - val_loss: 0.5602 - val_accuracy: 0.7150\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5263 - accuracy: 0.7375 - val_loss: 0.5571 - val_accuracy: 0.7144\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5224 - accuracy: 0.7450 - val_loss: 0.5559 - val_accuracy: 0.7159\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5201 - accuracy: 0.7487 - val_loss: 0.5534 - val_accuracy: 0.7244\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5180 - accuracy: 0.7525 - val_loss: 0.5547 - val_accuracy: 0.7147\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5165 - accuracy: 0.7462 - val_loss: 0.5499 - val_accuracy: 0.7206\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5124 - accuracy: 0.7550 - val_loss: 0.5485 - val_accuracy: 0.7212\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5123 - accuracy: 0.7525 - val_loss: 0.5470 - val_accuracy: 0.7234\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5063 - accuracy: 0.7550 - val_loss: 0.5445 - val_accuracy: 0.7256\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5058 - accuracy: 0.7513 - val_loss: 0.5427 - val_accuracy: 0.7253\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5026 - accuracy: 0.7575 - val_loss: 0.5412 - val_accuracy: 0.7222\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5022 - accuracy: 0.7550 - val_loss: 0.5396 - val_accuracy: 0.7287\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5025 - accuracy: 0.7462 - val_loss: 0.5402 - val_accuracy: 0.7222\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4998 - accuracy: 0.7600 - val_loss: 0.5382 - val_accuracy: 0.7359\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4968 - accuracy: 0.7538 - val_loss: 0.5342 - val_accuracy: 0.7287\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4928 - accuracy: 0.7675 - val_loss: 0.5339 - val_accuracy: 0.7275\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4944 - accuracy: 0.7550 - val_loss: 0.5316 - val_accuracy: 0.7306\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4916 - accuracy: 0.7600 - val_loss: 0.5325 - val_accuracy: 0.7303\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4885 - accuracy: 0.7613 - val_loss: 0.5332 - val_accuracy: 0.7225\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4881 - accuracy: 0.7638 - val_loss: 0.5274 - val_accuracy: 0.7403\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4823 - accuracy: 0.7700 - val_loss: 0.5265 - val_accuracy: 0.7359\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4808 - accuracy: 0.7725 - val_loss: 0.5266 - val_accuracy: 0.7384\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4803 - accuracy: 0.7750 - val_loss: 0.5246 - val_accuracy: 0.7387\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4774 - accuracy: 0.7688 - val_loss: 0.5226 - val_accuracy: 0.7378\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4767 - accuracy: 0.7763 - val_loss: 0.5228 - val_accuracy: 0.7394\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4770 - accuracy: 0.7713 - val_loss: 0.5198 - val_accuracy: 0.7422\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4717 - accuracy: 0.7675 - val_loss: 0.5180 - val_accuracy: 0.7422\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4695 - accuracy: 0.7738 - val_loss: 0.5167 - val_accuracy: 0.7450\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4689 - accuracy: 0.7688 - val_loss: 0.5182 - val_accuracy: 0.7381\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4696 - accuracy: 0.7788 - val_loss: 0.5185 - val_accuracy: 0.7434\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4629 - accuracy: 0.7900 - val_loss: 0.5161 - val_accuracy: 0.7422\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4655 - accuracy: 0.7800 - val_loss: 0.5150 - val_accuracy: 0.7459\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4665 - accuracy: 0.7788 - val_loss: 0.5161 - val_accuracy: 0.7406\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4597 - accuracy: 0.7900 - val_loss: 0.5134 - val_accuracy: 0.7459\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4617 - accuracy: 0.7862 - val_loss: 0.5088 - val_accuracy: 0.7484\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4606 - accuracy: 0.7950 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4546 - accuracy: 0.7875 - val_loss: 0.5076 - val_accuracy: 0.7497\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4530 - accuracy: 0.7925 - val_loss: 0.5075 - val_accuracy: 0.7456\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4532 - accuracy: 0.7937 - val_loss: 0.5050 - val_accuracy: 0.7503\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4526 - accuracy: 0.7912 - val_loss: 0.5028 - val_accuracy: 0.7538\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4500 - accuracy: 0.7912 - val_loss: 0.5025 - val_accuracy: 0.7528\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4477 - accuracy: 0.7987 - val_loss: 0.5017 - val_accuracy: 0.7513\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4509 - accuracy: 0.7900 - val_loss: 0.5039 - val_accuracy: 0.7572\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4425 - accuracy: 0.8037 - val_loss: 0.4998 - val_accuracy: 0.7522\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4415 - accuracy: 0.8025 - val_loss: 0.5006 - val_accuracy: 0.7503\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4382 - accuracy: 0.8025 - val_loss: 0.5012 - val_accuracy: 0.7578\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4390 - accuracy: 0.8112 - val_loss: 0.4987 - val_accuracy: 0.7531\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4400 - accuracy: 0.8075 - val_loss: 0.4955 - val_accuracy: 0.7575\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4356 - accuracy: 0.8100 - val_loss: 0.4960 - val_accuracy: 0.7622\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4303 - accuracy: 0.8087 - val_loss: 0.4955 - val_accuracy: 0.7559\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4296 - accuracy: 0.8087 - val_loss: 0.4929 - val_accuracy: 0.7600\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4269 - accuracy: 0.8138 - val_loss: 0.4916 - val_accuracy: 0.7575\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4238 - accuracy: 0.8150 - val_loss: 0.4918 - val_accuracy: 0.7678\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4238 - accuracy: 0.8125 - val_loss: 0.4941 - val_accuracy: 0.7544\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4253 - accuracy: 0.8112 - val_loss: 0.4917 - val_accuracy: 0.7669\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4191 - accuracy: 0.8138 - val_loss: 0.4882 - val_accuracy: 0.7644\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4151 - accuracy: 0.8188 - val_loss: 0.4866 - val_accuracy: 0.7706\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4137 - accuracy: 0.8175 - val_loss: 0.4867 - val_accuracy: 0.7684\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4118 - accuracy: 0.8188 - val_loss: 0.4847 - val_accuracy: 0.7681\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4121 - accuracy: 0.8175 - val_loss: 0.4859 - val_accuracy: 0.7694\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4068 - accuracy: 0.8250 - val_loss: 0.4871 - val_accuracy: 0.7628\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4092 - accuracy: 0.8225 - val_loss: 0.4841 - val_accuracy: 0.7709\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4046 - accuracy: 0.8238 - val_loss: 0.4817 - val_accuracy: 0.7731\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4018 - accuracy: 0.8325 - val_loss: 0.4809 - val_accuracy: 0.7734\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3993 - accuracy: 0.8300 - val_loss: 0.4770 - val_accuracy: 0.7772\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3961 - accuracy: 0.8375 - val_loss: 0.4769 - val_accuracy: 0.7753\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3973 - accuracy: 0.8363 - val_loss: 0.4818 - val_accuracy: 0.7681\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3965 - accuracy: 0.8300 - val_loss: 0.4758 - val_accuracy: 0.7759\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3904 - accuracy: 0.8363 - val_loss: 0.4767 - val_accuracy: 0.7766\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3881 - accuracy: 0.8400 - val_loss: 0.4758 - val_accuracy: 0.7744\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3896 - accuracy: 0.8363 - val_loss: 0.4725 - val_accuracy: 0.7784\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3847 - accuracy: 0.8462 - val_loss: 0.4730 - val_accuracy: 0.7797\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3857 - accuracy: 0.8462 - val_loss: 0.4696 - val_accuracy: 0.7791\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3820 - accuracy: 0.8338 - val_loss: 0.4753 - val_accuracy: 0.7753\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3853 - accuracy: 0.8388 - val_loss: 0.4688 - val_accuracy: 0.7806\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3769 - accuracy: 0.8525 - val_loss: 0.4663 - val_accuracy: 0.7794\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3726 - accuracy: 0.8450 - val_loss: 0.4728 - val_accuracy: 0.7744\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3768 - accuracy: 0.8575 - val_loss: 0.4647 - val_accuracy: 0.7869\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3703 - accuracy: 0.8637 - val_loss: 0.4644 - val_accuracy: 0.7859\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3693 - accuracy: 0.8525 - val_loss: 0.4669 - val_accuracy: 0.7769\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3655 - accuracy: 0.8512 - val_loss: 0.4631 - val_accuracy: 0.7869\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3611 - accuracy: 0.8625 - val_loss: 0.4616 - val_accuracy: 0.7881\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3591 - accuracy: 0.8612 - val_loss: 0.4634 - val_accuracy: 0.7791\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3591 - accuracy: 0.8687 - val_loss: 0.4612 - val_accuracy: 0.7897\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3572 - accuracy: 0.8725 - val_loss: 0.4610 - val_accuracy: 0.7881\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3567 - accuracy: 0.8650 - val_loss: 0.4637 - val_accuracy: 0.7775\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3527 - accuracy: 0.8700 - val_loss: 0.4625 - val_accuracy: 0.7803\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3490 - accuracy: 0.8700 - val_loss: 0.4607 - val_accuracy: 0.7800\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3510 - accuracy: 0.8687 - val_loss: 0.4592 - val_accuracy: 0.7909\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3496 - accuracy: 0.8750 - val_loss: 0.4581 - val_accuracy: 0.7881\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3451 - accuracy: 0.8662 - val_loss: 0.4619 - val_accuracy: 0.7759\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3414 - accuracy: 0.8763 - val_loss: 0.4589 - val_accuracy: 0.7906\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3421 - accuracy: 0.8662 - val_loss: 0.4553 - val_accuracy: 0.7872\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3385 - accuracy: 0.8662 - val_loss: 0.4686 - val_accuracy: 0.7763\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3439 - accuracy: 0.8700 - val_loss: 0.4587 - val_accuracy: 0.7956\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3346 - accuracy: 0.8763 - val_loss: 0.4535 - val_accuracy: 0.7850\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3349 - accuracy: 0.8750 - val_loss: 0.4605 - val_accuracy: 0.7738\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3291 - accuracy: 0.8850 - val_loss: 0.4571 - val_accuracy: 0.7894\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3329 - accuracy: 0.8675 - val_loss: 0.4552 - val_accuracy: 0.7822\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3263 - accuracy: 0.8838 - val_loss: 0.4533 - val_accuracy: 0.7878\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3271 - accuracy: 0.8788 - val_loss: 0.4541 - val_accuracy: 0.7862\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3332 - accuracy: 0.8687 - val_loss: 0.4591 - val_accuracy: 0.7744\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3229 - accuracy: 0.8775 - val_loss: 0.4535 - val_accuracy: 0.7844\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3190 - accuracy: 0.8850 - val_loss: 0.4558 - val_accuracy: 0.7900\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3235 - accuracy: 0.8800 - val_loss: 0.4633 - val_accuracy: 0.7747\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3191 - accuracy: 0.8825 - val_loss: 0.4524 - val_accuracy: 0.7856\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3171 - accuracy: 0.8775 - val_loss: 0.4540 - val_accuracy: 0.7906\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3140 - accuracy: 0.8825 - val_loss: 0.4564 - val_accuracy: 0.7769\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3128 - accuracy: 0.8800 - val_loss: 0.4547 - val_accuracy: 0.7875\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3138 - accuracy: 0.8888 - val_loss: 0.4538 - val_accuracy: 0.7862\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3082 - accuracy: 0.8875 - val_loss: 0.4516 - val_accuracy: 0.7866\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3071 - accuracy: 0.8725 - val_loss: 0.4615 - val_accuracy: 0.7713\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3069 - accuracy: 0.8813 - val_loss: 0.4526 - val_accuracy: 0.7869\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3043 - accuracy: 0.8900 - val_loss: 0.4609 - val_accuracy: 0.7903\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3107 - accuracy: 0.8825 - val_loss: 0.4538 - val_accuracy: 0.7788\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2997 - accuracy: 0.8913 - val_loss: 0.4540 - val_accuracy: 0.7809\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2982 - accuracy: 0.8950 - val_loss: 0.4574 - val_accuracy: 0.7872\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2984 - accuracy: 0.8925 - val_loss: 0.4604 - val_accuracy: 0.7744\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2911 - accuracy: 0.9013 - val_loss: 0.4559 - val_accuracy: 0.7894\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2987 - accuracy: 0.8925 - val_loss: 0.4592 - val_accuracy: 0.7772\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2928 - accuracy: 0.8938 - val_loss: 0.4553 - val_accuracy: 0.7778\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2895 - accuracy: 0.8938 - val_loss: 0.4545 - val_accuracy: 0.7881\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2887 - accuracy: 0.8975 - val_loss: 0.4543 - val_accuracy: 0.7822\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2860 - accuracy: 0.9013 - val_loss: 0.4558 - val_accuracy: 0.7769\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2826 - accuracy: 0.8988 - val_loss: 0.4531 - val_accuracy: 0.7847\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2810 - accuracy: 0.8963 - val_loss: 0.4618 - val_accuracy: 0.7784\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2771 - accuracy: 0.9075 - val_loss: 0.4563 - val_accuracy: 0.7884\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2777 - accuracy: 0.8975 - val_loss: 0.4606 - val_accuracy: 0.7769\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2745 - accuracy: 0.9025 - val_loss: 0.4563 - val_accuracy: 0.7828\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2754 - accuracy: 0.9050 - val_loss: 0.4586 - val_accuracy: 0.7784\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2695 - accuracy: 0.9062 - val_loss: 0.4550 - val_accuracy: 0.7884\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2729 - accuracy: 0.9075 - val_loss: 0.4605 - val_accuracy: 0.7909\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2752 - accuracy: 0.9050 - val_loss: 0.4761 - val_accuracy: 0.7700\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2692 - accuracy: 0.9000 - val_loss: 0.4572 - val_accuracy: 0.7834\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2655 - accuracy: 0.9100 - val_loss: 0.4571 - val_accuracy: 0.7891\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2646 - accuracy: 0.9100 - val_loss: 0.4580 - val_accuracy: 0.7797\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2605 - accuracy: 0.9062 - val_loss: 0.4605 - val_accuracy: 0.7794\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2574 - accuracy: 0.9150 - val_loss: 0.4656 - val_accuracy: 0.7772\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2551 - accuracy: 0.9212 - val_loss: 0.4549 - val_accuracy: 0.7866\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2550 - accuracy: 0.9162 - val_loss: 0.4658 - val_accuracy: 0.7778\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2542 - accuracy: 0.9175 - val_loss: 0.4663 - val_accuracy: 0.7772\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2508 - accuracy: 0.9275 - val_loss: 0.4592 - val_accuracy: 0.7862\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2487 - accuracy: 0.9150 - val_loss: 0.4675 - val_accuracy: 0.7778\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2468 - accuracy: 0.9250 - val_loss: 0.4642 - val_accuracy: 0.7887\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2466 - accuracy: 0.9175 - val_loss: 0.4644 - val_accuracy: 0.7819\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2449 - accuracy: 0.9162 - val_loss: 0.4740 - val_accuracy: 0.7759\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2461 - accuracy: 0.9137 - val_loss: 0.4700 - val_accuracy: 0.7778\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2465 - accuracy: 0.9237 - val_loss: 0.4665 - val_accuracy: 0.7878\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2433 - accuracy: 0.9212 - val_loss: 0.4696 - val_accuracy: 0.7866\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2430 - accuracy: 0.9200 - val_loss: 0.4696 - val_accuracy: 0.7834\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2378 - accuracy: 0.9200 - val_loss: 0.4759 - val_accuracy: 0.7772\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2328 - accuracy: 0.9325 - val_loss: 0.4682 - val_accuracy: 0.7850\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2308 - accuracy: 0.9237 - val_loss: 0.4821 - val_accuracy: 0.7747\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2307 - accuracy: 0.9275 - val_loss: 0.4709 - val_accuracy: 0.7881\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2276 - accuracy: 0.9262 - val_loss: 0.4806 - val_accuracy: 0.7741\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2288 - accuracy: 0.9350 - val_loss: 0.4715 - val_accuracy: 0.7875\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2267 - accuracy: 0.9300 - val_loss: 0.4817 - val_accuracy: 0.7731\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2247 - accuracy: 0.9337 - val_loss: 0.4730 - val_accuracy: 0.7900\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2195 - accuracy: 0.9325 - val_loss: 0.4780 - val_accuracy: 0.7859\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2246 - accuracy: 0.9300 - val_loss: 0.4989 - val_accuracy: 0.7744\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2251 - accuracy: 0.9300 - val_loss: 0.4799 - val_accuracy: 0.7844\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.4650 - accuracy: 0.7814\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_49 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_49 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions_11 (Encode  (None, 22, 18)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_11 (Tra  (None, 22, 18)           1718      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_11 (Gl  (None, 18)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 32ms/step - loss: 0.8795 - accuracy: 0.5250 - val_loss: 0.7860 - val_accuracy: 0.5506\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.7699 - accuracy: 0.5587 - val_loss: 0.7412 - val_accuracy: 0.5459\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7421 - accuracy: 0.5512 - val_loss: 0.7151 - val_accuracy: 0.5581\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7136 - accuracy: 0.5863 - val_loss: 0.6962 - val_accuracy: 0.5888\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6961 - accuracy: 0.6125 - val_loss: 0.6810 - val_accuracy: 0.6044\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6809 - accuracy: 0.6212 - val_loss: 0.6676 - val_accuracy: 0.6253\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6659 - accuracy: 0.6500 - val_loss: 0.6527 - val_accuracy: 0.6466\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6520 - accuracy: 0.6488 - val_loss: 0.6377 - val_accuracy: 0.6744\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6340 - accuracy: 0.6762 - val_loss: 0.6247 - val_accuracy: 0.6891\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6194 - accuracy: 0.6900 - val_loss: 0.6109 - val_accuracy: 0.6866\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6031 - accuracy: 0.6963 - val_loss: 0.5985 - val_accuracy: 0.6925\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5916 - accuracy: 0.7050 - val_loss: 0.5912 - val_accuracy: 0.7022\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5811 - accuracy: 0.7075 - val_loss: 0.5845 - val_accuracy: 0.7031\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5731 - accuracy: 0.7113 - val_loss: 0.5787 - val_accuracy: 0.7063\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5669 - accuracy: 0.7188 - val_loss: 0.5742 - val_accuracy: 0.7059\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5620 - accuracy: 0.7200 - val_loss: 0.5706 - val_accuracy: 0.7063\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5543 - accuracy: 0.7262 - val_loss: 0.5676 - val_accuracy: 0.7013\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5495 - accuracy: 0.7212 - val_loss: 0.5637 - val_accuracy: 0.7081\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5425 - accuracy: 0.7350 - val_loss: 0.5570 - val_accuracy: 0.7188\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5351 - accuracy: 0.7450 - val_loss: 0.5543 - val_accuracy: 0.7159\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5269 - accuracy: 0.7500 - val_loss: 0.5496 - val_accuracy: 0.7216\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5238 - accuracy: 0.7387 - val_loss: 0.5489 - val_accuracy: 0.7203\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5201 - accuracy: 0.7538 - val_loss: 0.5450 - val_accuracy: 0.7222\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5180 - accuracy: 0.7500 - val_loss: 0.5412 - val_accuracy: 0.7312\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5075 - accuracy: 0.7462 - val_loss: 0.5362 - val_accuracy: 0.7300\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5063 - accuracy: 0.7487 - val_loss: 0.5351 - val_accuracy: 0.7319\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4998 - accuracy: 0.7563 - val_loss: 0.5315 - val_accuracy: 0.7353\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4988 - accuracy: 0.7613 - val_loss: 0.5282 - val_accuracy: 0.7387\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4970 - accuracy: 0.7600 - val_loss: 0.5243 - val_accuracy: 0.7444\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4880 - accuracy: 0.7738 - val_loss: 0.5215 - val_accuracy: 0.7459\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4851 - accuracy: 0.7663 - val_loss: 0.5216 - val_accuracy: 0.7456\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4822 - accuracy: 0.7713 - val_loss: 0.5181 - val_accuracy: 0.7538\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4854 - accuracy: 0.7650 - val_loss: 0.5227 - val_accuracy: 0.7397\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4799 - accuracy: 0.7688 - val_loss: 0.5160 - val_accuracy: 0.7575\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4747 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7456\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.5124 - val_accuracy: 0.7559\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4690 - accuracy: 0.7763 - val_loss: 0.5108 - val_accuracy: 0.7594\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4667 - accuracy: 0.7750 - val_loss: 0.5103 - val_accuracy: 0.7563\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.5051 - val_accuracy: 0.7641\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4622 - accuracy: 0.7837 - val_loss: 0.5058 - val_accuracy: 0.7575\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7625\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4530 - accuracy: 0.7900 - val_loss: 0.5082 - val_accuracy: 0.7566\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4547 - accuracy: 0.7950 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4481 - accuracy: 0.7912 - val_loss: 0.5009 - val_accuracy: 0.7628\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4519 - accuracy: 0.7975 - val_loss: 0.5006 - val_accuracy: 0.7622\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4506 - accuracy: 0.7850 - val_loss: 0.5020 - val_accuracy: 0.7619\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4455 - accuracy: 0.8062 - val_loss: 0.4956 - val_accuracy: 0.7725\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4427 - accuracy: 0.7862 - val_loss: 0.4935 - val_accuracy: 0.7669\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4376 - accuracy: 0.8050 - val_loss: 0.4967 - val_accuracy: 0.7650\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4407 - accuracy: 0.8037 - val_loss: 0.4915 - val_accuracy: 0.7703\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4379 - accuracy: 0.7975 - val_loss: 0.4989 - val_accuracy: 0.7584\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4419 - accuracy: 0.7887 - val_loss: 0.4909 - val_accuracy: 0.7678\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4281 - accuracy: 0.8150 - val_loss: 0.4995 - val_accuracy: 0.7559\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4293 - accuracy: 0.8100 - val_loss: 0.4881 - val_accuracy: 0.7694\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4201 - accuracy: 0.8138 - val_loss: 0.4854 - val_accuracy: 0.7728\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4236 - accuracy: 0.8062 - val_loss: 0.4878 - val_accuracy: 0.7669\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4299 - accuracy: 0.8225 - val_loss: 0.4883 - val_accuracy: 0.7684\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4223 - accuracy: 0.7950 - val_loss: 0.4803 - val_accuracy: 0.7756\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4131 - accuracy: 0.8138 - val_loss: 0.4886 - val_accuracy: 0.7613\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4120 - accuracy: 0.8175 - val_loss: 0.4833 - val_accuracy: 0.7681\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.4820 - val_accuracy: 0.7722\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4084 - accuracy: 0.8200 - val_loss: 0.4816 - val_accuracy: 0.7713\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4075 - accuracy: 0.8163 - val_loss: 0.4752 - val_accuracy: 0.7763\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4027 - accuracy: 0.8288 - val_loss: 0.4829 - val_accuracy: 0.7691\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4047 - accuracy: 0.8288 - val_loss: 0.4785 - val_accuracy: 0.7741\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4011 - accuracy: 0.8188 - val_loss: 0.4829 - val_accuracy: 0.7681\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4056 - accuracy: 0.8138 - val_loss: 0.4907 - val_accuracy: 0.7697\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4068 - accuracy: 0.8213 - val_loss: 0.4896 - val_accuracy: 0.7709\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3999 - accuracy: 0.8188 - val_loss: 0.4727 - val_accuracy: 0.7750\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3977 - accuracy: 0.8125 - val_loss: 0.4779 - val_accuracy: 0.7738\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3954 - accuracy: 0.8250 - val_loss: 0.4972 - val_accuracy: 0.7613\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3947 - accuracy: 0.8062 - val_loss: 0.4718 - val_accuracy: 0.7747\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3914 - accuracy: 0.8288 - val_loss: 0.4836 - val_accuracy: 0.7741\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3886 - accuracy: 0.8238 - val_loss: 0.4693 - val_accuracy: 0.7728\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3850 - accuracy: 0.8300 - val_loss: 0.4811 - val_accuracy: 0.7784\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3862 - accuracy: 0.8275 - val_loss: 0.4696 - val_accuracy: 0.7788\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3881 - accuracy: 0.8225 - val_loss: 0.4692 - val_accuracy: 0.7769\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3830 - accuracy: 0.8263 - val_loss: 0.4732 - val_accuracy: 0.7772\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3811 - accuracy: 0.8275 - val_loss: 0.4836 - val_accuracy: 0.7750\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3733 - accuracy: 0.8263 - val_loss: 0.4646 - val_accuracy: 0.7831\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3709 - accuracy: 0.8325 - val_loss: 0.4676 - val_accuracy: 0.7831\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3711 - accuracy: 0.8300 - val_loss: 0.4844 - val_accuracy: 0.7775\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3704 - accuracy: 0.8275 - val_loss: 0.4654 - val_accuracy: 0.7784\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3641 - accuracy: 0.8413 - val_loss: 0.4694 - val_accuracy: 0.7844\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3675 - accuracy: 0.8313 - val_loss: 0.4653 - val_accuracy: 0.7825\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3678 - accuracy: 0.8275 - val_loss: 0.4822 - val_accuracy: 0.7769\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3654 - accuracy: 0.8313 - val_loss: 0.4582 - val_accuracy: 0.7881\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3621 - accuracy: 0.8413 - val_loss: 0.4638 - val_accuracy: 0.7825\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3601 - accuracy: 0.8313 - val_loss: 0.4634 - val_accuracy: 0.7794\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3530 - accuracy: 0.8400 - val_loss: 0.4478 - val_accuracy: 0.7928\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3494 - accuracy: 0.8413 - val_loss: 0.4655 - val_accuracy: 0.7841\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3489 - accuracy: 0.8375 - val_loss: 0.4676 - val_accuracy: 0.7812\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3453 - accuracy: 0.8550 - val_loss: 0.4634 - val_accuracy: 0.7850\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3516 - accuracy: 0.8425 - val_loss: 0.4506 - val_accuracy: 0.7887\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3496 - accuracy: 0.8400 - val_loss: 0.4613 - val_accuracy: 0.7822\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3383 - accuracy: 0.8475 - val_loss: 0.4586 - val_accuracy: 0.7803\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3372 - accuracy: 0.8500 - val_loss: 0.4579 - val_accuracy: 0.7884\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3380 - accuracy: 0.8475 - val_loss: 0.4520 - val_accuracy: 0.7878\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3294 - accuracy: 0.8600 - val_loss: 0.4457 - val_accuracy: 0.7916\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3344 - accuracy: 0.8462 - val_loss: 0.4487 - val_accuracy: 0.7859\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3248 - accuracy: 0.8512 - val_loss: 0.4421 - val_accuracy: 0.7947\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3284 - accuracy: 0.8650 - val_loss: 0.4621 - val_accuracy: 0.7834\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3252 - accuracy: 0.8575 - val_loss: 0.4505 - val_accuracy: 0.7859\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3161 - accuracy: 0.8612 - val_loss: 0.4709 - val_accuracy: 0.7841\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3187 - accuracy: 0.8662 - val_loss: 0.4583 - val_accuracy: 0.7853\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3290 - accuracy: 0.8512 - val_loss: 0.4758 - val_accuracy: 0.7825\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3218 - accuracy: 0.8625 - val_loss: 0.4508 - val_accuracy: 0.7925\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3160 - accuracy: 0.8662 - val_loss: 0.4483 - val_accuracy: 0.7875\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3122 - accuracy: 0.8625 - val_loss: 0.4636 - val_accuracy: 0.7859\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3038 - accuracy: 0.8700 - val_loss: 0.4480 - val_accuracy: 0.7891\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3040 - accuracy: 0.8725 - val_loss: 0.4507 - val_accuracy: 0.7872\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3019 - accuracy: 0.8725 - val_loss: 0.4749 - val_accuracy: 0.7837\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3064 - accuracy: 0.8700 - val_loss: 0.4391 - val_accuracy: 0.7897\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3016 - accuracy: 0.8737 - val_loss: 0.4432 - val_accuracy: 0.7900\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2921 - accuracy: 0.8737 - val_loss: 0.4530 - val_accuracy: 0.7906\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2905 - accuracy: 0.8775 - val_loss: 0.4325 - val_accuracy: 0.7962\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2901 - accuracy: 0.8775 - val_loss: 0.4326 - val_accuracy: 0.7994\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2872 - accuracy: 0.8875 - val_loss: 0.4620 - val_accuracy: 0.7834\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2870 - accuracy: 0.8875 - val_loss: 0.4516 - val_accuracy: 0.7897\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2834 - accuracy: 0.8763 - val_loss: 0.4517 - val_accuracy: 0.7887\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2760 - accuracy: 0.8863 - val_loss: 0.4455 - val_accuracy: 0.7931\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2785 - accuracy: 0.8875 - val_loss: 0.4460 - val_accuracy: 0.7906\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2939 - accuracy: 0.8825 - val_loss: 0.4409 - val_accuracy: 0.7962\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2885 - accuracy: 0.8825 - val_loss: 0.4362 - val_accuracy: 0.8006\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2664 - accuracy: 0.8925 - val_loss: 0.4440 - val_accuracy: 0.7978\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2605 - accuracy: 0.9000 - val_loss: 0.4293 - val_accuracy: 0.8059\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2620 - accuracy: 0.8950 - val_loss: 0.4311 - val_accuracy: 0.8022\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2561 - accuracy: 0.8938 - val_loss: 0.4355 - val_accuracy: 0.8053\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2612 - accuracy: 0.8888 - val_loss: 0.4221 - val_accuracy: 0.8062\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2961 - accuracy: 0.8750 - val_loss: 0.4490 - val_accuracy: 0.7966\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2781 - accuracy: 0.8712 - val_loss: 0.4294 - val_accuracy: 0.8028\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2561 - accuracy: 0.8950 - val_loss: 0.4323 - val_accuracy: 0.7969\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2561 - accuracy: 0.8975 - val_loss: 0.4216 - val_accuracy: 0.8056\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2455 - accuracy: 0.9013 - val_loss: 0.4329 - val_accuracy: 0.8109\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2650 - accuracy: 0.8875 - val_loss: 0.4305 - val_accuracy: 0.8037\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2565 - accuracy: 0.8888 - val_loss: 0.4286 - val_accuracy: 0.8106\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2370 - accuracy: 0.9038 - val_loss: 0.4211 - val_accuracy: 0.8138\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2306 - accuracy: 0.9025 - val_loss: 0.4208 - val_accuracy: 0.8128\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2305 - accuracy: 0.9125 - val_loss: 0.4195 - val_accuracy: 0.8178\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2507 - accuracy: 0.8975 - val_loss: 0.4352 - val_accuracy: 0.8144\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2275 - accuracy: 0.9087 - val_loss: 0.4011 - val_accuracy: 0.8316\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2241 - accuracy: 0.9125 - val_loss: 0.4145 - val_accuracy: 0.8200\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2254 - accuracy: 0.9125 - val_loss: 0.4337 - val_accuracy: 0.8103\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2467 - accuracy: 0.8913 - val_loss: 0.4071 - val_accuracy: 0.8313\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2417 - accuracy: 0.8975 - val_loss: 0.4065 - val_accuracy: 0.8278\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2304 - accuracy: 0.9038 - val_loss: 0.4062 - val_accuracy: 0.8244\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2034 - accuracy: 0.9275 - val_loss: 0.4043 - val_accuracy: 0.8378\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2205 - accuracy: 0.9050 - val_loss: 0.4031 - val_accuracy: 0.8363\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2005 - accuracy: 0.9212 - val_loss: 0.3849 - val_accuracy: 0.8409\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.4118 - val_accuracy: 0.8322\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2070 - accuracy: 0.9100 - val_loss: 0.3953 - val_accuracy: 0.8413\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2058 - accuracy: 0.9275 - val_loss: 0.3993 - val_accuracy: 0.8428\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2069 - accuracy: 0.9075 - val_loss: 0.3812 - val_accuracy: 0.8453\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1814 - accuracy: 0.9275 - val_loss: 0.3813 - val_accuracy: 0.8497\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1719 - accuracy: 0.9388 - val_loss: 0.3791 - val_accuracy: 0.8534\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1645 - accuracy: 0.9413 - val_loss: 0.3816 - val_accuracy: 0.8544\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1672 - accuracy: 0.9388 - val_loss: 0.3850 - val_accuracy: 0.8584\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1838 - accuracy: 0.9225 - val_loss: 0.3995 - val_accuracy: 0.8441\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1725 - accuracy: 0.9337 - val_loss: 0.3720 - val_accuracy: 0.8631\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1517 - accuracy: 0.9400 - val_loss: 0.3725 - val_accuracy: 0.8572\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1500 - accuracy: 0.9450 - val_loss: 0.3858 - val_accuracy: 0.8556\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1499 - accuracy: 0.9400 - val_loss: 0.3850 - val_accuracy: 0.8575\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1510 - accuracy: 0.9312 - val_loss: 0.3735 - val_accuracy: 0.8581\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1561 - accuracy: 0.9388 - val_loss: 0.3906 - val_accuracy: 0.8575\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1491 - accuracy: 0.9400 - val_loss: 0.3803 - val_accuracy: 0.8581\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1449 - accuracy: 0.9450 - val_loss: 0.4033 - val_accuracy: 0.8531\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1490 - accuracy: 0.9513 - val_loss: 0.3941 - val_accuracy: 0.8619\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1409 - accuracy: 0.9375 - val_loss: 0.3838 - val_accuracy: 0.8584\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1338 - accuracy: 0.9575 - val_loss: 0.3883 - val_accuracy: 0.8616\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1339 - accuracy: 0.9513 - val_loss: 0.3888 - val_accuracy: 0.8547\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1561 - accuracy: 0.9325 - val_loss: 0.3761 - val_accuracy: 0.8625\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1390 - accuracy: 0.9500 - val_loss: 0.4070 - val_accuracy: 0.8497\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1462 - accuracy: 0.9425 - val_loss: 0.3862 - val_accuracy: 0.8581\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1330 - accuracy: 0.9450 - val_loss: 0.3906 - val_accuracy: 0.8622\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1358 - accuracy: 0.9413 - val_loss: 0.3867 - val_accuracy: 0.8556\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1251 - accuracy: 0.9575 - val_loss: 0.3930 - val_accuracy: 0.8634\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1207 - accuracy: 0.9613 - val_loss: 0.3869 - val_accuracy: 0.8597\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1217 - accuracy: 0.9500 - val_loss: 0.3820 - val_accuracy: 0.8603\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1169 - accuracy: 0.9638 - val_loss: 0.4109 - val_accuracy: 0.8562\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1183 - accuracy: 0.9538 - val_loss: 0.3845 - val_accuracy: 0.8606\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1147 - accuracy: 0.9588 - val_loss: 0.3939 - val_accuracy: 0.8591\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1186 - accuracy: 0.9563 - val_loss: 0.4019 - val_accuracy: 0.8562\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1205 - accuracy: 0.9525 - val_loss: 0.3989 - val_accuracy: 0.8631\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1180 - accuracy: 0.9575 - val_loss: 0.4121 - val_accuracy: 0.8512\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1164 - accuracy: 0.9538 - val_loss: 0.4006 - val_accuracy: 0.8603\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1159 - accuracy: 0.9588 - val_loss: 0.4058 - val_accuracy: 0.8581\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1147 - accuracy: 0.9600 - val_loss: 0.4010 - val_accuracy: 0.8575\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1143 - accuracy: 0.9638 - val_loss: 0.4023 - val_accuracy: 0.8622\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1227 - accuracy: 0.9550 - val_loss: 0.3947 - val_accuracy: 0.8584\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1161 - accuracy: 0.9588 - val_loss: 0.4063 - val_accuracy: 0.8572\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1084 - accuracy: 0.9688 - val_loss: 0.3952 - val_accuracy: 0.8559\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1046 - accuracy: 0.9613 - val_loss: 0.4096 - val_accuracy: 0.8609\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1070 - accuracy: 0.9613 - val_loss: 0.3933 - val_accuracy: 0.8631\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0986 - accuracy: 0.9625 - val_loss: 0.3924 - val_accuracy: 0.8625\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1024 - accuracy: 0.9700 - val_loss: 0.3957 - val_accuracy: 0.8622\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1169 - accuracy: 0.9513 - val_loss: 0.3882 - val_accuracy: 0.8641\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1016 - accuracy: 0.9625 - val_loss: 0.4049 - val_accuracy: 0.8641\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1075 - accuracy: 0.9638 - val_loss: 0.3917 - val_accuracy: 0.8644\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1032 - accuracy: 0.9625 - val_loss: 0.3920 - val_accuracy: 0.8628\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0965 - accuracy: 0.9650 - val_loss: 0.4024 - val_accuracy: 0.8647\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.4107 - accuracy: 0.8633\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_50 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_50 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions_12 (Encode  (None, 22, 18)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_12 (Tra  (None, 22, 18)           1718      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_12 (Gl  (None, 18)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 32ms/step - loss: 0.9717 - accuracy: 0.5000 - val_loss: 0.8629 - val_accuracy: 0.5063\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.8240 - accuracy: 0.5250 - val_loss: 0.8211 - val_accuracy: 0.5222\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7844 - accuracy: 0.5450 - val_loss: 0.7770 - val_accuracy: 0.5256\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7512 - accuracy: 0.5512 - val_loss: 0.7454 - val_accuracy: 0.5362\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7257 - accuracy: 0.5587 - val_loss: 0.7223 - val_accuracy: 0.5587\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7064 - accuracy: 0.5763 - val_loss: 0.7043 - val_accuracy: 0.5697\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6912 - accuracy: 0.5863 - val_loss: 0.6902 - val_accuracy: 0.5928\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6792 - accuracy: 0.6075 - val_loss: 0.6794 - val_accuracy: 0.6116\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6690 - accuracy: 0.6250 - val_loss: 0.6704 - val_accuracy: 0.6253\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6600 - accuracy: 0.6350 - val_loss: 0.6617 - val_accuracy: 0.6241\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6511 - accuracy: 0.6587 - val_loss: 0.6536 - val_accuracy: 0.6500\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6417 - accuracy: 0.6737 - val_loss: 0.6462 - val_accuracy: 0.6550\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6341 - accuracy: 0.6800 - val_loss: 0.6382 - val_accuracy: 0.6637\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6266 - accuracy: 0.6825 - val_loss: 0.6307 - val_accuracy: 0.6800\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6190 - accuracy: 0.6963 - val_loss: 0.6230 - val_accuracy: 0.6869\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6101 - accuracy: 0.7100 - val_loss: 0.6143 - val_accuracy: 0.7019\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6014 - accuracy: 0.7125 - val_loss: 0.6054 - val_accuracy: 0.7091\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5913 - accuracy: 0.7200 - val_loss: 0.5958 - val_accuracy: 0.7169\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5819 - accuracy: 0.7300 - val_loss: 0.5855 - val_accuracy: 0.7231\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5713 - accuracy: 0.7475 - val_loss: 0.5764 - val_accuracy: 0.7197\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5627 - accuracy: 0.7362 - val_loss: 0.5667 - val_accuracy: 0.7387\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5532 - accuracy: 0.7425 - val_loss: 0.5563 - val_accuracy: 0.7275\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5405 - accuracy: 0.7412 - val_loss: 0.5503 - val_accuracy: 0.7466\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5341 - accuracy: 0.7412 - val_loss: 0.5381 - val_accuracy: 0.7444\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5248 - accuracy: 0.7575 - val_loss: 0.5322 - val_accuracy: 0.7406\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5152 - accuracy: 0.7688 - val_loss: 0.5248 - val_accuracy: 0.7503\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5060 - accuracy: 0.7725 - val_loss: 0.5270 - val_accuracy: 0.7316\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5135 - accuracy: 0.7538 - val_loss: 0.5124 - val_accuracy: 0.7547\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4971 - accuracy: 0.7675 - val_loss: 0.5069 - val_accuracy: 0.7628\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4863 - accuracy: 0.7763 - val_loss: 0.4990 - val_accuracy: 0.7634\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4749 - accuracy: 0.7912 - val_loss: 0.4908 - val_accuracy: 0.7647\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4648 - accuracy: 0.8012 - val_loss: 0.4847 - val_accuracy: 0.7691\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4602 - accuracy: 0.7875 - val_loss: 0.5039 - val_accuracy: 0.7550\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4574 - accuracy: 0.7900 - val_loss: 0.4769 - val_accuracy: 0.7744\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4456 - accuracy: 0.8012 - val_loss: 0.4757 - val_accuracy: 0.7703\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4457 - accuracy: 0.7825 - val_loss: 0.4667 - val_accuracy: 0.7756\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4374 - accuracy: 0.8075 - val_loss: 0.4620 - val_accuracy: 0.7800\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4254 - accuracy: 0.8075 - val_loss: 0.4580 - val_accuracy: 0.7837\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4193 - accuracy: 0.8138 - val_loss: 0.4617 - val_accuracy: 0.7841\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4182 - accuracy: 0.8163 - val_loss: 0.4944 - val_accuracy: 0.7550\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4161 - accuracy: 0.8175 - val_loss: 0.4437 - val_accuracy: 0.7894\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4014 - accuracy: 0.8112 - val_loss: 0.4388 - val_accuracy: 0.7972\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3911 - accuracy: 0.8188 - val_loss: 0.4476 - val_accuracy: 0.7925\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3833 - accuracy: 0.8313 - val_loss: 0.4225 - val_accuracy: 0.8047\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3839 - accuracy: 0.8338 - val_loss: 0.4187 - val_accuracy: 0.8075\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3747 - accuracy: 0.8388 - val_loss: 0.4103 - val_accuracy: 0.8141\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3660 - accuracy: 0.8413 - val_loss: 0.4129 - val_accuracy: 0.8122\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3678 - accuracy: 0.8500 - val_loss: 0.4074 - val_accuracy: 0.8175\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3537 - accuracy: 0.8512 - val_loss: 0.4032 - val_accuracy: 0.8181\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3575 - accuracy: 0.8462 - val_loss: 0.4216 - val_accuracy: 0.8078\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3869 - accuracy: 0.8388 - val_loss: 0.4112 - val_accuracy: 0.8103\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3727 - accuracy: 0.8375 - val_loss: 0.3967 - val_accuracy: 0.8259\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3562 - accuracy: 0.8475 - val_loss: 0.4156 - val_accuracy: 0.8166\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3397 - accuracy: 0.8550 - val_loss: 0.3936 - val_accuracy: 0.8278\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3378 - accuracy: 0.8625 - val_loss: 0.3893 - val_accuracy: 0.8291\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3316 - accuracy: 0.8587 - val_loss: 0.3984 - val_accuracy: 0.8188\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3582 - accuracy: 0.8425 - val_loss: 0.4403 - val_accuracy: 0.8016\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3973 - accuracy: 0.8288 - val_loss: 0.4503 - val_accuracy: 0.7937\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3500 - accuracy: 0.8475 - val_loss: 0.4059 - val_accuracy: 0.8175\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3429 - accuracy: 0.8487 - val_loss: 0.3870 - val_accuracy: 0.8263\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3321 - accuracy: 0.8575 - val_loss: 0.3860 - val_accuracy: 0.8297\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3397 - accuracy: 0.8575 - val_loss: 0.4018 - val_accuracy: 0.8250\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3425 - accuracy: 0.8562 - val_loss: 0.4251 - val_accuracy: 0.8047\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3374 - accuracy: 0.8562 - val_loss: 0.3855 - val_accuracy: 0.8278\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3187 - accuracy: 0.8700 - val_loss: 0.3803 - val_accuracy: 0.8288\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3123 - accuracy: 0.8687 - val_loss: 0.3795 - val_accuracy: 0.8278\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3112 - accuracy: 0.8650 - val_loss: 0.3893 - val_accuracy: 0.8281\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3040 - accuracy: 0.8675 - val_loss: 0.3739 - val_accuracy: 0.8303\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3028 - accuracy: 0.8700 - val_loss: 0.3761 - val_accuracy: 0.8328\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3110 - accuracy: 0.8675 - val_loss: 0.3752 - val_accuracy: 0.8309\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3010 - accuracy: 0.8725 - val_loss: 0.3703 - val_accuracy: 0.8344\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2985 - accuracy: 0.8700 - val_loss: 0.3724 - val_accuracy: 0.8309\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3002 - accuracy: 0.8763 - val_loss: 0.3936 - val_accuracy: 0.8228\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3051 - accuracy: 0.8737 - val_loss: 0.3954 - val_accuracy: 0.8256\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2991 - accuracy: 0.8712 - val_loss: 0.3713 - val_accuracy: 0.8359\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2938 - accuracy: 0.8775 - val_loss: 0.3696 - val_accuracy: 0.8388\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2943 - accuracy: 0.8763 - val_loss: 0.3756 - val_accuracy: 0.8353\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2891 - accuracy: 0.8863 - val_loss: 0.3911 - val_accuracy: 0.8225\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2857 - accuracy: 0.8825 - val_loss: 0.3928 - val_accuracy: 0.8247\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2947 - accuracy: 0.8725 - val_loss: 0.4018 - val_accuracy: 0.8169\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3003 - accuracy: 0.8763 - val_loss: 0.3757 - val_accuracy: 0.8347\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3012 - accuracy: 0.8700 - val_loss: 0.3835 - val_accuracy: 0.8288\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2868 - accuracy: 0.8750 - val_loss: 0.3688 - val_accuracy: 0.8375\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2849 - accuracy: 0.8737 - val_loss: 0.3821 - val_accuracy: 0.8316\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2798 - accuracy: 0.8825 - val_loss: 0.3791 - val_accuracy: 0.8338\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2743 - accuracy: 0.8850 - val_loss: 0.3669 - val_accuracy: 0.8394\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2801 - accuracy: 0.8850 - val_loss: 0.3702 - val_accuracy: 0.8369\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2817 - accuracy: 0.8913 - val_loss: 0.3659 - val_accuracy: 0.8391\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2778 - accuracy: 0.8788 - val_loss: 0.3675 - val_accuracy: 0.8422\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2755 - accuracy: 0.8750 - val_loss: 0.3691 - val_accuracy: 0.8381\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2935 - accuracy: 0.8763 - val_loss: 0.3702 - val_accuracy: 0.8400\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2788 - accuracy: 0.8863 - val_loss: 0.3675 - val_accuracy: 0.8416\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2667 - accuracy: 0.8863 - val_loss: 0.3921 - val_accuracy: 0.8294\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2925 - accuracy: 0.8737 - val_loss: 0.3885 - val_accuracy: 0.8275\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2752 - accuracy: 0.8825 - val_loss: 0.3652 - val_accuracy: 0.8397\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2714 - accuracy: 0.8850 - val_loss: 0.3660 - val_accuracy: 0.8422\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2692 - accuracy: 0.8825 - val_loss: 0.3697 - val_accuracy: 0.8381\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2660 - accuracy: 0.8888 - val_loss: 0.3706 - val_accuracy: 0.8378\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2696 - accuracy: 0.8888 - val_loss: 0.3656 - val_accuracy: 0.8406\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2631 - accuracy: 0.8863 - val_loss: 0.3657 - val_accuracy: 0.8428\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2615 - accuracy: 0.8913 - val_loss: 0.3675 - val_accuracy: 0.8428\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2723 - accuracy: 0.8863 - val_loss: 0.3693 - val_accuracy: 0.8400\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2560 - accuracy: 0.8950 - val_loss: 0.3666 - val_accuracy: 0.8444\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2558 - accuracy: 0.8975 - val_loss: 0.3638 - val_accuracy: 0.8419\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2541 - accuracy: 0.8863 - val_loss: 0.3641 - val_accuracy: 0.8431\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2636 - accuracy: 0.8850 - val_loss: 0.3625 - val_accuracy: 0.8425\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2632 - accuracy: 0.8888 - val_loss: 0.3701 - val_accuracy: 0.8363\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2648 - accuracy: 0.8838 - val_loss: 0.3697 - val_accuracy: 0.8394\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2792 - accuracy: 0.8838 - val_loss: 0.3877 - val_accuracy: 0.8281\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2830 - accuracy: 0.8825 - val_loss: 0.3903 - val_accuracy: 0.8244\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2763 - accuracy: 0.8900 - val_loss: 0.3679 - val_accuracy: 0.8406\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2531 - accuracy: 0.8975 - val_loss: 0.3720 - val_accuracy: 0.8438\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2516 - accuracy: 0.9025 - val_loss: 0.3810 - val_accuracy: 0.8369\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2542 - accuracy: 0.8938 - val_loss: 0.3626 - val_accuracy: 0.8469\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2424 - accuracy: 0.8925 - val_loss: 0.3662 - val_accuracy: 0.8441\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2467 - accuracy: 0.8888 - val_loss: 0.3638 - val_accuracy: 0.8450\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2528 - accuracy: 0.8975 - val_loss: 0.3639 - val_accuracy: 0.8434\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2411 - accuracy: 0.8975 - val_loss: 0.3675 - val_accuracy: 0.8453\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2384 - accuracy: 0.8988 - val_loss: 0.3702 - val_accuracy: 0.8388\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2740 - accuracy: 0.8800 - val_loss: 0.3912 - val_accuracy: 0.8250\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2618 - accuracy: 0.9013 - val_loss: 0.3797 - val_accuracy: 0.8356\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2495 - accuracy: 0.9000 - val_loss: 0.3811 - val_accuracy: 0.8369\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2493 - accuracy: 0.8938 - val_loss: 0.3682 - val_accuracy: 0.8447\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2365 - accuracy: 0.9013 - val_loss: 0.3708 - val_accuracy: 0.8397\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2477 - accuracy: 0.9000 - val_loss: 0.3654 - val_accuracy: 0.8453\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2384 - accuracy: 0.8975 - val_loss: 0.3640 - val_accuracy: 0.8438\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2505 - accuracy: 0.9038 - val_loss: 0.3684 - val_accuracy: 0.8453\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2630 - accuracy: 0.8863 - val_loss: 0.3694 - val_accuracy: 0.8428\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2434 - accuracy: 0.8988 - val_loss: 0.3676 - val_accuracy: 0.8422\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2332 - accuracy: 0.9137 - val_loss: 0.3748 - val_accuracy: 0.8419\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2370 - accuracy: 0.8975 - val_loss: 0.3677 - val_accuracy: 0.8450\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2281 - accuracy: 0.9125 - val_loss: 0.3654 - val_accuracy: 0.8447\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2303 - accuracy: 0.9025 - val_loss: 0.3631 - val_accuracy: 0.8453\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2261 - accuracy: 0.9062 - val_loss: 0.3675 - val_accuracy: 0.8472\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2254 - accuracy: 0.9100 - val_loss: 0.3742 - val_accuracy: 0.8428\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2264 - accuracy: 0.9125 - val_loss: 0.3783 - val_accuracy: 0.8350\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2427 - accuracy: 0.9100 - val_loss: 0.3670 - val_accuracy: 0.8484\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2259 - accuracy: 0.9125 - val_loss: 0.3712 - val_accuracy: 0.8475\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2195 - accuracy: 0.9087 - val_loss: 0.3667 - val_accuracy: 0.8453\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2165 - accuracy: 0.9137 - val_loss: 0.3680 - val_accuracy: 0.8462\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2214 - accuracy: 0.9150 - val_loss: 0.3668 - val_accuracy: 0.8441\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2402 - accuracy: 0.9175 - val_loss: 0.3763 - val_accuracy: 0.8388\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2363 - accuracy: 0.9062 - val_loss: 0.3704 - val_accuracy: 0.8372\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2443 - accuracy: 0.8988 - val_loss: 0.3683 - val_accuracy: 0.8472\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2213 - accuracy: 0.9150 - val_loss: 0.3651 - val_accuracy: 0.8425\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2193 - accuracy: 0.9212 - val_loss: 0.3672 - val_accuracy: 0.8447\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2134 - accuracy: 0.9200 - val_loss: 0.3850 - val_accuracy: 0.8459\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2129 - accuracy: 0.9200 - val_loss: 0.3657 - val_accuracy: 0.8428\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2145 - accuracy: 0.9187 - val_loss: 0.3661 - val_accuracy: 0.8469\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2087 - accuracy: 0.9237 - val_loss: 0.3771 - val_accuracy: 0.8453\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2107 - accuracy: 0.9162 - val_loss: 0.3814 - val_accuracy: 0.8466\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2059 - accuracy: 0.9287 - val_loss: 0.3796 - val_accuracy: 0.8447\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2115 - accuracy: 0.9187 - val_loss: 0.3699 - val_accuracy: 0.8416\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2104 - accuracy: 0.9262 - val_loss: 0.3815 - val_accuracy: 0.8459\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2381 - accuracy: 0.9087 - val_loss: 0.3777 - val_accuracy: 0.8444\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2385 - accuracy: 0.9062 - val_loss: 0.3760 - val_accuracy: 0.8369\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3735 - accuracy: 0.8413\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_51 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_51 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions_13 (Encode  (None, 22, 18)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_13 (Tra  (None, 22, 18)           1718      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_13 (Gl  (None, 18)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 32ms/step - loss: 0.8295 - accuracy: 0.5088 - val_loss: 0.7842 - val_accuracy: 0.5172\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.7849 - accuracy: 0.5100 - val_loss: 0.7479 - val_accuracy: 0.5294\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7484 - accuracy: 0.5288 - val_loss: 0.7182 - val_accuracy: 0.5500\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7223 - accuracy: 0.5425 - val_loss: 0.6923 - val_accuracy: 0.5709\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6939 - accuracy: 0.5775 - val_loss: 0.6713 - val_accuracy: 0.5897\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6735 - accuracy: 0.6100 - val_loss: 0.6525 - val_accuracy: 0.6266\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6547 - accuracy: 0.6375 - val_loss: 0.6379 - val_accuracy: 0.6384\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6395 - accuracy: 0.6687 - val_loss: 0.6252 - val_accuracy: 0.6625\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6271 - accuracy: 0.6850 - val_loss: 0.6148 - val_accuracy: 0.6850\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6161 - accuracy: 0.7100 - val_loss: 0.6044 - val_accuracy: 0.6919\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6054 - accuracy: 0.7163 - val_loss: 0.5947 - val_accuracy: 0.7047\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5934 - accuracy: 0.7175 - val_loss: 0.5872 - val_accuracy: 0.7075\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5843 - accuracy: 0.7237 - val_loss: 0.5793 - val_accuracy: 0.7144\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5769 - accuracy: 0.7188 - val_loss: 0.5724 - val_accuracy: 0.7237\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5696 - accuracy: 0.7237 - val_loss: 0.5674 - val_accuracy: 0.7272\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5635 - accuracy: 0.7325 - val_loss: 0.5615 - val_accuracy: 0.7312\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5582 - accuracy: 0.7362 - val_loss: 0.5567 - val_accuracy: 0.7322\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5530 - accuracy: 0.7200 - val_loss: 0.5529 - val_accuracy: 0.7366\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5465 - accuracy: 0.7412 - val_loss: 0.5480 - val_accuracy: 0.7384\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5391 - accuracy: 0.7475 - val_loss: 0.5432 - val_accuracy: 0.7403\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5340 - accuracy: 0.7425 - val_loss: 0.5393 - val_accuracy: 0.7412\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5293 - accuracy: 0.7487 - val_loss: 0.5373 - val_accuracy: 0.7487\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5247 - accuracy: 0.7513 - val_loss: 0.5342 - val_accuracy: 0.7491\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5221 - accuracy: 0.7513 - val_loss: 0.5321 - val_accuracy: 0.7447\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5172 - accuracy: 0.7538 - val_loss: 0.5293 - val_accuracy: 0.7450\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5131 - accuracy: 0.7538 - val_loss: 0.5267 - val_accuracy: 0.7494\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5099 - accuracy: 0.7575 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5064 - accuracy: 0.7588 - val_loss: 0.5234 - val_accuracy: 0.7475\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5032 - accuracy: 0.7575 - val_loss: 0.5208 - val_accuracy: 0.7528\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5008 - accuracy: 0.7588 - val_loss: 0.5207 - val_accuracy: 0.7503\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4975 - accuracy: 0.7600 - val_loss: 0.5185 - val_accuracy: 0.7506\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4947 - accuracy: 0.7638 - val_loss: 0.5181 - val_accuracy: 0.7491\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4935 - accuracy: 0.7663 - val_loss: 0.5156 - val_accuracy: 0.7497\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4909 - accuracy: 0.7588 - val_loss: 0.5143 - val_accuracy: 0.7538\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4880 - accuracy: 0.7663 - val_loss: 0.5152 - val_accuracy: 0.7484\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4868 - accuracy: 0.7700 - val_loss: 0.5132 - val_accuracy: 0.7506\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4844 - accuracy: 0.7650 - val_loss: 0.5122 - val_accuracy: 0.7503\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4813 - accuracy: 0.7638 - val_loss: 0.5099 - val_accuracy: 0.7528\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4804 - accuracy: 0.7738 - val_loss: 0.5069 - val_accuracy: 0.7544\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4769 - accuracy: 0.7713 - val_loss: 0.5074 - val_accuracy: 0.7525\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4779 - accuracy: 0.7675 - val_loss: 0.5075 - val_accuracy: 0.7528\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4743 - accuracy: 0.7550 - val_loss: 0.5052 - val_accuracy: 0.7541\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4705 - accuracy: 0.7713 - val_loss: 0.5045 - val_accuracy: 0.7547\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4697 - accuracy: 0.7763 - val_loss: 0.5079 - val_accuracy: 0.7550\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4674 - accuracy: 0.7750 - val_loss: 0.5013 - val_accuracy: 0.7534\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4635 - accuracy: 0.7738 - val_loss: 0.5069 - val_accuracy: 0.7516\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4635 - accuracy: 0.7738 - val_loss: 0.5002 - val_accuracy: 0.7566\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4969 - val_accuracy: 0.7588\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4559 - accuracy: 0.7900 - val_loss: 0.4935 - val_accuracy: 0.7622\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4534 - accuracy: 0.7912 - val_loss: 0.4930 - val_accuracy: 0.7600\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4504 - accuracy: 0.7875 - val_loss: 0.4910 - val_accuracy: 0.7606\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4485 - accuracy: 0.7812 - val_loss: 0.4916 - val_accuracy: 0.7600\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4464 - accuracy: 0.7862 - val_loss: 0.4893 - val_accuracy: 0.7638\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4431 - accuracy: 0.7950 - val_loss: 0.4848 - val_accuracy: 0.7641\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4403 - accuracy: 0.7925 - val_loss: 0.4846 - val_accuracy: 0.7634\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4377 - accuracy: 0.7950 - val_loss: 0.4827 - val_accuracy: 0.7672\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4353 - accuracy: 0.8037 - val_loss: 0.4807 - val_accuracy: 0.7672\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4322 - accuracy: 0.7937 - val_loss: 0.4795 - val_accuracy: 0.7678\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4306 - accuracy: 0.7950 - val_loss: 0.4824 - val_accuracy: 0.7653\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4279 - accuracy: 0.8025 - val_loss: 0.4765 - val_accuracy: 0.7744\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4236 - accuracy: 0.8050 - val_loss: 0.4750 - val_accuracy: 0.7719\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4339 - accuracy: 0.7950 - val_loss: 0.4864 - val_accuracy: 0.7719\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4275 - accuracy: 0.8050 - val_loss: 0.4754 - val_accuracy: 0.7728\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4202 - accuracy: 0.8087 - val_loss: 0.4787 - val_accuracy: 0.7750\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4145 - accuracy: 0.8025 - val_loss: 0.4707 - val_accuracy: 0.7744\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4111 - accuracy: 0.8100 - val_loss: 0.4686 - val_accuracy: 0.7819\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4085 - accuracy: 0.8150 - val_loss: 0.4676 - val_accuracy: 0.7797\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4057 - accuracy: 0.8150 - val_loss: 0.4640 - val_accuracy: 0.7822\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4028 - accuracy: 0.8125 - val_loss: 0.4672 - val_accuracy: 0.7775\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3993 - accuracy: 0.8175 - val_loss: 0.4689 - val_accuracy: 0.7788\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3982 - accuracy: 0.8175 - val_loss: 0.4594 - val_accuracy: 0.7853\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3940 - accuracy: 0.8138 - val_loss: 0.4673 - val_accuracy: 0.7803\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3966 - accuracy: 0.8238 - val_loss: 0.4605 - val_accuracy: 0.7859\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3865 - accuracy: 0.8275 - val_loss: 0.4555 - val_accuracy: 0.7916\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3844 - accuracy: 0.8313 - val_loss: 0.4568 - val_accuracy: 0.7916\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3823 - accuracy: 0.8300 - val_loss: 0.4520 - val_accuracy: 0.7959\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3771 - accuracy: 0.8288 - val_loss: 0.4523 - val_accuracy: 0.7934\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3698 - accuracy: 0.8438 - val_loss: 0.4451 - val_accuracy: 0.7984\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3663 - accuracy: 0.8438 - val_loss: 0.4503 - val_accuracy: 0.7975\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3629 - accuracy: 0.8475 - val_loss: 0.4445 - val_accuracy: 0.8019\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3561 - accuracy: 0.8425 - val_loss: 0.4350 - val_accuracy: 0.8028\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3518 - accuracy: 0.8462 - val_loss: 0.4344 - val_accuracy: 0.8025\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3459 - accuracy: 0.8575 - val_loss: 0.4240 - val_accuracy: 0.8075\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3419 - accuracy: 0.8512 - val_loss: 0.4232 - val_accuracy: 0.8103\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3355 - accuracy: 0.8662 - val_loss: 0.4155 - val_accuracy: 0.8128\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3334 - accuracy: 0.8537 - val_loss: 0.4151 - val_accuracy: 0.8112\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3248 - accuracy: 0.8687 - val_loss: 0.4006 - val_accuracy: 0.8194\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3166 - accuracy: 0.8763 - val_loss: 0.3946 - val_accuracy: 0.8366\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3050 - accuracy: 0.8775 - val_loss: 0.3857 - val_accuracy: 0.8441\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3034 - accuracy: 0.8875 - val_loss: 0.3883 - val_accuracy: 0.8378\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3006 - accuracy: 0.8825 - val_loss: 0.3720 - val_accuracy: 0.8441\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2869 - accuracy: 0.8975 - val_loss: 0.3662 - val_accuracy: 0.8531\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2755 - accuracy: 0.8938 - val_loss: 0.3674 - val_accuracy: 0.8597\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2695 - accuracy: 0.9112 - val_loss: 0.3556 - val_accuracy: 0.8553\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2582 - accuracy: 0.9087 - val_loss: 0.3515 - val_accuracy: 0.8606\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2514 - accuracy: 0.9125 - val_loss: 0.3613 - val_accuracy: 0.8578\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2548 - accuracy: 0.9050 - val_loss: 0.3431 - val_accuracy: 0.8628\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2447 - accuracy: 0.9125 - val_loss: 0.3421 - val_accuracy: 0.8600\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2447 - accuracy: 0.9125 - val_loss: 0.3544 - val_accuracy: 0.8519\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2431 - accuracy: 0.9100 - val_loss: 0.3359 - val_accuracy: 0.8637\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2273 - accuracy: 0.9187 - val_loss: 0.3277 - val_accuracy: 0.8669\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2213 - accuracy: 0.9300 - val_loss: 0.3251 - val_accuracy: 0.8697\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2227 - accuracy: 0.9162 - val_loss: 0.3318 - val_accuracy: 0.8669\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2135 - accuracy: 0.9250 - val_loss: 0.3175 - val_accuracy: 0.8722\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2055 - accuracy: 0.9287 - val_loss: 0.3119 - val_accuracy: 0.8791\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2106 - accuracy: 0.9275 - val_loss: 0.3139 - val_accuracy: 0.8772\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2026 - accuracy: 0.9312 - val_loss: 0.3144 - val_accuracy: 0.8816\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2138 - accuracy: 0.9212 - val_loss: 0.3117 - val_accuracy: 0.8747\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2025 - accuracy: 0.9275 - val_loss: 0.3062 - val_accuracy: 0.8756\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1958 - accuracy: 0.9325 - val_loss: 0.3073 - val_accuracy: 0.8816\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1902 - accuracy: 0.9400 - val_loss: 0.3115 - val_accuracy: 0.8763\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1992 - accuracy: 0.9337 - val_loss: 0.3067 - val_accuracy: 0.8753\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1857 - accuracy: 0.9300 - val_loss: 0.3046 - val_accuracy: 0.8772\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1806 - accuracy: 0.9388 - val_loss: 0.3277 - val_accuracy: 0.8731\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1821 - accuracy: 0.9362 - val_loss: 0.3002 - val_accuracy: 0.8819\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1730 - accuracy: 0.9375 - val_loss: 0.2939 - val_accuracy: 0.8844\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1715 - accuracy: 0.9375 - val_loss: 0.2981 - val_accuracy: 0.8800\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1697 - accuracy: 0.9350 - val_loss: 0.2943 - val_accuracy: 0.8859\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1744 - accuracy: 0.9388 - val_loss: 0.2938 - val_accuracy: 0.8831\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1657 - accuracy: 0.9450 - val_loss: 0.2909 - val_accuracy: 0.8844\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1651 - accuracy: 0.9400 - val_loss: 0.2925 - val_accuracy: 0.8916\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1612 - accuracy: 0.9400 - val_loss: 0.3115 - val_accuracy: 0.8769\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1582 - accuracy: 0.9450 - val_loss: 0.2939 - val_accuracy: 0.8844\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1561 - accuracy: 0.9450 - val_loss: 0.2982 - val_accuracy: 0.8844\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1553 - accuracy: 0.9425 - val_loss: 0.2955 - val_accuracy: 0.8881\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1627 - accuracy: 0.9488 - val_loss: 0.2990 - val_accuracy: 0.8869\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1545 - accuracy: 0.9475 - val_loss: 0.2905 - val_accuracy: 0.8841\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1665 - accuracy: 0.9463 - val_loss: 0.3097 - val_accuracy: 0.8781\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1654 - accuracy: 0.9438 - val_loss: 0.2810 - val_accuracy: 0.8863\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1557 - accuracy: 0.9475 - val_loss: 0.2879 - val_accuracy: 0.8822\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1487 - accuracy: 0.9463 - val_loss: 0.2837 - val_accuracy: 0.8831\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1490 - accuracy: 0.9475 - val_loss: 0.2929 - val_accuracy: 0.8881\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1562 - accuracy: 0.9400 - val_loss: 0.3508 - val_accuracy: 0.8619\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1711 - accuracy: 0.9362 - val_loss: 0.3097 - val_accuracy: 0.8800\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1559 - accuracy: 0.9450 - val_loss: 0.2879 - val_accuracy: 0.8906\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1482 - accuracy: 0.9500 - val_loss: 0.2915 - val_accuracy: 0.8919\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1333 - accuracy: 0.9575 - val_loss: 0.2904 - val_accuracy: 0.8872\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1271 - accuracy: 0.9563 - val_loss: 0.3258 - val_accuracy: 0.8756\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1484 - accuracy: 0.9475 - val_loss: 0.2965 - val_accuracy: 0.8913\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1392 - accuracy: 0.9538 - val_loss: 0.2808 - val_accuracy: 0.8903\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1282 - accuracy: 0.9475 - val_loss: 0.2808 - val_accuracy: 0.8922\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1226 - accuracy: 0.9613 - val_loss: 0.2748 - val_accuracy: 0.8947\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1185 - accuracy: 0.9538 - val_loss: 0.2874 - val_accuracy: 0.8913\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1173 - accuracy: 0.9588 - val_loss: 0.2817 - val_accuracy: 0.8938\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1171 - accuracy: 0.9588 - val_loss: 0.2818 - val_accuracy: 0.8928\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1156 - accuracy: 0.9638 - val_loss: 0.2850 - val_accuracy: 0.8925\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1126 - accuracy: 0.9600 - val_loss: 0.3062 - val_accuracy: 0.8884\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1190 - accuracy: 0.9575 - val_loss: 0.2881 - val_accuracy: 0.8969\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1132 - accuracy: 0.9663 - val_loss: 0.2825 - val_accuracy: 0.8988\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1052 - accuracy: 0.9575 - val_loss: 0.2759 - val_accuracy: 0.8975\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1037 - accuracy: 0.9650 - val_loss: 0.2986 - val_accuracy: 0.8966\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1013 - accuracy: 0.9675 - val_loss: 0.2805 - val_accuracy: 0.9000\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1018 - accuracy: 0.9700 - val_loss: 0.2854 - val_accuracy: 0.9000\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1133 - accuracy: 0.9500 - val_loss: 0.2850 - val_accuracy: 0.8944\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1068 - accuracy: 0.9638 - val_loss: 0.2808 - val_accuracy: 0.9003\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0924 - accuracy: 0.9737 - val_loss: 0.2775 - val_accuracy: 0.8972\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1006 - accuracy: 0.9675 - val_loss: 0.2876 - val_accuracy: 0.9006\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1079 - accuracy: 0.9588 - val_loss: 0.2849 - val_accuracy: 0.8944\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1111 - accuracy: 0.9625 - val_loss: 0.2799 - val_accuracy: 0.8997\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1080 - accuracy: 0.9563 - val_loss: 0.2773 - val_accuracy: 0.8978\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0951 - accuracy: 0.9675 - val_loss: 0.2801 - val_accuracy: 0.9019\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0938 - accuracy: 0.9700 - val_loss: 0.2793 - val_accuracy: 0.9025\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1089 - accuracy: 0.9575 - val_loss: 0.2886 - val_accuracy: 0.8959\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1191 - accuracy: 0.9575 - val_loss: 0.2956 - val_accuracy: 0.8978\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0915 - accuracy: 0.9750 - val_loss: 0.2866 - val_accuracy: 0.9009\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0920 - accuracy: 0.9712 - val_loss: 0.2801 - val_accuracy: 0.9016\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0951 - accuracy: 0.9625 - val_loss: 0.2831 - val_accuracy: 0.8947\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0942 - accuracy: 0.9688 - val_loss: 0.2805 - val_accuracy: 0.9031\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0972 - accuracy: 0.9650 - val_loss: 0.3012 - val_accuracy: 0.8978\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0903 - accuracy: 0.9675 - val_loss: 0.2811 - val_accuracy: 0.9016\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0858 - accuracy: 0.9675 - val_loss: 0.2870 - val_accuracy: 0.9034\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0787 - accuracy: 0.9737 - val_loss: 0.2815 - val_accuracy: 0.9034\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0760 - accuracy: 0.9725 - val_loss: 0.2852 - val_accuracy: 0.9066\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0784 - accuracy: 0.9712 - val_loss: 0.2922 - val_accuracy: 0.9025\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0784 - accuracy: 0.9775 - val_loss: 0.2832 - val_accuracy: 0.9041\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0726 - accuracy: 0.9775 - val_loss: 0.2905 - val_accuracy: 0.9025\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0795 - accuracy: 0.9688 - val_loss: 0.2875 - val_accuracy: 0.9013\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0938 - accuracy: 0.9688 - val_loss: 0.3054 - val_accuracy: 0.8991\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0840 - accuracy: 0.9737 - val_loss: 0.2992 - val_accuracy: 0.8978\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0784 - accuracy: 0.9750 - val_loss: 0.2915 - val_accuracy: 0.9059\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0727 - accuracy: 0.9762 - val_loss: 0.2838 - val_accuracy: 0.9056\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0779 - accuracy: 0.9725 - val_loss: 0.2923 - val_accuracy: 0.9028\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0738 - accuracy: 0.9787 - val_loss: 0.2826 - val_accuracy: 0.9013\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0938 - accuracy: 0.9737 - val_loss: 0.3164 - val_accuracy: 0.8891\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1123 - accuracy: 0.9638 - val_loss: 0.2962 - val_accuracy: 0.8978\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0897 - accuracy: 0.9787 - val_loss: 0.2931 - val_accuracy: 0.8972\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0842 - accuracy: 0.9700 - val_loss: 0.2916 - val_accuracy: 0.9034\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0787 - accuracy: 0.9737 - val_loss: 0.2828 - val_accuracy: 0.9025\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 0.2840 - val_accuracy: 0.9038\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0838 - accuracy: 0.9787 - val_loss: 0.2921 - val_accuracy: 0.8997\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0722 - accuracy: 0.9750 - val_loss: 0.2829 - val_accuracy: 0.9069\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.0672 - accuracy: 0.9825 - val_loss: 0.2761 - val_accuracy: 0.9056\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.2784 - accuracy: 0.8948\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_52 (Masking)        (None, 22, 18)            0         \n",
      "                                                                 \n",
      " layer_normalization_52 (Lay  (None, 22, 18)           36        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " encode_positions_14 (Encode  (None, 22, 18)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_14 (Tra  (None, 22, 18)           1718      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_14 (Gl  (None, 18)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 32ms/step - loss: 1.3395 - accuracy: 0.4938 - val_loss: 1.1267 - val_accuracy: 0.4659\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9416 - accuracy: 0.5038 - val_loss: 0.8921 - val_accuracy: 0.4747\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.8085 - accuracy: 0.5063 - val_loss: 0.8249 - val_accuracy: 0.4806\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7696 - accuracy: 0.5300 - val_loss: 0.7929 - val_accuracy: 0.4881\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7460 - accuracy: 0.5375 - val_loss: 0.7667 - val_accuracy: 0.5022\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7262 - accuracy: 0.5575 - val_loss: 0.7454 - val_accuracy: 0.5094\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.7114 - accuracy: 0.5450 - val_loss: 0.7305 - val_accuracy: 0.5150\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6998 - accuracy: 0.5562 - val_loss: 0.7156 - val_accuracy: 0.5294\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6887 - accuracy: 0.5813 - val_loss: 0.7027 - val_accuracy: 0.5456\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6767 - accuracy: 0.5950 - val_loss: 0.6892 - val_accuracy: 0.5600\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6647 - accuracy: 0.6087 - val_loss: 0.6754 - val_accuracy: 0.5772\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6521 - accuracy: 0.6237 - val_loss: 0.6611 - val_accuracy: 0.6044\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6386 - accuracy: 0.6587 - val_loss: 0.6444 - val_accuracy: 0.6425\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6246 - accuracy: 0.6825 - val_loss: 0.6294 - val_accuracy: 0.6644\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.6098 - accuracy: 0.6950 - val_loss: 0.6126 - val_accuracy: 0.6872\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5950 - accuracy: 0.7175 - val_loss: 0.5962 - val_accuracy: 0.7153\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5826 - accuracy: 0.7362 - val_loss: 0.5830 - val_accuracy: 0.7203\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5742 - accuracy: 0.7362 - val_loss: 0.5718 - val_accuracy: 0.7247\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5627 - accuracy: 0.7400 - val_loss: 0.5615 - val_accuracy: 0.7306\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5507 - accuracy: 0.7475 - val_loss: 0.5532 - val_accuracy: 0.7319\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5433 - accuracy: 0.7450 - val_loss: 0.5443 - val_accuracy: 0.7347\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5360 - accuracy: 0.7475 - val_loss: 0.5446 - val_accuracy: 0.7287\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5283 - accuracy: 0.7525 - val_loss: 0.5321 - val_accuracy: 0.7306\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5215 - accuracy: 0.7500 - val_loss: 0.5250 - val_accuracy: 0.7437\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5136 - accuracy: 0.7575 - val_loss: 0.5166 - val_accuracy: 0.7497\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.5049 - accuracy: 0.7588 - val_loss: 0.5127 - val_accuracy: 0.7494\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4969 - accuracy: 0.7725 - val_loss: 0.5040 - val_accuracy: 0.7591\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4877 - accuracy: 0.7738 - val_loss: 0.4966 - val_accuracy: 0.7600\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4805 - accuracy: 0.7750 - val_loss: 0.4891 - val_accuracy: 0.7638\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4731 - accuracy: 0.7800 - val_loss: 0.4862 - val_accuracy: 0.7647\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4684 - accuracy: 0.7775 - val_loss: 0.4822 - val_accuracy: 0.7650\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4646 - accuracy: 0.7825 - val_loss: 0.4763 - val_accuracy: 0.7666\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4630 - accuracy: 0.7837 - val_loss: 0.4752 - val_accuracy: 0.7697\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4558 - accuracy: 0.7825 - val_loss: 0.4706 - val_accuracy: 0.7697\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4504 - accuracy: 0.7875 - val_loss: 0.4674 - val_accuracy: 0.7719\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4468 - accuracy: 0.7912 - val_loss: 0.4645 - val_accuracy: 0.7753\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4459 - accuracy: 0.7887 - val_loss: 0.4610 - val_accuracy: 0.7744\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4415 - accuracy: 0.7875 - val_loss: 0.4625 - val_accuracy: 0.7747\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4382 - accuracy: 0.7912 - val_loss: 0.4566 - val_accuracy: 0.7778\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4350 - accuracy: 0.7862 - val_loss: 0.4559 - val_accuracy: 0.7791\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4340 - accuracy: 0.7875 - val_loss: 0.4535 - val_accuracy: 0.7794\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4317 - accuracy: 0.7937 - val_loss: 0.4560 - val_accuracy: 0.7809\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4318 - accuracy: 0.7887 - val_loss: 0.4662 - val_accuracy: 0.7694\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4290 - accuracy: 0.7875 - val_loss: 0.4501 - val_accuracy: 0.7800\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4262 - accuracy: 0.7912 - val_loss: 0.4485 - val_accuracy: 0.7806\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4243 - accuracy: 0.7887 - val_loss: 0.4477 - val_accuracy: 0.7825\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4219 - accuracy: 0.7912 - val_loss: 0.4462 - val_accuracy: 0.7812\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4194 - accuracy: 0.7962 - val_loss: 0.4445 - val_accuracy: 0.7828\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4180 - accuracy: 0.7962 - val_loss: 0.4453 - val_accuracy: 0.7816\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4194 - accuracy: 0.7950 - val_loss: 0.4473 - val_accuracy: 0.7800\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4284 - accuracy: 0.7887 - val_loss: 0.4440 - val_accuracy: 0.7806\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4241 - accuracy: 0.7862 - val_loss: 0.4449 - val_accuracy: 0.7788\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4215 - accuracy: 0.7975 - val_loss: 0.4505 - val_accuracy: 0.7738\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4180 - accuracy: 0.7925 - val_loss: 0.4475 - val_accuracy: 0.7759\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4168 - accuracy: 0.7975 - val_loss: 0.4436 - val_accuracy: 0.7800\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4116 - accuracy: 0.8025 - val_loss: 0.4408 - val_accuracy: 0.7816\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4084 - accuracy: 0.8050 - val_loss: 0.4374 - val_accuracy: 0.7828\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4058 - accuracy: 0.8100 - val_loss: 0.4363 - val_accuracy: 0.7837\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4041 - accuracy: 0.8087 - val_loss: 0.4347 - val_accuracy: 0.7844\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4018 - accuracy: 0.8175 - val_loss: 0.4344 - val_accuracy: 0.7847\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4032 - accuracy: 0.8112 - val_loss: 0.4332 - val_accuracy: 0.7844\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3985 - accuracy: 0.8225 - val_loss: 0.4335 - val_accuracy: 0.7859\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.4001 - accuracy: 0.8188 - val_loss: 0.4319 - val_accuracy: 0.7859\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3978 - accuracy: 0.8213 - val_loss: 0.4312 - val_accuracy: 0.7862\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3947 - accuracy: 0.8238 - val_loss: 0.4333 - val_accuracy: 0.7897\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3944 - accuracy: 0.8225 - val_loss: 0.4304 - val_accuracy: 0.7894\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3932 - accuracy: 0.8175 - val_loss: 0.4306 - val_accuracy: 0.7919\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3920 - accuracy: 0.8250 - val_loss: 0.4282 - val_accuracy: 0.7912\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3895 - accuracy: 0.8238 - val_loss: 0.4288 - val_accuracy: 0.7947\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3900 - accuracy: 0.8263 - val_loss: 0.4268 - val_accuracy: 0.7937\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3881 - accuracy: 0.8250 - val_loss: 0.4270 - val_accuracy: 0.7947\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3889 - accuracy: 0.8250 - val_loss: 0.4301 - val_accuracy: 0.7956\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3869 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.7919\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3835 - accuracy: 0.8313 - val_loss: 0.4261 - val_accuracy: 0.7947\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3831 - accuracy: 0.8288 - val_loss: 0.4257 - val_accuracy: 0.7966\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3807 - accuracy: 0.8300 - val_loss: 0.4280 - val_accuracy: 0.7975\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3795 - accuracy: 0.8288 - val_loss: 0.4250 - val_accuracy: 0.7984\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3797 - accuracy: 0.8325 - val_loss: 0.4229 - val_accuracy: 0.8006\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3822 - accuracy: 0.8350 - val_loss: 0.4329 - val_accuracy: 0.7947\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3867 - accuracy: 0.8150 - val_loss: 0.4239 - val_accuracy: 0.7981\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3924 - accuracy: 0.8250 - val_loss: 0.4449 - val_accuracy: 0.7831\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3871 - accuracy: 0.8263 - val_loss: 0.4316 - val_accuracy: 0.7984\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3845 - accuracy: 0.8213 - val_loss: 0.4259 - val_accuracy: 0.7962\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3766 - accuracy: 0.8438 - val_loss: 0.4247 - val_accuracy: 0.8009\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3701 - accuracy: 0.8462 - val_loss: 0.4234 - val_accuracy: 0.8003\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3712 - accuracy: 0.8363 - val_loss: 0.4272 - val_accuracy: 0.7981\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3730 - accuracy: 0.8400 - val_loss: 0.4258 - val_accuracy: 0.8006\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3708 - accuracy: 0.8338 - val_loss: 0.4282 - val_accuracy: 0.8019\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3724 - accuracy: 0.8363 - val_loss: 0.4228 - val_accuracy: 0.8053\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3686 - accuracy: 0.8388 - val_loss: 0.4219 - val_accuracy: 0.8062\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3656 - accuracy: 0.8500 - val_loss: 0.4235 - val_accuracy: 0.8047\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3641 - accuracy: 0.8462 - val_loss: 0.4216 - val_accuracy: 0.8072\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3671 - accuracy: 0.8363 - val_loss: 0.4220 - val_accuracy: 0.8044\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3727 - accuracy: 0.8400 - val_loss: 0.4234 - val_accuracy: 0.8003\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3672 - accuracy: 0.8413 - val_loss: 0.4198 - val_accuracy: 0.8078\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3634 - accuracy: 0.8438 - val_loss: 0.4223 - val_accuracy: 0.8047\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3565 - accuracy: 0.8550 - val_loss: 0.4227 - val_accuracy: 0.8100\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3557 - accuracy: 0.8575 - val_loss: 0.4216 - val_accuracy: 0.8053\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3524 - accuracy: 0.8562 - val_loss: 0.4245 - val_accuracy: 0.8078\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3519 - accuracy: 0.8550 - val_loss: 0.4197 - val_accuracy: 0.8094\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3489 - accuracy: 0.8562 - val_loss: 0.4224 - val_accuracy: 0.8069\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3486 - accuracy: 0.8550 - val_loss: 0.4223 - val_accuracy: 0.8081\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3471 - accuracy: 0.8575 - val_loss: 0.4210 - val_accuracy: 0.8059\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3476 - accuracy: 0.8612 - val_loss: 0.4291 - val_accuracy: 0.8025\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3442 - accuracy: 0.8562 - val_loss: 0.4258 - val_accuracy: 0.8031\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3502 - accuracy: 0.8575 - val_loss: 0.4217 - val_accuracy: 0.8078\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3437 - accuracy: 0.8637 - val_loss: 0.4249 - val_accuracy: 0.8025\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3436 - accuracy: 0.8625 - val_loss: 0.4285 - val_accuracy: 0.7997\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3430 - accuracy: 0.8562 - val_loss: 0.4232 - val_accuracy: 0.8044\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3414 - accuracy: 0.8650 - val_loss: 0.4218 - val_accuracy: 0.8075\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3424 - accuracy: 0.8612 - val_loss: 0.4239 - val_accuracy: 0.8062\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3370 - accuracy: 0.8612 - val_loss: 0.4198 - val_accuracy: 0.8047\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3329 - accuracy: 0.8675 - val_loss: 0.4277 - val_accuracy: 0.8022\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3479 - accuracy: 0.8625 - val_loss: 0.4231 - val_accuracy: 0.8084\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3409 - accuracy: 0.8612 - val_loss: 0.4315 - val_accuracy: 0.7981\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3355 - accuracy: 0.8700 - val_loss: 0.4376 - val_accuracy: 0.7987\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3518 - accuracy: 0.8487 - val_loss: 0.4236 - val_accuracy: 0.8053\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3560 - accuracy: 0.8475 - val_loss: 0.4331 - val_accuracy: 0.7941\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3527 - accuracy: 0.8550 - val_loss: 0.4422 - val_accuracy: 0.7909\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3491 - accuracy: 0.8600 - val_loss: 0.4232 - val_accuracy: 0.8009\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3462 - accuracy: 0.8525 - val_loss: 0.4223 - val_accuracy: 0.8056\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3391 - accuracy: 0.8612 - val_loss: 0.4249 - val_accuracy: 0.8028\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3329 - accuracy: 0.8687 - val_loss: 0.4250 - val_accuracy: 0.8009\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3277 - accuracy: 0.8750 - val_loss: 0.4279 - val_accuracy: 0.8003\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3260 - accuracy: 0.8712 - val_loss: 0.4273 - val_accuracy: 0.8006\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3251 - accuracy: 0.8737 - val_loss: 0.4229 - val_accuracy: 0.8084\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3237 - accuracy: 0.8737 - val_loss: 0.4240 - val_accuracy: 0.8069\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3320 - accuracy: 0.8662 - val_loss: 0.4314 - val_accuracy: 0.7972\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3234 - accuracy: 0.8763 - val_loss: 0.4296 - val_accuracy: 0.7987\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3232 - accuracy: 0.8637 - val_loss: 0.4269 - val_accuracy: 0.8109\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3298 - accuracy: 0.8612 - val_loss: 0.4244 - val_accuracy: 0.8059\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3263 - accuracy: 0.8662 - val_loss: 0.4274 - val_accuracy: 0.8009\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3165 - accuracy: 0.8763 - val_loss: 0.4248 - val_accuracy: 0.8062\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3147 - accuracy: 0.8800 - val_loss: 0.4315 - val_accuracy: 0.8022\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3194 - accuracy: 0.8700 - val_loss: 0.4283 - val_accuracy: 0.8025\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3223 - accuracy: 0.8650 - val_loss: 0.4230 - val_accuracy: 0.8116\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3144 - accuracy: 0.8775 - val_loss: 0.4271 - val_accuracy: 0.8056\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3097 - accuracy: 0.8763 - val_loss: 0.4325 - val_accuracy: 0.8006\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3076 - accuracy: 0.8813 - val_loss: 0.4307 - val_accuracy: 0.8016\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3081 - accuracy: 0.8813 - val_loss: 0.4404 - val_accuracy: 0.7972\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3127 - accuracy: 0.8737 - val_loss: 0.4327 - val_accuracy: 0.8047\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3128 - accuracy: 0.8750 - val_loss: 0.4263 - val_accuracy: 0.8056\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3087 - accuracy: 0.8750 - val_loss: 0.4285 - val_accuracy: 0.8100\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3127 - accuracy: 0.8737 - val_loss: 0.4382 - val_accuracy: 0.7978\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3071 - accuracy: 0.8788 - val_loss: 0.4279 - val_accuracy: 0.8053\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3048 - accuracy: 0.8825 - val_loss: 0.4368 - val_accuracy: 0.8012\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3022 - accuracy: 0.8825 - val_loss: 0.4310 - val_accuracy: 0.8031\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3097 - accuracy: 0.8813 - val_loss: 0.4281 - val_accuracy: 0.8128\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.3236 - accuracy: 0.8650 - val_loss: 0.4340 - val_accuracy: 0.8012\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3137 - accuracy: 0.8763 - val_loss: 0.4402 - val_accuracy: 0.7981\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.4223 - accuracy: 0.8046\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......encode_positions\n",
      ".........vars\n",
      "......global_max_pooling1d\n",
      ".........vars\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......masking\n",
      ".........vars\n",
      "......transformer_encoder\n",
      ".........encoder_layers\n",
      "............transformer_encoder_block\n",
      "..............._attention_dropout\n",
      "..................vars\n",
      "..............._attention_layer\n",
      ".................._dropout_layer\n",
      ".....................vars\n",
      ".................._key_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._output_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._query_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._softmax\n",
      ".....................vars\n",
      ".................._value_dense\n",
      ".....................vars\n",
      "........................0\n",
      "..................vars\n",
      "..............._attention_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._inner_dropout_layer\n",
      "..................vars\n",
      "..............._intermediate_activation_layer\n",
      "..................vars\n",
      "..............._intermediate_dense\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._output_dense\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._output_dropout\n",
      "..................vars\n",
      "..............._output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      ".........output_normalization\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........33\n",
      ".........34\n",
      ".........35\n",
      ".........36\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-26 22:32:11        98024\n",
      "config.json                                    2023-03-26 22:32:11         2173\n",
      "metadata.json                                  2023-03-26 22:32:11           64\n",
      "500/500 [==============================] - 100s 199ms/step - loss: 0.2185 - accuracy: 0.9532\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.1222 - accuracy: 0.9662\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.2784 - accuracy: 0.8948\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Small training dataset with high holdout share, 800 examples\n",
    "experiment(2, time_task, 0.8, input_shape=(22, 18), output_shape=2, activation='softmax')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complex regex for ip recognition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def ipv6_task(holdout):\n",
    "    # Convert alphabet into one-hot vectors\n",
    "    alphabet = \"0123456789abcdefABCDEF: \"\n",
    "    num_chars = len(alphabet)\n",
    "    char_to_index = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\n",
    "    df = pd.read_csv('ipv6.csv')\n",
    "\n",
    "    # Convert true/false to categorical using keras.utils.to_categorical\n",
    "    df['valid_int'] = df['valid'].apply(lambda x: 1 if x else 0)\n",
    "    df['valid_one_hot'] = keras.utils.to_categorical(df['valid_int']).tolist()\n",
    "\n",
    "    # Convert the time strings to one-hot vectors and pad them to the max length with null characters\n",
    "    df['ipv6_one_hot'] = df['string'].apply(lambda x: string_to_one_hot(x, num_chars, char_to_index))\n",
    "    # Find the max length of the one-hot vectors\n",
    "    max_seq_len = df['ipv6_one_hot'].apply(lambda x: x.shape[0]).max()\n",
    "    df['ipv6_one_hot'] = df['ipv6_one_hot'].apply(lambda x: pad_one_hot(x, max_seq_len))\n",
    "\n",
    "    # The same lines as above, but with a cycle\n",
    "\n",
    "    # Extract columns to make the data easier to work with\n",
    "    X = np.stack(df['ipv6_one_hot'].values)\n",
    "    y = np.stack(df['valid_one_hot'].values)\n",
    "\n",
    "    # Split the data into training and testing sets, preserving the ratio of valid/invalid times\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=holdout, stratify=y, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=holdout, stratify=y_train_val, random_state=42)\n",
    "\n",
    "    inspect_data(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    return X_train, X_val, y_train, y_val, X_test, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 3: Sufficient available data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7200, 95, 24)\n",
      "y_train shape: (7200, 2)\n",
      "X_val shape: (4800, 95, 24)\n",
      "y_val shape: (4800, 2)\n",
      "X_test shape: (8000, 95, 24)\n",
      "y_test shape: (8000, 2)\n",
      "X_train example: [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "y_train example: [0. 1.]\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_102 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_102 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                2086      \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,152\n",
      "Trainable params: 1,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 1128, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 50s 361ms/step - loss: 0.6940 - accuracy: 0.5006 - val_loss: 0.6922 - val_accuracy: 0.5385\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.6814 - accuracy: 0.5857 - val_loss: 0.6406 - val_accuracy: 0.6544\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.5168 - accuracy: 0.7538 - val_loss: 0.4057 - val_accuracy: 0.8173\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.3243 - accuracy: 0.8656 - val_loss: 0.2652 - val_accuracy: 0.8994\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.2465 - accuracy: 0.9075 - val_loss: 0.2076 - val_accuracy: 0.9279\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.2146 - accuracy: 0.9247 - val_loss: 0.1866 - val_accuracy: 0.9354\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1903 - accuracy: 0.9346 - val_loss: 0.1975 - val_accuracy: 0.9277\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1743 - accuracy: 0.9418 - val_loss: 0.1501 - val_accuracy: 0.9506\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1617 - accuracy: 0.9460 - val_loss: 0.1474 - val_accuracy: 0.9508\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1547 - accuracy: 0.9483 - val_loss: 0.1515 - val_accuracy: 0.9494\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1558 - accuracy: 0.9489 - val_loss: 0.1247 - val_accuracy: 0.9621\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1489 - accuracy: 0.9507 - val_loss: 0.1247 - val_accuracy: 0.9588\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1532 - accuracy: 0.9493 - val_loss: 0.1344 - val_accuracy: 0.9592\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1266 - accuracy: 0.9603 - val_loss: 0.1144 - val_accuracy: 0.9642\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1268 - accuracy: 0.9592 - val_loss: 0.1139 - val_accuracy: 0.9646\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1091 - accuracy: 0.9663 - val_loss: 0.1142 - val_accuracy: 0.9638\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1165 - accuracy: 0.9646 - val_loss: 0.0988 - val_accuracy: 0.9690\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1189 - accuracy: 0.9621 - val_loss: 0.1039 - val_accuracy: 0.9667\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1333 - accuracy: 0.9564 - val_loss: 0.0967 - val_accuracy: 0.9704\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0938 - accuracy: 0.9719 - val_loss: 0.1162 - val_accuracy: 0.9623\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0864 - accuracy: 0.9750 - val_loss: 0.1197 - val_accuracy: 0.9627\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0864 - accuracy: 0.9744 - val_loss: 0.1132 - val_accuracy: 0.9656\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0894 - accuracy: 0.9725 - val_loss: 0.0830 - val_accuracy: 0.9748\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0916 - accuracy: 0.9743 - val_loss: 0.0856 - val_accuracy: 0.9742\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0716 - accuracy: 0.9799 - val_loss: 0.1010 - val_accuracy: 0.9675\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1679 - accuracy: 0.9451 - val_loss: 0.1126 - val_accuracy: 0.9621\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0979 - accuracy: 0.9710 - val_loss: 0.0882 - val_accuracy: 0.9710\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0746 - accuracy: 0.9790 - val_loss: 0.0728 - val_accuracy: 0.9771\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0754 - accuracy: 0.9796 - val_loss: 0.0777 - val_accuracy: 0.9746\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0662 - accuracy: 0.9812 - val_loss: 0.0661 - val_accuracy: 0.9792\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0839 - accuracy: 0.9733 - val_loss: 0.0640 - val_accuracy: 0.9787\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0841 - accuracy: 0.9749 - val_loss: 0.0687 - val_accuracy: 0.9783\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0626 - accuracy: 0.9819 - val_loss: 0.0690 - val_accuracy: 0.9783\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0670 - accuracy: 0.9799 - val_loss: 0.0638 - val_accuracy: 0.9812\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0864 - accuracy: 0.9736 - val_loss: 0.0570 - val_accuracy: 0.9817\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0624 - accuracy: 0.9807 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0533 - accuracy: 0.9851 - val_loss: 0.0573 - val_accuracy: 0.9810\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0444 - accuracy: 0.9886 - val_loss: 0.0570 - val_accuracy: 0.9817\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 0.0759 - val_accuracy: 0.9762\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0494 - accuracy: 0.9871 - val_loss: 0.0469 - val_accuracy: 0.9854\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0463 - accuracy: 0.9871 - val_loss: 0.0763 - val_accuracy: 0.9785\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0443 - accuracy: 0.9875 - val_loss: 0.0473 - val_accuracy: 0.9846\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 0.0464 - val_accuracy: 0.9840\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0371 - accuracy: 0.9899 - val_loss: 0.0445 - val_accuracy: 0.9848\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0512 - accuracy: 0.9849 - val_loss: 0.0966 - val_accuracy: 0.9692\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.0723 - val_accuracy: 0.9798\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0398 - accuracy: 0.9894 - val_loss: 0.0418 - val_accuracy: 0.9881\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 0.0454 - val_accuracy: 0.9873\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 0.0344 - val_accuracy: 0.9900\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 0.0321 - val_accuracy: 0.9896\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0276 - accuracy: 0.9929 - val_loss: 0.0456 - val_accuracy: 0.9865\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0250 - accuracy: 0.9939 - val_loss: 0.0342 - val_accuracy: 0.9892\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.0555 - val_accuracy: 0.9852\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0235 - accuracy: 0.9940 - val_loss: 0.0321 - val_accuracy: 0.9912\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.0600 - val_accuracy: 0.9835\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 0.0928 - val_accuracy: 0.9767\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0543 - accuracy: 0.9833 - val_loss: 0.0306 - val_accuracy: 0.9898\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0516 - val_accuracy: 0.9856\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.0293 - val_accuracy: 0.9915\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.0311 - val_accuracy: 0.9902\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.0264 - val_accuracy: 0.9931\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0219 - val_accuracy: 0.9927\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.0577 - val_accuracy: 0.9862\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 0.0267 - val_accuracy: 0.9919\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.0387 - val_accuracy: 0.9900\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.1901 - val_accuracy: 0.9652\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0435 - accuracy: 0.9876 - val_loss: 0.0275 - val_accuracy: 0.9919\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0228 - val_accuracy: 0.9927\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0198 - val_accuracy: 0.9935\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0283 - val_accuracy: 0.9917\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0213 - val_accuracy: 0.9937\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0284 - val_accuracy: 0.9915\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0203 - val_accuracy: 0.9944\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0353 - accuracy: 0.9903 - val_loss: 0.0182 - val_accuracy: 0.9946\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0170 - val_accuracy: 0.9956\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0165 - val_accuracy: 0.9962\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0158 - val_accuracy: 0.9958\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0160 - val_accuracy: 0.9956\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0185 - val_accuracy: 0.9952\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0181 - val_accuracy: 0.9950\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0176 - val_accuracy: 0.9948\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.0183 - val_accuracy: 0.9944\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0195 - val_accuracy: 0.9942\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0205 - val_accuracy: 0.9942\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0204 - val_accuracy: 0.9942\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0137 - val_accuracy: 0.9956\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0217 - val_accuracy: 0.9944\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0354 - val_accuracy: 0.9898\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0144 - val_accuracy: 0.9950\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0157 - val_accuracy: 0.9956\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0185 - val_accuracy: 0.9950\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0143 - val_accuracy: 0.9965\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0154 - val_accuracy: 0.9950\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0387 - val_accuracy: 0.9900\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0095 - val_accuracy: 0.9973\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0084 - val_accuracy: 0.9979\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0107 - val_accuracy: 0.9965\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 3.6491e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9965\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.8707e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.4009e-04 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9969\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 1.8308e-04 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9975\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.6055e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9969\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.4760e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 1.1828e-04 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.0897e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 9.6501e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9973\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 8.6759e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9971\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 7.7350e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 7.0853e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 6.3683e-05 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 5.8117e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9975\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 5.2728e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 4.9089e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9975\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.4523e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9975\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 4.1618e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9975\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 3.7905e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 3.4816e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9973\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.1531e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9975\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.9626e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9975\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.7395e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9973\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.5110e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9975\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.3237e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9973\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.1475e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.0141e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.8441e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9973\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.7469e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.5910e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9975\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.4761e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9973\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.3840e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9975\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.2996e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9975\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.1961e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9971\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 1.1280e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9973\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 1.0500e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9973\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 9.7758e-06 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9975\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 9.0554e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9973\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 8.4441e-06 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9973\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 7.8293e-06 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9975\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 7.4120e-06 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9975\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 7.1277e-06 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9973\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 6.4522e-06 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 5.8908e-06 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9967\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 5.6795e-06 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9971\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 5.2215e-06 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9971\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.8755e-06 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9971\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 4.5886e-06 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9973\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 4.3605e-06 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9971\n",
      "250/250 [==============================] - 18s 69ms/step - loss: 0.0112 - accuracy: 0.9979\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_103 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_103 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                2086      \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,152\n",
      "Trainable params: 1,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 1128, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 46s 360ms/step - loss: 0.6927 - accuracy: 0.5213 - val_loss: 0.6866 - val_accuracy: 0.5756\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.6368 - accuracy: 0.6492 - val_loss: 0.5582 - val_accuracy: 0.7383\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.4512 - accuracy: 0.8033 - val_loss: 0.4049 - val_accuracy: 0.8271\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.3316 - accuracy: 0.8707 - val_loss: 0.2917 - val_accuracy: 0.8952\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.2641 - accuracy: 0.9024 - val_loss: 0.2336 - val_accuracy: 0.9156\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.2243 - accuracy: 0.9226 - val_loss: 0.2014 - val_accuracy: 0.9308\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.2024 - accuracy: 0.9294 - val_loss: 0.1828 - val_accuracy: 0.9404\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1824 - accuracy: 0.9386 - val_loss: 0.1795 - val_accuracy: 0.9469\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1595 - accuracy: 0.9492 - val_loss: 0.1458 - val_accuracy: 0.9527\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.1472 - accuracy: 0.9506 - val_loss: 0.1291 - val_accuracy: 0.9579\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.1431 - accuracy: 0.9551 - val_loss: 0.1260 - val_accuracy: 0.9583\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.1241 - accuracy: 0.9603 - val_loss: 0.1290 - val_accuracy: 0.9619\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.1167 - accuracy: 0.9640 - val_loss: 0.1094 - val_accuracy: 0.9677\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.1076 - accuracy: 0.9647 - val_loss: 0.0953 - val_accuracy: 0.9717\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.1001 - accuracy: 0.9678 - val_loss: 0.0925 - val_accuracy: 0.9710\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1013 - accuracy: 0.9689 - val_loss: 0.0954 - val_accuracy: 0.9712\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0844 - accuracy: 0.9732 - val_loss: 0.0924 - val_accuracy: 0.9750\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0745 - accuracy: 0.9776 - val_loss: 0.0802 - val_accuracy: 0.9771\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0819 - accuracy: 0.9753 - val_loss: 0.0848 - val_accuracy: 0.9767\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0709 - accuracy: 0.9782 - val_loss: 0.0642 - val_accuracy: 0.9806\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0617 - accuracy: 0.9814 - val_loss: 0.0611 - val_accuracy: 0.9802\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0526 - accuracy: 0.9842 - val_loss: 0.0589 - val_accuracy: 0.9837\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0522 - accuracy: 0.9842 - val_loss: 0.0611 - val_accuracy: 0.9802\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0554 - accuracy: 0.9831 - val_loss: 0.0538 - val_accuracy: 0.9869\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.0661 - val_accuracy: 0.9804\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0719 - accuracy: 0.9792 - val_loss: 0.0542 - val_accuracy: 0.9825\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0702 - accuracy: 0.9811 - val_loss: 0.0606 - val_accuracy: 0.9812\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0559 - accuracy: 0.9843 - val_loss: 0.0468 - val_accuracy: 0.9862\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0489 - accuracy: 0.9853 - val_loss: 0.0449 - val_accuracy: 0.9875\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0357 - accuracy: 0.9885 - val_loss: 0.0416 - val_accuracy: 0.9883\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.0434 - val_accuracy: 0.9862\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 0.0507 - val_accuracy: 0.9837\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 0.0365 - val_accuracy: 0.9887\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.0368 - val_accuracy: 0.9892\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0255 - accuracy: 0.9907 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0345 - val_accuracy: 0.9896\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0362 - val_accuracy: 0.9890\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 0.0307 - val_accuracy: 0.9919\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.0493 - val_accuracy: 0.9852\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0310 - accuracy: 0.9904 - val_loss: 0.0424 - val_accuracy: 0.9867\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0290 - val_accuracy: 0.9917\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 0.0644 - val_accuracy: 0.9798\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.0321 - val_accuracy: 0.9908\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0264 - val_accuracy: 0.9912\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0132 - accuracy: 0.9950 - val_loss: 0.0232 - val_accuracy: 0.9931\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0309 - val_accuracy: 0.9904\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0122 - accuracy: 0.9950 - val_loss: 0.0258 - val_accuracy: 0.9923\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0219 - val_accuracy: 0.9923\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0520 - val_accuracy: 0.9858\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0207 - val_accuracy: 0.9933\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0299 - accuracy: 0.9925 - val_loss: 0.0255 - val_accuracy: 0.9923\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0220 - val_accuracy: 0.9925\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0210 - val_accuracy: 0.9933\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0279 - val_accuracy: 0.9912\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.0185 - val_accuracy: 0.9937\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0169 - val_accuracy: 0.9944\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0187 - val_accuracy: 0.9940\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0177 - val_accuracy: 0.9948\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0295 - val_accuracy: 0.9921\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.0199 - val_accuracy: 0.9933\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0186 - val_accuracy: 0.9940\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0200 - val_accuracy: 0.9925\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0169 - val_accuracy: 0.9950\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0146 - val_accuracy: 0.9952\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0145 - val_accuracy: 0.9950\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0127 - val_accuracy: 0.9967\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0132 - val_accuracy: 0.9962\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0150 - val_accuracy: 0.9950\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9950\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9973\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 43s 379ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0127 - val_accuracy: 0.9967\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0294 - val_accuracy: 0.9912\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0152 - val_accuracy: 0.9952\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0112 - val_accuracy: 0.9967\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9956\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 8.2618e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9950\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 6.9306e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9958\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 9.4446e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0522 - val_accuracy: 0.9846\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.1076 - accuracy: 0.9789 - val_loss: 0.0235 - val_accuracy: 0.9925\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0139 - val_accuracy: 0.9958\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9967\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9967\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9977\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9965\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9965\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 9.0613e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 8.7953e-04 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9967\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 7.4376e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 8.3201e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9973\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 6.7652e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 6.1086e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9979\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 5.7393e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9975\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 5.1533e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9975\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.7477e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9975\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.6588e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9983\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.5441e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 3.8587e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 3.8962e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9983\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 3.8072e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9981\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 3.3915e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.8543e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.8860e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9977\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.7788e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.5353e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.4116e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9981\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.0879e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.9324e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.0014e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.0778e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9977\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.5072e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.3257 - accuracy: 0.9368 - val_loss: 0.1009 - val_accuracy: 0.9702\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0538 - accuracy: 0.9842 - val_loss: 0.0310 - val_accuracy: 0.9902\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.0131 - val_accuracy: 0.9954\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0092 - val_accuracy: 0.9965\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0080 - val_accuracy: 0.9971\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9977\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9975\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9979\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 9.8257e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 9.0304e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 8.2378e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 7.6204e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9977\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 7.0911e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 6.6293e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 6.1234e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9979\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 5.7741e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 5.4412e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9979\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 5.0532e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.8499e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9979\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.7956e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9981\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.2204e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9981\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.9726e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9979\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.7118e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9979\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 3.5268e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.3835e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.2764e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9979\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.9953e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 2.8822e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9973\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.7354e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9979\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.5490e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9973\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 2.4163e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9973\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.2400e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 2.2423e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 1.9873e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 41s 362ms/step - loss: 1.8938e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9979\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 1.9441e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.6391e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9971\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 1.6689e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9975\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 1.5111e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 1.4228e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9975\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 1.3931e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 1.3344e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9979\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 1.1795e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9977\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.1967e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9975\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.0488e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 9.5912e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9975\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 1.0188e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 8.9542e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9975\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 8.5174e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9975\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 7.4058e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 7.2889e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9975\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 6.6478e-05 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9975\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 6.1608e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9975\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 5.7775e-05 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9975\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 5.6226e-05 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9973\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 5.3284e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9975\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 4.6533e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9975\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 4.9577e-05 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9975\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 4.2798e-05 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9975\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.8019e-05 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9979\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.5550e-05 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9975\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 3.6443e-05 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9977\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.2356e-05 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9977\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.0787e-05 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.8793e-05 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9975\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 2.8638e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9975\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 2.4673e-05 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9975\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_104 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_104 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                2086      \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,152\n",
      "Trainable params: 1,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 1128, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 46s 358ms/step - loss: 0.6922 - accuracy: 0.5301 - val_loss: 0.6873 - val_accuracy: 0.5567\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.6643 - accuracy: 0.6044 - val_loss: 0.6128 - val_accuracy: 0.6879\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.5069 - accuracy: 0.7607 - val_loss: 0.4104 - val_accuracy: 0.8346\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.3337 - accuracy: 0.8726 - val_loss: 0.3024 - val_accuracy: 0.8858\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.2581 - accuracy: 0.9056 - val_loss: 0.2161 - val_accuracy: 0.9225\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.1972 - accuracy: 0.9326 - val_loss: 0.1777 - val_accuracy: 0.9419\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.1699 - accuracy: 0.9432 - val_loss: 0.1882 - val_accuracy: 0.9373\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.1647 - accuracy: 0.9458 - val_loss: 0.1503 - val_accuracy: 0.9546\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.1427 - accuracy: 0.9521 - val_loss: 0.1419 - val_accuracy: 0.9554\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.1306 - accuracy: 0.9593 - val_loss: 0.2297 - val_accuracy: 0.9177\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.1302 - accuracy: 0.9589 - val_loss: 0.1189 - val_accuracy: 0.9648\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 0.1107 - accuracy: 0.9656 - val_loss: 0.1514 - val_accuracy: 0.9525\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.1059 - accuracy: 0.9681 - val_loss: 0.1030 - val_accuracy: 0.9702\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0972 - accuracy: 0.9715 - val_loss: 0.1011 - val_accuracy: 0.9690\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.1021 - accuracy: 0.9678 - val_loss: 0.1147 - val_accuracy: 0.9631\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0976 - accuracy: 0.9681 - val_loss: 0.0910 - val_accuracy: 0.9742\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0829 - accuracy: 0.9756 - val_loss: 0.0945 - val_accuracy: 0.9710\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 0.1032 - val_accuracy: 0.9675\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0993 - accuracy: 0.9701 - val_loss: 0.1168 - val_accuracy: 0.9702\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0827 - accuracy: 0.9736 - val_loss: 0.0705 - val_accuracy: 0.9800\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0841 - accuracy: 0.9736 - val_loss: 0.0812 - val_accuracy: 0.9737\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0651 - accuracy: 0.9810 - val_loss: 0.0727 - val_accuracy: 0.9783\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0709 - accuracy: 0.9792 - val_loss: 0.0707 - val_accuracy: 0.9790\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0660 - accuracy: 0.9804 - val_loss: 0.0812 - val_accuracy: 0.9742\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0615 - accuracy: 0.9821 - val_loss: 0.0657 - val_accuracy: 0.9808\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0547 - accuracy: 0.9837 - val_loss: 0.0621 - val_accuracy: 0.9817\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0504 - accuracy: 0.9857 - val_loss: 0.0618 - val_accuracy: 0.9812\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0599 - accuracy: 0.9831 - val_loss: 0.1030 - val_accuracy: 0.9704\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.0947 - val_accuracy: 0.9698\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0653 - accuracy: 0.9796 - val_loss: 0.0589 - val_accuracy: 0.9827\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0522 - accuracy: 0.9829 - val_loss: 0.0633 - val_accuracy: 0.9821\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0484 - accuracy: 0.9860 - val_loss: 0.0986 - val_accuracy: 0.9729\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0540 - accuracy: 0.9829 - val_loss: 0.0614 - val_accuracy: 0.9821\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 40s 351ms/step - loss: 0.0424 - accuracy: 0.9867 - val_loss: 0.0481 - val_accuracy: 0.9865\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.0489 - val_accuracy: 0.9865\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0394 - accuracy: 0.9890 - val_loss: 0.0521 - val_accuracy: 0.9850\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0469 - accuracy: 0.9842 - val_loss: 0.0489 - val_accuracy: 0.9860\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0376 - accuracy: 0.9881 - val_loss: 0.0475 - val_accuracy: 0.9862\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0446 - accuracy: 0.9872 - val_loss: 0.0434 - val_accuracy: 0.9867\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0415 - accuracy: 0.9865 - val_loss: 0.0537 - val_accuracy: 0.9837\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0446 - accuracy: 0.9862 - val_loss: 0.0591 - val_accuracy: 0.9823\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.0937 - val_accuracy: 0.9712\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0322 - accuracy: 0.9906 - val_loss: 0.0518 - val_accuracy: 0.9848\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.1733 - val_accuracy: 0.9435\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0453 - accuracy: 0.9850 - val_loss: 0.0415 - val_accuracy: 0.9881\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0348 - accuracy: 0.9892 - val_loss: 0.0409 - val_accuracy: 0.9875\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0300 - accuracy: 0.9907 - val_loss: 0.0527 - val_accuracy: 0.9844\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0316 - accuracy: 0.9910 - val_loss: 0.0378 - val_accuracy: 0.9894\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.0533 - val_accuracy: 0.9852\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.0434 - val_accuracy: 0.9890\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.0421 - val_accuracy: 0.9875\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0411 - accuracy: 0.9876 - val_loss: 0.0388 - val_accuracy: 0.9900\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.0420 - val_accuracy: 0.9887\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0363 - val_accuracy: 0.9902\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0248 - accuracy: 0.9932 - val_loss: 0.0497 - val_accuracy: 0.9871\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 0.0464 - val_accuracy: 0.9875\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.0346 - val_accuracy: 0.9906\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0435 - accuracy: 0.9862 - val_loss: 0.0367 - val_accuracy: 0.9896\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.0350 - val_accuracy: 0.9896\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.0323 - val_accuracy: 0.9908\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0200 - accuracy: 0.9918 - val_loss: 0.0372 - val_accuracy: 0.9898\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0315 - val_accuracy: 0.9908\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0329 - val_accuracy: 0.9902\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0310 - val_accuracy: 0.9908\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0322 - val_accuracy: 0.9906\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.0445 - val_accuracy: 0.9894\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0429 - val_accuracy: 0.9879\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0141 - accuracy: 0.9944 - val_loss: 0.0357 - val_accuracy: 0.9908\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 40s 351ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0489 - val_accuracy: 0.9848\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0371 - val_accuracy: 0.9912\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0317 - accuracy: 0.9903 - val_loss: 0.0761 - val_accuracy: 0.9804\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 40s 351ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0275 - val_accuracy: 0.9923\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0073 - accuracy: 0.9971 - val_loss: 0.0429 - val_accuracy: 0.9902\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0296 - val_accuracy: 0.9921\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0088 - accuracy: 0.9961 - val_loss: 0.0267 - val_accuracy: 0.9915\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.0258 - val_accuracy: 0.9915\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.0281 - val_accuracy: 0.9900\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0308 - val_accuracy: 0.9923\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0279 - val_accuracy: 0.9919\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0290 - val_accuracy: 0.9917\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0295 - val_accuracy: 0.9919\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.0288 - val_accuracy: 0.9925\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0266 - val_accuracy: 0.9925\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0282 - val_accuracy: 0.9931\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0310 - val_accuracy: 0.9919\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0350 - val_accuracy: 0.9921\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0257 - val_accuracy: 0.9923\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9931\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 8.5944e-04 - accuracy: 0.9999 - val_loss: 0.0252 - val_accuracy: 0.9942\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 4.7463e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 5.2683e-04 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9942\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.1585e-04 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9942\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 3.0429e-04 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9937\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.3930e-04 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9940\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.8770e-04 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9937\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.7418e-04 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9937\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.4770e-04 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9937\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.3484e-04 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9942\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.1926e-04 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9937\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.1168e-04 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9942\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.0803e-04 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9942\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.0793e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9942\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 9.4181e-05 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9942\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 8.6566e-05 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9942\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 6.8389e-05 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9942\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 6.3570e-05 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9942\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 6.7340e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9937\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 5.1704e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9942\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 5.3570e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9944\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 4.7088e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9942\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.1893e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9944\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 3.8678e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9942\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 4.3462e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9944\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.3052e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9942\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 3.0526e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9942\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 2.8401e-05 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9944\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.7207e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9940\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.5400e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9944\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 2.3169e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9940\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.1041e-05 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9942\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 2.0715e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9940\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 1.9717e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 40s 356ms/step - loss: 2.1664e-05 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9944\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.7748e-05 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9940\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.5351e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9940\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.9628e-05 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9940\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.1202 - accuracy: 0.9856 - val_loss: 0.4611 - val_accuracy: 0.9302\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0820 - accuracy: 0.9812 - val_loss: 0.0346 - val_accuracy: 0.9904\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.0263 - val_accuracy: 0.9923\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0250 - val_accuracy: 0.9927\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0225 - val_accuracy: 0.9933\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0237 - val_accuracy: 0.9929\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0310 - val_accuracy: 0.9925\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0227 - val_accuracy: 0.9935\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9931\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0364 - val_accuracy: 0.9917\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 9.8045e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9929\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 7.2398e-04 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9923\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 6.2266e-04 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9933\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 4.8822e-04 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9937\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 3.8939e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9935\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 3.3949e-04 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9933\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 3.0018e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9933\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.9417e-04 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9929\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.5890e-04 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9931\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.1598e-04 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9937\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 2.0267e-04 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9937\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 1.9052e-04 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9935\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 1.7032e-04 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9931\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.5113e-04 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9933\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.4946e-04 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9931\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 1.6664e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9933\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 1.1722e-04 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9937\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 1.0257e-04 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9935\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 40s 351ms/step - loss: 1.0034e-04 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9935\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 8.3942e-05 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9935\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 7.8449e-05 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9933\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 7.4426e-05 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9931\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 6.9118e-05 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9931\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 6.2042e-05 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9935\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 5.6441e-05 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9935\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 5.1177e-05 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9935\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 4.9147e-05 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9935\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 4.5206e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9935\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 4.0815e-05 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9935\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 3.8744e-05 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9933\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 3.8931e-05 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9935\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 3.5024e-05 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9937\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.9937e-05 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9937\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 2.8881e-05 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9937\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 2.6986e-05 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9937\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 2.6771e-05 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9937\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.3984e-05 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9942\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 2.0731e-05 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9940\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 2.1637e-05 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9940\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 2.0836e-05 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9942\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.6361e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9942\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 40s 355ms/step - loss: 1.6058e-05 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9940\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 40s 353ms/step - loss: 1.4718e-05 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9937\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 40s 354ms/step - loss: 1.4234e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9942\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 40s 352ms/step - loss: 1.3429e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9942\n",
      "250/250 [==============================] - 20s 69ms/step - loss: 0.0175 - accuracy: 0.9940\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_105 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_105 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                2086      \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,152\n",
      "Trainable params: 1,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 1128, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 48s 364ms/step - loss: 0.6831 - accuracy: 0.5597 - val_loss: 0.6640 - val_accuracy: 0.6167\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.6047 - accuracy: 0.6746 - val_loss: 0.5146 - val_accuracy: 0.7583\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.4308 - accuracy: 0.8107 - val_loss: 0.3819 - val_accuracy: 0.8462\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.3370 - accuracy: 0.8667 - val_loss: 0.2918 - val_accuracy: 0.8952\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.2728 - accuracy: 0.8982 - val_loss: 0.2656 - val_accuracy: 0.9038\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.2377 - accuracy: 0.9131 - val_loss: 0.2274 - val_accuracy: 0.9200\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.2279 - accuracy: 0.9172 - val_loss: 0.3018 - val_accuracy: 0.8813\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.2101 - accuracy: 0.9254 - val_loss: 0.2051 - val_accuracy: 0.9287\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1890 - accuracy: 0.9354 - val_loss: 0.1952 - val_accuracy: 0.9337\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.1986 - accuracy: 0.9336 - val_loss: 0.2515 - val_accuracy: 0.9040\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1842 - accuracy: 0.9364 - val_loss: 0.1840 - val_accuracy: 0.9400\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1739 - accuracy: 0.9417 - val_loss: 0.1723 - val_accuracy: 0.9454\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1706 - accuracy: 0.9426 - val_loss: 0.2110 - val_accuracy: 0.9285\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1644 - accuracy: 0.9446 - val_loss: 0.1629 - val_accuracy: 0.9454\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.1578 - accuracy: 0.9489 - val_loss: 0.1540 - val_accuracy: 0.9490\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.1514 - accuracy: 0.9490 - val_loss: 0.1596 - val_accuracy: 0.9479\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1534 - accuracy: 0.9515 - val_loss: 0.1576 - val_accuracy: 0.9483\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1429 - accuracy: 0.9524 - val_loss: 0.1409 - val_accuracy: 0.9560\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.1512 - accuracy: 0.9507 - val_loss: 0.1587 - val_accuracy: 0.9471\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.1331 - accuracy: 0.9565 - val_loss: 0.1430 - val_accuracy: 0.9535\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.1307 - accuracy: 0.9576 - val_loss: 0.1387 - val_accuracy: 0.9569\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1259 - accuracy: 0.9596 - val_loss: 0.1274 - val_accuracy: 0.9623\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1269 - accuracy: 0.9604 - val_loss: 0.1275 - val_accuracy: 0.9594\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1187 - accuracy: 0.9635 - val_loss: 0.1221 - val_accuracy: 0.9617\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.1375 - accuracy: 0.9539 - val_loss: 0.1242 - val_accuracy: 0.9619\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1108 - accuracy: 0.9646 - val_loss: 0.1106 - val_accuracy: 0.9660\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1163 - accuracy: 0.9631 - val_loss: 0.1448 - val_accuracy: 0.9508\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.1154 - accuracy: 0.9633 - val_loss: 0.1029 - val_accuracy: 0.9685\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.1069 - accuracy: 0.9650 - val_loss: 0.1034 - val_accuracy: 0.9667\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0972 - accuracy: 0.9699 - val_loss: 0.1292 - val_accuracy: 0.9588\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.1127 - accuracy: 0.9639 - val_loss: 0.1175 - val_accuracy: 0.9621\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.1002 - accuracy: 0.9701 - val_loss: 0.1129 - val_accuracy: 0.9644\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0863 - accuracy: 0.9740 - val_loss: 0.0919 - val_accuracy: 0.9731\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0802 - accuracy: 0.9772 - val_loss: 0.1159 - val_accuracy: 0.9625\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0805 - accuracy: 0.9760 - val_loss: 0.0977 - val_accuracy: 0.9681\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.0801 - accuracy: 0.9765 - val_loss: 0.1141 - val_accuracy: 0.9669\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0822 - accuracy: 0.9737 - val_loss: 0.0777 - val_accuracy: 0.9771\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0682 - accuracy: 0.9808 - val_loss: 0.0745 - val_accuracy: 0.9762\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.0735 - accuracy: 0.9762 - val_loss: 0.0781 - val_accuracy: 0.9762\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0658 - accuracy: 0.9806 - val_loss: 0.0748 - val_accuracy: 0.9771\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0740 - accuracy: 0.9757 - val_loss: 0.0661 - val_accuracy: 0.9798\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0555 - accuracy: 0.9837 - val_loss: 0.0640 - val_accuracy: 0.9783\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0554 - accuracy: 0.9832 - val_loss: 0.0648 - val_accuracy: 0.9790\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0532 - accuracy: 0.9843 - val_loss: 0.0615 - val_accuracy: 0.9804\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0480 - accuracy: 0.9864 - val_loss: 0.0572 - val_accuracy: 0.9810\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0442 - accuracy: 0.9869 - val_loss: 0.0592 - val_accuracy: 0.9808\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0589 - accuracy: 0.9815 - val_loss: 0.0497 - val_accuracy: 0.9831\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.0574 - val_accuracy: 0.9835\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0412 - accuracy: 0.9876 - val_loss: 0.0587 - val_accuracy: 0.9827\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0352 - accuracy: 0.9904 - val_loss: 0.0577 - val_accuracy: 0.9831\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.0368 - accuracy: 0.9886 - val_loss: 0.0427 - val_accuracy: 0.9873\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0324 - accuracy: 0.9904 - val_loss: 0.0456 - val_accuracy: 0.9840\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 0.0373 - val_accuracy: 0.9879\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.0760 - val_accuracy: 0.9794\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 0.0548 - val_accuracy: 0.9812\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0387 - val_accuracy: 0.9885\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0325 - accuracy: 0.9907 - val_loss: 0.0355 - val_accuracy: 0.9892\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.0349 - val_accuracy: 0.9881\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0386 - val_accuracy: 0.9883\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0279 - accuracy: 0.9911 - val_loss: 0.0382 - val_accuracy: 0.9902\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.0269 - val_accuracy: 0.9919\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0165 - accuracy: 0.9961 - val_loss: 0.0276 - val_accuracy: 0.9917\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0360 - val_accuracy: 0.9892\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.0263 - val_accuracy: 0.9929\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.0246 - val_accuracy: 0.9937\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.0269 - val_accuracy: 0.9929\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0249 - val_accuracy: 0.9952\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.0325 - val_accuracy: 0.9915\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.0254 - val_accuracy: 0.9929\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0251 - val_accuracy: 0.9927\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.0482 - val_accuracy: 0.9883\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0217 - val_accuracy: 0.9942\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0205 - val_accuracy: 0.9952\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0364 - val_accuracy: 0.9902\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0253 - val_accuracy: 0.9929\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0371 - val_accuracy: 0.9917\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0174 - val_accuracy: 0.9946\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0367 - val_accuracy: 0.9910\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0182 - val_accuracy: 0.9952\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0196 - val_accuracy: 0.9958\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.0184 - val_accuracy: 0.9952\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0209 - val_accuracy: 0.9952\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0242 - val_accuracy: 0.9935\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0213 - val_accuracy: 0.9952\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0234 - val_accuracy: 0.9950\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 7.4529e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9954\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 5.7244e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9950\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 7.9148e-04 - accuracy: 0.9999 - val_loss: 0.0262 - val_accuracy: 0.9950\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0306 - val_accuracy: 0.9942\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0437 - val_accuracy: 0.9906\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.0225 - val_accuracy: 0.9952\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0835 - val_accuracy: 0.9852\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0228 - val_accuracy: 0.9950\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0446 - val_accuracy: 0.9902\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0431 - accuracy: 0.9892 - val_loss: 0.0211 - val_accuracy: 0.9946\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0191 - val_accuracy: 0.9950\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0208 - val_accuracy: 0.9954\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0263 - val_accuracy: 0.9935\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 4.8265e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9960\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 3.3703e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9960\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 2.3957e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9965\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 2.1737e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9954\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0681 - accuracy: 0.9885 - val_loss: 0.0666 - val_accuracy: 0.9760\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0214 - accuracy: 0.9943 - val_loss: 0.0191 - val_accuracy: 0.9950\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0136 - val_accuracy: 0.9958\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0131 - val_accuracy: 0.9962\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0110 - val_accuracy: 0.9971\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0125 - val_accuracy: 0.9958\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 7.2145e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9967\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 5.2322e-04 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9973\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 4.0059e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9969\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 2.9205e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9962\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 2.6744e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9969\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 2.2393e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9969\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 1.8555e-04 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9975\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.6239e-04 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9971\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 1.4483e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9973\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.2854e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9971\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.2814e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9971\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 41s 363ms/step - loss: 9.6869e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9971\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 8.7273e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9977\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 8.0339e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9975\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 7.3953e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 6.3417e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9977\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 5.7921e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9977\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 5.5264e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9975\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 4.7774e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9975\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 4.4626e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9975\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 4.2085e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9975\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 3.7454e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9975\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 3.4196e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9975\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 3.2279e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 2.9196e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9975\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 2.7916e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9975\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 2.5317e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 2.2476e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 2.1326e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9975\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 1.9918e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9975\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.8020e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9975\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 1.6748e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 1.5523e-05 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9975\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 1.4383e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9975\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 1.3460e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9975\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 1.1979e-05 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9975\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 1.1377e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 1.0756e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9975\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 9.7314e-06 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9975\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 9.4930e-06 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9975\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 41s 361ms/step - loss: 8.4005e-06 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9975\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 8.0195e-06 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9975\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 7.4032e-06 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9975\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 6.9975e-06 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9975\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 6.5192e-06 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9975\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 6.0263e-06 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9975\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 41s 360ms/step - loss: 5.6354e-06 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9975\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 5.3329e-06 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9975\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 4.7797e-06 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9975\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0119 - accuracy: 0.9961\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_106 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_106 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                2086      \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,152\n",
      "Trainable params: 1,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 1128, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 46s 363ms/step - loss: 0.6920 - accuracy: 0.5253 - val_loss: 0.6881 - val_accuracy: 0.5263\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.6585 - accuracy: 0.6258 - val_loss: 0.5980 - val_accuracy: 0.6967\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.4690 - accuracy: 0.7843 - val_loss: 0.3889 - val_accuracy: 0.8473\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.3342 - accuracy: 0.8661 - val_loss: 0.3128 - val_accuracy: 0.8829\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.2757 - accuracy: 0.8986 - val_loss: 0.2576 - val_accuracy: 0.9044\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.2437 - accuracy: 0.9133 - val_loss: 0.2139 - val_accuracy: 0.9273\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.2266 - accuracy: 0.9218 - val_loss: 0.1985 - val_accuracy: 0.9360\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.2074 - accuracy: 0.9297 - val_loss: 0.1918 - val_accuracy: 0.9340\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1925 - accuracy: 0.9361 - val_loss: 0.1825 - val_accuracy: 0.9446\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1851 - accuracy: 0.9413 - val_loss: 0.1924 - val_accuracy: 0.9362\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1836 - accuracy: 0.9401 - val_loss: 0.1633 - val_accuracy: 0.9483\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1693 - accuracy: 0.9464 - val_loss: 0.1794 - val_accuracy: 0.9440\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1714 - accuracy: 0.9444 - val_loss: 0.1571 - val_accuracy: 0.9519\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1572 - accuracy: 0.9500 - val_loss: 0.1557 - val_accuracy: 0.9519\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1883 - accuracy: 0.9367 - val_loss: 0.2381 - val_accuracy: 0.9104\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1674 - accuracy: 0.9442 - val_loss: 0.1655 - val_accuracy: 0.9458\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1558 - accuracy: 0.9521 - val_loss: 0.1464 - val_accuracy: 0.9546\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1493 - accuracy: 0.9531 - val_loss: 0.1399 - val_accuracy: 0.9563\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1421 - accuracy: 0.9549 - val_loss: 0.1388 - val_accuracy: 0.9569\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1434 - accuracy: 0.9539 - val_loss: 0.1417 - val_accuracy: 0.9560\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1364 - accuracy: 0.9565 - val_loss: 0.1373 - val_accuracy: 0.9575\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1384 - accuracy: 0.9569 - val_loss: 0.1478 - val_accuracy: 0.9540\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1336 - accuracy: 0.9568 - val_loss: 0.1233 - val_accuracy: 0.9627\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1251 - accuracy: 0.9625 - val_loss: 0.1208 - val_accuracy: 0.9633\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1259 - accuracy: 0.9607 - val_loss: 0.1221 - val_accuracy: 0.9635\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1224 - accuracy: 0.9624 - val_loss: 0.1189 - val_accuracy: 0.9656\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1162 - accuracy: 0.9649 - val_loss: 0.1176 - val_accuracy: 0.9648\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1174 - accuracy: 0.9671 - val_loss: 0.1071 - val_accuracy: 0.9694\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1065 - accuracy: 0.9689 - val_loss: 0.1038 - val_accuracy: 0.9685\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.1083 - accuracy: 0.9689 - val_loss: 0.0990 - val_accuracy: 0.9712\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1156 - accuracy: 0.9651 - val_loss: 0.1059 - val_accuracy: 0.9715\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0973 - accuracy: 0.9721 - val_loss: 0.0985 - val_accuracy: 0.9721\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0920 - accuracy: 0.9740 - val_loss: 0.0904 - val_accuracy: 0.9754\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.1120 - accuracy: 0.9667 - val_loss: 0.0912 - val_accuracy: 0.9731\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0958 - accuracy: 0.9712 - val_loss: 0.1071 - val_accuracy: 0.9702\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0900 - accuracy: 0.9724 - val_loss: 0.1209 - val_accuracy: 0.9629\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0829 - accuracy: 0.9760 - val_loss: 0.0806 - val_accuracy: 0.9785\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0806 - accuracy: 0.9772 - val_loss: 0.0892 - val_accuracy: 0.9731\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0787 - accuracy: 0.9762 - val_loss: 0.0808 - val_accuracy: 0.9754\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0700 - accuracy: 0.9806 - val_loss: 0.0801 - val_accuracy: 0.9781\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0732 - accuracy: 0.9782 - val_loss: 0.0758 - val_accuracy: 0.9781\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0692 - accuracy: 0.9796 - val_loss: 0.1267 - val_accuracy: 0.9615\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0818 - accuracy: 0.9756 - val_loss: 0.0744 - val_accuracy: 0.9796\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0695 - accuracy: 0.9787 - val_loss: 0.0792 - val_accuracy: 0.9773\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0603 - accuracy: 0.9828 - val_loss: 0.0627 - val_accuracy: 0.9831\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.0604 - val_accuracy: 0.9835\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0700 - val_accuracy: 0.9808\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0562 - accuracy: 0.9832 - val_loss: 0.0595 - val_accuracy: 0.9831\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 0.0781 - val_accuracy: 0.9790\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0458 - accuracy: 0.9869 - val_loss: 0.0558 - val_accuracy: 0.9869\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0549 - accuracy: 0.9819 - val_loss: 0.0762 - val_accuracy: 0.9771\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 0.0499 - val_accuracy: 0.9873\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0405 - accuracy: 0.9875 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.0605 - val_accuracy: 0.9829\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0472 - accuracy: 0.9856 - val_loss: 0.0563 - val_accuracy: 0.9837\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.0481 - val_accuracy: 0.9869\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0463 - val_accuracy: 0.9890\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.0432 - val_accuracy: 0.9881\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0281 - accuracy: 0.9907 - val_loss: 0.0582 - val_accuracy: 0.9852\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0399 - val_accuracy: 0.9896\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0434 - val_accuracy: 0.9885\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.1027 - val_accuracy: 0.9708\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 0.0404 - val_accuracy: 0.9892\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.0417 - val_accuracy: 0.9898\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0354 - val_accuracy: 0.9898\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0466 - val_accuracy: 0.9879\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0399 - val_accuracy: 0.9900\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0485 - val_accuracy: 0.9892\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0352 - val_accuracy: 0.9904\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 0.0307 - val_accuracy: 0.9906\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0252 - val_accuracy: 0.9929\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.0294 - val_accuracy: 0.9906\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0311 - val_accuracy: 0.9919\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.0558 - val_accuracy: 0.9852\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0271 - val_accuracy: 0.9929\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0267 - val_accuracy: 0.9925\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0248 - val_accuracy: 0.9931\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0454 - val_accuracy: 0.9904\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.0680 - val_accuracy: 0.9865\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0241 - val_accuracy: 0.9927\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0265 - val_accuracy: 0.9923\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.0302 - val_accuracy: 0.9925\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0096 - accuracy: 0.9958 - val_loss: 0.0267 - val_accuracy: 0.9929\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0309 - val_accuracy: 0.9919\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0282 - val_accuracy: 0.9921\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0229 - val_accuracy: 0.9940\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0227 - val_accuracy: 0.9931\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0243 - val_accuracy: 0.9942\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0335 - val_accuracy: 0.9927\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.0404 - val_accuracy: 0.9892\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0504 - val_accuracy: 0.9896\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0126 - accuracy: 0.9950 - val_loss: 0.0588 - val_accuracy: 0.9867\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.0583 - val_accuracy: 0.9829\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.0492 - val_accuracy: 0.9879\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0376 - val_accuracy: 0.9912\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0284 - val_accuracy: 0.9925\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0252 - val_accuracy: 0.9935\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9933\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 7.5693e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9948\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 4.8771e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9948\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 3.8446e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9952\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 4.7034e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9950\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 3.5374e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9952\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 2.9832e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9954\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 2.6367e-04 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9952\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 2.4231e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9952\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 1.9597e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9950\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.6168e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9950\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.4504e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9950\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.4023e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9950\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.1635e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9948\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.0299e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9950\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 9.5992e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9948\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 8.7222e-05 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9948\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 7.9042e-05 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9952\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 7.7436e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9950\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 7.1841e-05 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9952\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 6.3188e-05 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9944\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 5.4866e-05 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9952\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 5.2205e-05 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9952\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 4.6991e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9948\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 4.4299e-05 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9946\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 3.9328e-05 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9948\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 3.9288e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9950\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 3.6495e-05 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9944\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 3.2780e-05 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9952\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 3.1405e-05 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9948\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 2.6912e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9954\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 40s 357ms/step - loss: 2.7336e-05 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9944\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 2.3737e-05 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9946\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 2.2193e-05 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9948\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.9880e-05 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9946\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.8631e-05 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9952\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 41s 359ms/step - loss: 1.7731e-05 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9954\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.6530e-05 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9950\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.5567e-05 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9942\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.4460e-05 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9946\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.3027e-05 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9942\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.2145e-05 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9946\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.1037e-05 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9944\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 1.0244e-05 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9942\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 9.4246e-06 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9948\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 9.3155e-06 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9946\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 8.8180e-06 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9942\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 7.5887e-06 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9942\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 6.9648e-06 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9942\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 6.5689e-06 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9942\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 40s 358ms/step - loss: 6.1618e-06 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9942\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 40s 359ms/step - loss: 5.4697e-06 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9944\n",
      "250/250 [==============================] - 18s 69ms/step - loss: 0.0232 - accuracy: 0.9948\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......masking\n",
      ".........vars\n",
      "......rnn\n",
      ".........cell\n",
      "............controller\n",
      "...............cells\n",
      "..................lstm_cell\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "........................2\n",
      "...............vars\n",
      "............output_layer\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............parameters_layer\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............read_layers\n",
      "...............dense\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_1\n",
      "..................vars\n",
      ".....................0\n",
      "............vars\n",
      "...............0\n",
      "............w_layers\n",
      "...............dense\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_1\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_2\n",
      "..................vars\n",
      ".....................0\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-27 09:54:27        82448\n",
      "config.json                                    2023-03-27 09:54:27         2128\n",
      "metadata.json                                  2023-03-27 09:54:27           64\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_107 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_107 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, 13)                1976      \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,052\n",
      "Trainable params: 2,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 5s 18ms/step - loss: 0.7018 - accuracy: 0.5017 - val_loss: 0.6993 - val_accuracy: 0.4969\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6947 - accuracy: 0.5069 - val_loss: 0.6967 - val_accuracy: 0.4942\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6926 - accuracy: 0.5242 - val_loss: 0.6956 - val_accuracy: 0.5040\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6910 - accuracy: 0.5288 - val_loss: 0.6949 - val_accuracy: 0.5110\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6897 - accuracy: 0.5371 - val_loss: 0.6942 - val_accuracy: 0.5183\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6860 - accuracy: 0.5549 - val_loss: 0.6836 - val_accuracy: 0.5642\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5994 - accuracy: 0.7076 - val_loss: 0.5003 - val_accuracy: 0.7977\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4659 - accuracy: 0.8053 - val_loss: 0.4022 - val_accuracy: 0.8473\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3991 - accuracy: 0.8425 - val_loss: 0.3690 - val_accuracy: 0.8583\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3557 - accuracy: 0.8650 - val_loss: 0.3538 - val_accuracy: 0.8652\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3255 - accuracy: 0.8789 - val_loss: 0.3260 - val_accuracy: 0.8792\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3368 - accuracy: 0.8681 - val_loss: 0.3137 - val_accuracy: 0.8840\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2868 - accuracy: 0.8942 - val_loss: 0.2842 - val_accuracy: 0.8996\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2523 - accuracy: 0.9106 - val_loss: 0.2614 - val_accuracy: 0.9100\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2481 - accuracy: 0.9133 - val_loss: 0.2446 - val_accuracy: 0.9156\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2423 - accuracy: 0.9146 - val_loss: 0.2890 - val_accuracy: 0.8794\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2274 - accuracy: 0.9224 - val_loss: 0.2421 - val_accuracy: 0.9194\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2401 - accuracy: 0.9135 - val_loss: 0.2245 - val_accuracy: 0.9244\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2006 - accuracy: 0.9332 - val_loss: 0.2895 - val_accuracy: 0.9004\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1981 - accuracy: 0.9346 - val_loss: 0.3200 - val_accuracy: 0.8881\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2148 - accuracy: 0.9258 - val_loss: 0.2074 - val_accuracy: 0.9317\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1956 - accuracy: 0.9358 - val_loss: 0.2288 - val_accuracy: 0.9102\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1795 - accuracy: 0.9440 - val_loss: 0.2471 - val_accuracy: 0.8979\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1778 - accuracy: 0.9422 - val_loss: 0.1812 - val_accuracy: 0.9390\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1896 - accuracy: 0.9368 - val_loss: 0.1970 - val_accuracy: 0.9350\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1836 - accuracy: 0.9368 - val_loss: 0.5832 - val_accuracy: 0.7396\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2113 - accuracy: 0.9279 - val_loss: 0.1642 - val_accuracy: 0.9502\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1906 - accuracy: 0.9340 - val_loss: 0.1652 - val_accuracy: 0.9485\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1742 - accuracy: 0.9422 - val_loss: 0.1760 - val_accuracy: 0.9392\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1466 - accuracy: 0.9549 - val_loss: 0.1494 - val_accuracy: 0.9519\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1328 - accuracy: 0.9604 - val_loss: 0.1723 - val_accuracy: 0.9381\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1516 - accuracy: 0.9514 - val_loss: 0.1415 - val_accuracy: 0.9563\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1784 - accuracy: 0.9417 - val_loss: 0.1485 - val_accuracy: 0.9527\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1502 - accuracy: 0.9524 - val_loss: 0.2655 - val_accuracy: 0.8917\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1553 - accuracy: 0.9515 - val_loss: 0.1436 - val_accuracy: 0.9571\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1248 - accuracy: 0.9606 - val_loss: 0.2040 - val_accuracy: 0.9187\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1168 - accuracy: 0.9640 - val_loss: 0.1242 - val_accuracy: 0.9592\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1187 - accuracy: 0.9644 - val_loss: 0.1166 - val_accuracy: 0.9650\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1045 - accuracy: 0.9700 - val_loss: 0.1169 - val_accuracy: 0.9648\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1091 - accuracy: 0.9675 - val_loss: 0.1195 - val_accuracy: 0.9648\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1380 - accuracy: 0.9560 - val_loss: 0.1327 - val_accuracy: 0.9588\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1064 - accuracy: 0.9679 - val_loss: 0.1532 - val_accuracy: 0.9560\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0965 - accuracy: 0.9708 - val_loss: 0.1077 - val_accuracy: 0.9688\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0938 - accuracy: 0.9718 - val_loss: 0.1117 - val_accuracy: 0.9671\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0850 - accuracy: 0.9750 - val_loss: 0.1235 - val_accuracy: 0.9554\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1508 - accuracy: 0.9544 - val_loss: 0.1444 - val_accuracy: 0.9498\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2948 - accuracy: 0.9087 - val_loss: 1.1672 - val_accuracy: 0.5512\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.7157 - accuracy: 0.5707 - val_loss: 0.6300 - val_accuracy: 0.5946\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6007 - accuracy: 0.6313 - val_loss: 0.5681 - val_accuracy: 0.6654\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4387 - accuracy: 0.7910 - val_loss: 0.3305 - val_accuracy: 0.8673\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2690 - accuracy: 0.9036 - val_loss: 0.2313 - val_accuracy: 0.9215\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2026 - accuracy: 0.9317 - val_loss: 0.1868 - val_accuracy: 0.9400\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1686 - accuracy: 0.9469 - val_loss: 0.1629 - val_accuracy: 0.9485\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1420 - accuracy: 0.9563 - val_loss: 0.1445 - val_accuracy: 0.9544\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1234 - accuracy: 0.9631 - val_loss: 0.1286 - val_accuracy: 0.9617\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1156 - accuracy: 0.9667 - val_loss: 0.1215 - val_accuracy: 0.9627\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1372 - accuracy: 0.9604 - val_loss: 0.4021 - val_accuracy: 0.8729\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1639 - accuracy: 0.9500 - val_loss: 0.1371 - val_accuracy: 0.9583\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1224 - accuracy: 0.9629 - val_loss: 0.1188 - val_accuracy: 0.9648\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.1167 - val_accuracy: 0.9608\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0871 - accuracy: 0.9750 - val_loss: 0.0954 - val_accuracy: 0.9712\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0757 - accuracy: 0.9785 - val_loss: 0.1270 - val_accuracy: 0.9531\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0686 - accuracy: 0.9817 - val_loss: 0.0983 - val_accuracy: 0.9663\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0717 - accuracy: 0.9807 - val_loss: 0.0790 - val_accuracy: 0.9760\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0784 - accuracy: 0.9774 - val_loss: 0.0824 - val_accuracy: 0.9758\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1187 - accuracy: 0.9671 - val_loss: 0.1412 - val_accuracy: 0.9517\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0755 - accuracy: 0.9783 - val_loss: 0.1540 - val_accuracy: 0.9417\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1021 - accuracy: 0.9681 - val_loss: 0.0923 - val_accuracy: 0.9725\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0700 - accuracy: 0.9799 - val_loss: 0.0719 - val_accuracy: 0.9800\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0589 - accuracy: 0.9843 - val_loss: 0.0793 - val_accuracy: 0.9750\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0654 - accuracy: 0.9797 - val_loss: 0.0922 - val_accuracy: 0.9702\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0569 - accuracy: 0.9850 - val_loss: 0.0811 - val_accuracy: 0.9790\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0793 - accuracy: 0.9751 - val_loss: 0.1064 - val_accuracy: 0.9696\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0521 - accuracy: 0.9849 - val_loss: 0.0769 - val_accuracy: 0.9744\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0683 - accuracy: 0.9804 - val_loss: 0.0645 - val_accuracy: 0.9810\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.0561 - val_accuracy: 0.9840\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0538 - accuracy: 0.9846 - val_loss: 0.0722 - val_accuracy: 0.9812\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0599 - accuracy: 0.9835 - val_loss: 0.0601 - val_accuracy: 0.9835\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: 0.0698 - val_accuracy: 0.9775\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0514 - accuracy: 0.9846 - val_loss: 0.0526 - val_accuracy: 0.9846\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0557 - accuracy: 0.9847 - val_loss: 0.0736 - val_accuracy: 0.9767\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0500 - accuracy: 0.9856 - val_loss: 0.0699 - val_accuracy: 0.9781\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0498 - accuracy: 0.9862 - val_loss: 0.0835 - val_accuracy: 0.9746\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0385 - accuracy: 0.9890 - val_loss: 0.0477 - val_accuracy: 0.9860\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0349 - accuracy: 0.9907 - val_loss: 0.0419 - val_accuracy: 0.9873\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0340 - accuracy: 0.9906 - val_loss: 0.0422 - val_accuracy: 0.9885\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 0.0649 - val_accuracy: 0.9821\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0521 - accuracy: 0.9842 - val_loss: 0.0498 - val_accuracy: 0.9850\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0437 - accuracy: 0.9869 - val_loss: 0.0450 - val_accuracy: 0.9846\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.0382 - val_accuracy: 0.9890\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0284 - accuracy: 0.9919 - val_loss: 0.0360 - val_accuracy: 0.9894\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 0.0857 - val_accuracy: 0.9798\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0783 - accuracy: 0.9787 - val_loss: 0.0473 - val_accuracy: 0.9862\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0408 - accuracy: 0.9879 - val_loss: 0.0395 - val_accuracy: 0.9867\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0241 - accuracy: 0.9942 - val_loss: 0.0360 - val_accuracy: 0.9883\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.0332 - val_accuracy: 0.9892\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0193 - accuracy: 0.9960 - val_loss: 0.0367 - val_accuracy: 0.9896\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0494 - accuracy: 0.9867 - val_loss: 0.0670 - val_accuracy: 0.9798\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5921 - accuracy: 0.8342 - val_loss: 0.1637 - val_accuracy: 0.9429\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1082 - accuracy: 0.9640 - val_loss: 0.0953 - val_accuracy: 0.9731\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0595 - accuracy: 0.9829 - val_loss: 0.0675 - val_accuracy: 0.9792\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0634 - accuracy: 0.9818 - val_loss: 0.0586 - val_accuracy: 0.9835\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0411 - accuracy: 0.9881 - val_loss: 0.0519 - val_accuracy: 0.9848\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0353 - accuracy: 0.9906 - val_loss: 0.0442 - val_accuracy: 0.9875\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0273 - accuracy: 0.9935 - val_loss: 0.0433 - val_accuracy: 0.9871\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0243 - accuracy: 0.9946 - val_loss: 0.0404 - val_accuracy: 0.9883\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.0405 - val_accuracy: 0.9887\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0359 - accuracy: 0.9907 - val_loss: 0.1333 - val_accuracy: 0.9700\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0307 - accuracy: 0.9918 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.0409 - val_accuracy: 0.9879\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.0582 - val_accuracy: 0.9852\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0334 - accuracy: 0.9922 - val_loss: 0.2275 - val_accuracy: 0.9544\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0719 - accuracy: 0.9821 - val_loss: 0.0403 - val_accuracy: 0.9885\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0244 - accuracy: 0.9935 - val_loss: 0.0350 - val_accuracy: 0.9906\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0570 - accuracy: 0.9846 - val_loss: 0.0446 - val_accuracy: 0.9873\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 0.0350 - val_accuracy: 0.9896\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 0.0374 - val_accuracy: 0.9904\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0592 - accuracy: 0.9853 - val_loss: 0.1147 - val_accuracy: 0.9625\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1154 - accuracy: 0.9689 - val_loss: 0.0641 - val_accuracy: 0.9785\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0317 - accuracy: 0.9915 - val_loss: 0.0321 - val_accuracy: 0.9906\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 0.0322 - val_accuracy: 0.9902\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 0.0330 - val_accuracy: 0.9904\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.0283 - val_accuracy: 0.9910\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0419 - accuracy: 0.9894 - val_loss: 0.2349 - val_accuracy: 0.9427\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1755 - accuracy: 0.9465 - val_loss: 0.1253 - val_accuracy: 0.9625\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0947 - accuracy: 0.9689 - val_loss: 0.0668 - val_accuracy: 0.9815\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0626 - accuracy: 0.9808 - val_loss: 0.0549 - val_accuracy: 0.9852\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0490 - accuracy: 0.9851 - val_loss: 0.0675 - val_accuracy: 0.9785\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0379 - accuracy: 0.9901 - val_loss: 0.0370 - val_accuracy: 0.9875\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0355 - accuracy: 0.9903 - val_loss: 0.0326 - val_accuracy: 0.9906\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0242 - accuracy: 0.9946 - val_loss: 0.0394 - val_accuracy: 0.9862\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0250 - accuracy: 0.9929 - val_loss: 0.0356 - val_accuracy: 0.9904\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 0.0459 - val_accuracy: 0.9848\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0649 - accuracy: 0.9829 - val_loss: 0.0349 - val_accuracy: 0.9894\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0197 - accuracy: 0.9957 - val_loss: 0.0254 - val_accuracy: 0.9927\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.0328 - val_accuracy: 0.9919\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0239 - val_accuracy: 0.9921\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0219 - val_accuracy: 0.9931\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1673 - accuracy: 0.9449 - val_loss: 0.0938 - val_accuracy: 0.9690\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0453 - accuracy: 0.9851 - val_loss: 0.0397 - val_accuracy: 0.9862\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 0.0314 - val_accuracy: 0.9904\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.0268 - val_accuracy: 0.9906\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0233 - val_accuracy: 0.9917\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.0255 - val_accuracy: 0.9929\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.0218 - val_accuracy: 0.9925\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0216 - val_accuracy: 0.9925\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.0241 - val_accuracy: 0.9921\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.0210 - val_accuracy: 0.9937\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0219 - val_accuracy: 0.9940\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0213 - val_accuracy: 0.9935\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0227 - val_accuracy: 0.9933\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.0266 - val_accuracy: 0.9925\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0436 - accuracy: 0.9876 - val_loss: 0.0358 - val_accuracy: 0.9900\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0279 - val_accuracy: 0.9919\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.0231 - val_accuracy: 0.9919\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0232 - val_accuracy: 0.9921\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0215 - val_accuracy: 0.9927\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0199 - val_accuracy: 0.9931\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.2287 - val_accuracy: 0.9306\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0216 - val_accuracy: 0.9933\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.0221 - val_accuracy: 0.9935\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0236 - val_accuracy: 0.9927\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0189 - val_accuracy: 0.9942\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0188 - val_accuracy: 0.9942\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0191 - val_accuracy: 0.9944\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0187 - val_accuracy: 0.9944\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0286 - val_accuracy: 0.9944\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0188 - val_accuracy: 0.9946\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.0337 - val_accuracy: 0.9933\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0310 - val_accuracy: 0.9902\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0187 - val_accuracy: 0.9937\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0204 - val_accuracy: 0.9935\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1156 - accuracy: 0.9736 - val_loss: 0.0380 - val_accuracy: 0.9873\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0354 - accuracy: 0.9897 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0224 - accuracy: 0.9918 - val_loss: 0.0219 - val_accuracy: 0.9927\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0218 - val_accuracy: 0.9927\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.0217 - val_accuracy: 0.9927\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0177 - val_accuracy: 0.9935\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0187 - val_accuracy: 0.9937\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0180 - val_accuracy: 0.9946\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0177 - val_accuracy: 0.9940\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0166 - val_accuracy: 0.9944\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0192 - val_accuracy: 0.9946\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0200 - val_accuracy: 0.9946\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0217 - val_accuracy: 0.9952\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0215 - val_accuracy: 0.9950\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0205 - val_accuracy: 0.9948\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0218 - val_accuracy: 0.9948\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0221 - val_accuracy: 0.9948\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0220 - val_accuracy: 0.9948\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0223 - val_accuracy: 0.9944\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0226 - val_accuracy: 0.9950\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0226 - val_accuracy: 0.9950\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0227 - val_accuracy: 0.9950\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0230 - val_accuracy: 0.9950\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0231 - val_accuracy: 0.9950\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0232 - val_accuracy: 0.9948\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0235 - val_accuracy: 0.9952\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0240 - val_accuracy: 0.9942\n",
      "250/250 [==============================] - 2s 4ms/step - loss: 0.0392 - accuracy: 0.9926\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_108 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_108 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 13)                1976      \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,052\n",
      "Trainable params: 2,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 4s 17ms/step - loss: 0.6984 - accuracy: 0.5058 - val_loss: 0.6969 - val_accuracy: 0.4983\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6939 - accuracy: 0.5119 - val_loss: 0.6952 - val_accuracy: 0.5042\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6924 - accuracy: 0.5197 - val_loss: 0.6944 - val_accuracy: 0.5071\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6911 - accuracy: 0.5264 - val_loss: 0.6931 - val_accuracy: 0.5177\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6831 - accuracy: 0.5654 - val_loss: 0.6696 - val_accuracy: 0.6127\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5734 - accuracy: 0.7428 - val_loss: 0.4806 - val_accuracy: 0.8250\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4626 - accuracy: 0.8260 - val_loss: 0.4381 - val_accuracy: 0.8419\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4065 - accuracy: 0.8496 - val_loss: 0.3581 - val_accuracy: 0.8796\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3375 - accuracy: 0.8913 - val_loss: 0.3772 - val_accuracy: 0.8642\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3438 - accuracy: 0.8793 - val_loss: 0.3203 - val_accuracy: 0.8925\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3390 - accuracy: 0.8815 - val_loss: 0.4404 - val_accuracy: 0.8254\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2789 - accuracy: 0.9103 - val_loss: 0.2352 - val_accuracy: 0.9331\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2420 - accuracy: 0.9247 - val_loss: 0.2348 - val_accuracy: 0.9267\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2769 - accuracy: 0.9096 - val_loss: 0.2746 - val_accuracy: 0.9073\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2222 - accuracy: 0.9333 - val_loss: 0.1883 - val_accuracy: 0.9463\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1967 - accuracy: 0.9417 - val_loss: 0.1749 - val_accuracy: 0.9490\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2048 - accuracy: 0.9367 - val_loss: 0.1970 - val_accuracy: 0.9377\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1938 - accuracy: 0.9406 - val_loss: 0.1969 - val_accuracy: 0.9385\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2525 - accuracy: 0.9136 - val_loss: 0.2267 - val_accuracy: 0.9237\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1672 - accuracy: 0.9497 - val_loss: 0.1718 - val_accuracy: 0.9477\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1513 - accuracy: 0.9546 - val_loss: 0.1681 - val_accuracy: 0.9477\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1656 - accuracy: 0.9504 - val_loss: 0.1621 - val_accuracy: 0.9500\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1719 - accuracy: 0.9454 - val_loss: 0.1471 - val_accuracy: 0.9581\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1577 - accuracy: 0.9514 - val_loss: 0.1458 - val_accuracy: 0.9569\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2221 - accuracy: 0.9264 - val_loss: 0.1730 - val_accuracy: 0.9431\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1479 - accuracy: 0.9531 - val_loss: 0.1751 - val_accuracy: 0.9465\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1277 - accuracy: 0.9628 - val_loss: 0.1285 - val_accuracy: 0.9623\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1323 - accuracy: 0.9610 - val_loss: 0.1386 - val_accuracy: 0.9590\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1176 - accuracy: 0.9658 - val_loss: 0.1144 - val_accuracy: 0.9638\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1027 - accuracy: 0.9710 - val_loss: 0.1687 - val_accuracy: 0.9500\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1447 - accuracy: 0.9576 - val_loss: 0.1693 - val_accuracy: 0.9500\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1765 - accuracy: 0.9425 - val_loss: 0.1287 - val_accuracy: 0.9615\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1059 - accuracy: 0.9711 - val_loss: 0.1378 - val_accuracy: 0.9585\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1017 - accuracy: 0.9692 - val_loss: 0.1107 - val_accuracy: 0.9667\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1057 - accuracy: 0.9688 - val_loss: 0.1193 - val_accuracy: 0.9656\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1168 - accuracy: 0.9607 - val_loss: 0.1295 - val_accuracy: 0.9606\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1393 - accuracy: 0.9575 - val_loss: 0.1072 - val_accuracy: 0.9685\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1129 - accuracy: 0.9649 - val_loss: 0.1205 - val_accuracy: 0.9654\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0808 - accuracy: 0.9760 - val_loss: 0.0906 - val_accuracy: 0.9725\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1143 - accuracy: 0.9640 - val_loss: 0.0966 - val_accuracy: 0.9721\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1266 - accuracy: 0.9621 - val_loss: 0.1032 - val_accuracy: 0.9706\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0764 - accuracy: 0.9793 - val_loss: 0.0877 - val_accuracy: 0.9721\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0747 - accuracy: 0.9786 - val_loss: 0.0894 - val_accuracy: 0.9740\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0762 - accuracy: 0.9776 - val_loss: 0.0942 - val_accuracy: 0.9635\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0703 - accuracy: 0.9797 - val_loss: 0.0887 - val_accuracy: 0.9725\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2155 - accuracy: 0.9342 - val_loss: 0.1865 - val_accuracy: 0.9356\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1184 - accuracy: 0.9601 - val_loss: 0.0944 - val_accuracy: 0.9690\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0760 - accuracy: 0.9772 - val_loss: 0.0860 - val_accuracy: 0.9725\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0853 - accuracy: 0.9753 - val_loss: 0.1112 - val_accuracy: 0.9571\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0674 - accuracy: 0.9810 - val_loss: 0.2181 - val_accuracy: 0.9431\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0764 - accuracy: 0.9793 - val_loss: 0.0717 - val_accuracy: 0.9806\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0558 - accuracy: 0.9836 - val_loss: 0.0762 - val_accuracy: 0.9744\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0719 - val_accuracy: 0.9794\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0739 - accuracy: 0.9803 - val_loss: 0.0788 - val_accuracy: 0.9735\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0748 - accuracy: 0.9782 - val_loss: 0.0708 - val_accuracy: 0.9787\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0507 - accuracy: 0.9861 - val_loss: 0.0713 - val_accuracy: 0.9783\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0590 - accuracy: 0.9833 - val_loss: 0.0775 - val_accuracy: 0.9787\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1029 - accuracy: 0.9665 - val_loss: 0.0982 - val_accuracy: 0.9625\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0549 - accuracy: 0.9835 - val_loss: 0.0768 - val_accuracy: 0.9790\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0490 - accuracy: 0.9858 - val_loss: 0.0745 - val_accuracy: 0.9785\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0438 - accuracy: 0.9872 - val_loss: 0.0757 - val_accuracy: 0.9794\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0667 - accuracy: 0.9810 - val_loss: 0.0863 - val_accuracy: 0.9679\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0529 - accuracy: 0.9846 - val_loss: 0.0848 - val_accuracy: 0.9675\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0875 - accuracy: 0.9747 - val_loss: 0.1083 - val_accuracy: 0.9598\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0579 - accuracy: 0.9831 - val_loss: 0.1002 - val_accuracy: 0.9717\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0944 - accuracy: 0.9707 - val_loss: 0.0738 - val_accuracy: 0.9748\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0579 - accuracy: 0.9839 - val_loss: 0.0696 - val_accuracy: 0.9815\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0492 - accuracy: 0.9869 - val_loss: 0.0780 - val_accuracy: 0.9790\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0492 - accuracy: 0.9862 - val_loss: 0.0771 - val_accuracy: 0.9715\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0439 - accuracy: 0.9883 - val_loss: 0.0674 - val_accuracy: 0.9777\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0654 - accuracy: 0.9811 - val_loss: 0.0777 - val_accuracy: 0.9787\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0373 - accuracy: 0.9911 - val_loss: 0.0662 - val_accuracy: 0.9829\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0378 - accuracy: 0.9897 - val_loss: 0.0691 - val_accuracy: 0.9817\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1314 - accuracy: 0.9638 - val_loss: 0.1342 - val_accuracy: 0.9594\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0713 - accuracy: 0.9781 - val_loss: 0.0696 - val_accuracy: 0.9775\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.0660 - val_accuracy: 0.9781\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0450 - accuracy: 0.9882 - val_loss: 0.0825 - val_accuracy: 0.9785\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 0.0716 - val_accuracy: 0.9754\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0483 - accuracy: 0.9861 - val_loss: 0.0755 - val_accuracy: 0.9746\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0326 - accuracy: 0.9915 - val_loss: 0.0670 - val_accuracy: 0.9831\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0423 - accuracy: 0.9871 - val_loss: 0.0776 - val_accuracy: 0.9804\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0507 - accuracy: 0.9864 - val_loss: 0.0660 - val_accuracy: 0.9817\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0503 - accuracy: 0.9849 - val_loss: 0.1670 - val_accuracy: 0.9315\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0563 - accuracy: 0.9815 - val_loss: 0.0639 - val_accuracy: 0.9817\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0303 - accuracy: 0.9924 - val_loss: 0.0975 - val_accuracy: 0.9619\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0496 - accuracy: 0.9836 - val_loss: 0.0762 - val_accuracy: 0.9777\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0430 - accuracy: 0.9878 - val_loss: 0.0583 - val_accuracy: 0.9812\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0495 - accuracy: 0.9867 - val_loss: 0.0804 - val_accuracy: 0.9781\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0299 - accuracy: 0.9924 - val_loss: 0.0648 - val_accuracy: 0.9825\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0302 - accuracy: 0.9914 - val_loss: 0.0555 - val_accuracy: 0.9848\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 0.0512 - val_accuracy: 0.9852\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0391 - accuracy: 0.9892 - val_loss: 0.2007 - val_accuracy: 0.9285\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0416 - accuracy: 0.9871 - val_loss: 0.0637 - val_accuracy: 0.9771\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0271 - accuracy: 0.9926 - val_loss: 0.0760 - val_accuracy: 0.9819\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.0499 - val_accuracy: 0.9848\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0580 - accuracy: 0.9832 - val_loss: 0.0938 - val_accuracy: 0.9748\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0638 - accuracy: 0.9794 - val_loss: 0.0654 - val_accuracy: 0.9819\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.0550 - val_accuracy: 0.9837\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.0596 - val_accuracy: 0.9796\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.0658 - val_accuracy: 0.9844\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0511 - val_accuracy: 0.9854\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0177 - accuracy: 0.9964 - val_loss: 0.0585 - val_accuracy: 0.9862\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.9968 - val_loss: 0.0499 - val_accuracy: 0.9844\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0191 - accuracy: 0.9960 - val_loss: 0.0622 - val_accuracy: 0.9844\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0283 - accuracy: 0.9931 - val_loss: 0.0514 - val_accuracy: 0.9842\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0611 - val_accuracy: 0.9854\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0499 - val_accuracy: 0.9854\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.0523 - val_accuracy: 0.9862\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0467 - val_accuracy: 0.9871\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0474 - val_accuracy: 0.9869\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0821 - accuracy: 0.9817 - val_loss: 0.1049 - val_accuracy: 0.9750\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0466 - accuracy: 0.9869 - val_loss: 0.0746 - val_accuracy: 0.9769\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.0549 - val_accuracy: 0.9860\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0516 - val_accuracy: 0.9852\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.0448 - val_accuracy: 0.9871\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0626 - val_accuracy: 0.9812\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0421 - accuracy: 0.9894 - val_loss: 0.0487 - val_accuracy: 0.9846\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 0.0452 - val_accuracy: 0.9877\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0461 - val_accuracy: 0.9881\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0445 - val_accuracy: 0.9883\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.0465 - val_accuracy: 0.9833\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.0423 - val_accuracy: 0.9873\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0465 - accuracy: 0.9864 - val_loss: 0.0566 - val_accuracy: 0.9817\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0272 - accuracy: 0.9929 - val_loss: 0.0464 - val_accuracy: 0.9867\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0553 - val_accuracy: 0.9871\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0394 - val_accuracy: 0.9894\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0383 - val_accuracy: 0.9881\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0604 - val_accuracy: 0.9865\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.0350 - val_accuracy: 0.9885\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.0348 - val_accuracy: 0.9885\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.0810 - val_accuracy: 0.9821\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0259 - accuracy: 0.9940 - val_loss: 0.0840 - val_accuracy: 0.9821\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0129 - accuracy: 0.9975 - val_loss: 0.0385 - val_accuracy: 0.9881\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0890 - val_accuracy: 0.9815\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0333 - accuracy: 0.9911 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0383 - val_accuracy: 0.9883\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0618 - val_accuracy: 0.9796\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0518 - val_accuracy: 0.9865\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0441 - val_accuracy: 0.9879\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0289 - val_accuracy: 0.9917\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0362 - val_accuracy: 0.9906\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0372 - val_accuracy: 0.9908\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0635 - accuracy: 0.9878 - val_loss: 0.4605 - val_accuracy: 0.9152\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0747 - accuracy: 0.9790 - val_loss: 0.0618 - val_accuracy: 0.9819\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0167 - accuracy: 0.9960 - val_loss: 0.0469 - val_accuracy: 0.9871\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0417 - val_accuracy: 0.9894\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.0415 - val_accuracy: 0.9896\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0393 - val_accuracy: 0.9887\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.0379 - val_accuracy: 0.9887\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0397 - val_accuracy: 0.9904\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0388 - val_accuracy: 0.9906\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0378 - val_accuracy: 0.9908\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.0371 - val_accuracy: 0.9906\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0390 - val_accuracy: 0.9915\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0425 - val_accuracy: 0.9906\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0401 - val_accuracy: 0.9915\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0406 - val_accuracy: 0.9917\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0413 - val_accuracy: 0.9912\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0416 - val_accuracy: 0.9912\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0414 - val_accuracy: 0.9915\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0416 - val_accuracy: 0.9912\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0411 - val_accuracy: 0.9912\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0434 - val_accuracy: 0.9912\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0421 - val_accuracy: 0.9910\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0440 - val_accuracy: 0.9912\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0441 - val_accuracy: 0.9906\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0448 - val_accuracy: 0.9908\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0446 - val_accuracy: 0.9908\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0450 - val_accuracy: 0.9910\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0450 - val_accuracy: 0.9910\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0462 - val_accuracy: 0.9904\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0459 - val_accuracy: 0.9906\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0471 - val_accuracy: 0.9904\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0483 - val_accuracy: 0.9902\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0483 - val_accuracy: 0.9904\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0496 - val_accuracy: 0.9902\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0482 - val_accuracy: 0.9904\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0495 - val_accuracy: 0.9904\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0482 - val_accuracy: 0.9906\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0506 - val_accuracy: 0.9902\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0511 - val_accuracy: 0.9904\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0564 - val_accuracy: 0.9894\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0552 - val_accuracy: 0.9900\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0558 - val_accuracy: 0.9898\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0645 - val_accuracy: 0.9896\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.2038 - val_accuracy: 0.9723\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.9765 - accuracy: 0.8618 - val_loss: 0.2006 - val_accuracy: 0.9552\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1560 - accuracy: 0.9622 - val_loss: 0.1379 - val_accuracy: 0.9646\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1004 - accuracy: 0.9729 - val_loss: 0.1067 - val_accuracy: 0.9719\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0766 - accuracy: 0.9783 - val_loss: 0.0884 - val_accuracy: 0.9758\n",
      "250/250 [==============================] - 2s 4ms/step - loss: 0.0351 - accuracy: 0.9911\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_109 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_109 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 13)                1976      \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,052\n",
      "Trainable params: 2,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 16ms/step - loss: 0.6953 - accuracy: 0.5024 - val_loss: 0.6933 - val_accuracy: 0.5117\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6927 - accuracy: 0.5167 - val_loss: 0.6919 - val_accuracy: 0.5221\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6768 - accuracy: 0.5861 - val_loss: 0.6437 - val_accuracy: 0.6606\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5765 - accuracy: 0.7389 - val_loss: 0.5282 - val_accuracy: 0.7681\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4662 - accuracy: 0.8142 - val_loss: 0.4057 - val_accuracy: 0.8525\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3788 - accuracy: 0.8611 - val_loss: 0.3757 - val_accuracy: 0.8615\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3347 - accuracy: 0.8817 - val_loss: 0.3299 - val_accuracy: 0.8731\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2950 - accuracy: 0.8936 - val_loss: 0.3065 - val_accuracy: 0.8900\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2787 - accuracy: 0.8989 - val_loss: 0.5144 - val_accuracy: 0.7917\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2643 - accuracy: 0.9026 - val_loss: 0.2762 - val_accuracy: 0.9010\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2254 - accuracy: 0.9228 - val_loss: 0.3392 - val_accuracy: 0.8754\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2242 - accuracy: 0.9229 - val_loss: 0.2071 - val_accuracy: 0.9306\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2113 - accuracy: 0.9282 - val_loss: 0.2020 - val_accuracy: 0.9321\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1901 - accuracy: 0.9357 - val_loss: 0.1949 - val_accuracy: 0.9260\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1730 - accuracy: 0.9426 - val_loss: 0.1804 - val_accuracy: 0.9390\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1691 - accuracy: 0.9450 - val_loss: 0.1592 - val_accuracy: 0.9490\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1439 - accuracy: 0.9542 - val_loss: 0.2462 - val_accuracy: 0.9194\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1703 - accuracy: 0.9447 - val_loss: 0.1422 - val_accuracy: 0.9552\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1439 - accuracy: 0.9551 - val_loss: 0.1417 - val_accuracy: 0.9525\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1302 - accuracy: 0.9582 - val_loss: 0.1328 - val_accuracy: 0.9565\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1296 - accuracy: 0.9610 - val_loss: 0.1610 - val_accuracy: 0.9427\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1779 - accuracy: 0.9417 - val_loss: 0.1354 - val_accuracy: 0.9571\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1273 - accuracy: 0.9625 - val_loss: 0.1163 - val_accuracy: 0.9648\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1126 - accuracy: 0.9663 - val_loss: 0.1068 - val_accuracy: 0.9679\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1484 - accuracy: 0.9517 - val_loss: 0.1260 - val_accuracy: 0.9575\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1008 - accuracy: 0.9715 - val_loss: 0.1090 - val_accuracy: 0.9654\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0951 - accuracy: 0.9728 - val_loss: 0.1638 - val_accuracy: 0.9419\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1294 - accuracy: 0.9604 - val_loss: 0.1308 - val_accuracy: 0.9590\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0798 - accuracy: 0.9783 - val_loss: 0.1010 - val_accuracy: 0.9706\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0861 - accuracy: 0.9749 - val_loss: 0.0840 - val_accuracy: 0.9756\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9711 - val_loss: 0.0909 - val_accuracy: 0.9706\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0755 - accuracy: 0.9790 - val_loss: 0.0771 - val_accuracy: 0.9779\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0748 - accuracy: 0.9786 - val_loss: 0.0883 - val_accuracy: 0.9706\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0758 - accuracy: 0.9782 - val_loss: 0.0892 - val_accuracy: 0.9744\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0784 - accuracy: 0.9774 - val_loss: 0.0718 - val_accuracy: 0.9792\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0597 - accuracy: 0.9831 - val_loss: 0.0617 - val_accuracy: 0.9804\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0539 - accuracy: 0.9862 - val_loss: 0.0839 - val_accuracy: 0.9700\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0737 - accuracy: 0.9790 - val_loss: 0.0821 - val_accuracy: 0.9760\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0565 - accuracy: 0.9836 - val_loss: 0.0686 - val_accuracy: 0.9790\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0641 - accuracy: 0.9808 - val_loss: 0.0514 - val_accuracy: 0.9842\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0465 - accuracy: 0.9879 - val_loss: 0.0549 - val_accuracy: 0.9831\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0743 - accuracy: 0.9787 - val_loss: 0.0799 - val_accuracy: 0.9752\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0510 - accuracy: 0.9851 - val_loss: 0.0512 - val_accuracy: 0.9840\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0601 - accuracy: 0.9836 - val_loss: 0.0571 - val_accuracy: 0.9833\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0488 - accuracy: 0.9860 - val_loss: 0.0460 - val_accuracy: 0.9871\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0579 - accuracy: 0.9826 - val_loss: 0.0616 - val_accuracy: 0.9806\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0362 - accuracy: 0.9901 - val_loss: 0.0420 - val_accuracy: 0.9881\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0376 - accuracy: 0.9906 - val_loss: 0.0749 - val_accuracy: 0.9754\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0429 - accuracy: 0.9878 - val_loss: 0.0446 - val_accuracy: 0.9865\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.0380 - val_accuracy: 0.9892\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0792 - accuracy: 0.9785 - val_loss: 0.0599 - val_accuracy: 0.9835\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 0.0915 - val_accuracy: 0.9685\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0524 - accuracy: 0.9853 - val_loss: 0.0672 - val_accuracy: 0.9769\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 0.0443 - val_accuracy: 0.9873\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0569 - accuracy: 0.9840 - val_loss: 0.0673 - val_accuracy: 0.9748\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0369 - accuracy: 0.9903 - val_loss: 0.0392 - val_accuracy: 0.9867\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0284 - accuracy: 0.9925 - val_loss: 0.0959 - val_accuracy: 0.9742\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 0.0430 - val_accuracy: 0.9877\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0780 - accuracy: 0.9794 - val_loss: 0.0608 - val_accuracy: 0.9823\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 0.0416 - val_accuracy: 0.9875\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0427 - val_accuracy: 0.9879\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.0338 - val_accuracy: 0.9898\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.0283 - val_accuracy: 0.9917\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.0360 - val_accuracy: 0.9887\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0221 - accuracy: 0.9946 - val_loss: 0.0433 - val_accuracy: 0.9885\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0282 - accuracy: 0.9926 - val_loss: 0.0729 - val_accuracy: 0.9821\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.0378 - val_accuracy: 0.9885\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 0.0350 - val_accuracy: 0.9902\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0344 - val_accuracy: 0.9890\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0391 - val_accuracy: 0.9885\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.0281 - val_accuracy: 0.9929\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.0322 - val_accuracy: 0.9910\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0636 - val_accuracy: 0.9852\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0227 - accuracy: 0.9937 - val_loss: 0.0360 - val_accuracy: 0.9890\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0323 - val_accuracy: 0.9894\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0312 - val_accuracy: 0.9927\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0519 - accuracy: 0.9867 - val_loss: 0.0553 - val_accuracy: 0.9869\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 0.0329 - val_accuracy: 0.9910\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.0305 - val_accuracy: 0.9917\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0257 - val_accuracy: 0.9929\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0248 - val_accuracy: 0.9940\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.0259 - val_accuracy: 0.9935\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0271 - val_accuracy: 0.9942\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0265 - accuracy: 0.9929 - val_loss: 0.0442 - val_accuracy: 0.9858\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0360 - val_accuracy: 0.9906\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0292 - val_accuracy: 0.9927\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0277 - val_accuracy: 0.9927\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0309 - val_accuracy: 0.9921\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0311 - val_accuracy: 0.9919\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0312 - val_accuracy: 0.9931\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0264 - accuracy: 0.9937 - val_loss: 0.0652 - val_accuracy: 0.9804\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 0.0739 - val_accuracy: 0.9812\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.0303 - val_accuracy: 0.9910\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0278 - accuracy: 0.9911 - val_loss: 0.0243 - val_accuracy: 0.9915\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0205 - val_accuracy: 0.9935\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0096 - accuracy: 0.9961 - val_loss: 0.0249 - val_accuracy: 0.9935\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0261 - val_accuracy: 0.9937\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9931\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0365 - val_accuracy: 0.9927\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0377 - val_accuracy: 0.9921\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0680 - val_accuracy: 0.9850\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0567 - accuracy: 0.9857 - val_loss: 0.0292 - val_accuracy: 0.9908\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0216 - val_accuracy: 0.9944\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0325 - val_accuracy: 0.9902\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0204 - val_accuracy: 0.9944\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0240 - val_accuracy: 0.9940\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0224 - val_accuracy: 0.9942\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0226 - val_accuracy: 0.9940\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9944\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9944\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 8.4255e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9948\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 7.3268e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9946\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 6.4279e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9940\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 6.0095e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9946\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 5.3684e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9944\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 5.0399e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9946\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 4.5974e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9944\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 4.2060e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9948\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 4.0032e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9946\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 3.7075e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9946\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 3.4588e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9946\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 3.2529e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9946\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 3.0490e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9944\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 2.8597e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9946\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 2.6994e-04 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9948\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 2.5374e-04 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9952\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 2.3940e-04 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9944\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 2.2656e-04 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9950\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 2.1369e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9950\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 2.0143e-04 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9946\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.9116e-04 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9950\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.8063e-04 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9950\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.6997e-04 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9940\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.6095e-04 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9950\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.5251e-04 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9948\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.4462e-04 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9948\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3664e-04 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9950\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2923e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9950\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2236e-04 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9946\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.1592e-04 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9942\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.1008e-04 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9948\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.0372e-04 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9944\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 9.8343e-05 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9948\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 9.3480e-05 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9944\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 8.8507e-05 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9948\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 8.3563e-05 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9948\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 7.9313e-05 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9944\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 7.4682e-05 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9944\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 7.0636e-05 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9948\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 6.7090e-05 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9944\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 6.3732e-05 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9942\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 5.9961e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9942\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 5.6689e-05 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9946\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 5.3890e-05 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9944\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 5.0864e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9946\n",
      "250/250 [==============================] - 2s 4ms/step - loss: 0.0248 - accuracy: 0.9926\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_110 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_110 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 13)                1976      \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,052\n",
      "Trainable params: 2,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 16ms/step - loss: 0.6972 - accuracy: 0.4928 - val_loss: 0.6951 - val_accuracy: 0.5031\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6934 - accuracy: 0.5106 - val_loss: 0.6935 - val_accuracy: 0.5152\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6892 - accuracy: 0.5322 - val_loss: 0.6748 - val_accuracy: 0.6037\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5747 - accuracy: 0.7528 - val_loss: 0.4780 - val_accuracy: 0.8204\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4320 - accuracy: 0.8442 - val_loss: 0.3797 - val_accuracy: 0.8727\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3611 - accuracy: 0.8733 - val_loss: 0.3197 - val_accuracy: 0.8946\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2937 - accuracy: 0.9025 - val_loss: 0.3545 - val_accuracy: 0.8735\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2901 - accuracy: 0.8999 - val_loss: 0.2496 - val_accuracy: 0.9202\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2628 - accuracy: 0.9129 - val_loss: 0.2320 - val_accuracy: 0.9279\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2422 - accuracy: 0.9211 - val_loss: 0.2461 - val_accuracy: 0.9190\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2388 - accuracy: 0.9226 - val_loss: 0.1924 - val_accuracy: 0.9448\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2037 - accuracy: 0.9362 - val_loss: 0.1876 - val_accuracy: 0.9452\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2086 - accuracy: 0.9331 - val_loss: 0.2214 - val_accuracy: 0.9256\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2548 - accuracy: 0.9142 - val_loss: 0.2711 - val_accuracy: 0.9017\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1924 - accuracy: 0.9388 - val_loss: 0.1724 - val_accuracy: 0.9488\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1741 - accuracy: 0.9472 - val_loss: 0.2151 - val_accuracy: 0.9304\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1754 - accuracy: 0.9447 - val_loss: 0.1882 - val_accuracy: 0.9419\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1887 - accuracy: 0.9397 - val_loss: 0.1934 - val_accuracy: 0.9390\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1585 - accuracy: 0.9525 - val_loss: 0.1651 - val_accuracy: 0.9498\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1442 - accuracy: 0.9561 - val_loss: 0.1786 - val_accuracy: 0.9431\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1758 - accuracy: 0.9436 - val_loss: 0.2246 - val_accuracy: 0.9262\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1439 - accuracy: 0.9576 - val_loss: 0.1357 - val_accuracy: 0.9613\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1476 - accuracy: 0.9546 - val_loss: 0.1345 - val_accuracy: 0.9646\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1531 - accuracy: 0.9547 - val_loss: 0.1700 - val_accuracy: 0.9475\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1779 - accuracy: 0.9439 - val_loss: 0.1673 - val_accuracy: 0.9479\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1343 - accuracy: 0.9596 - val_loss: 0.1947 - val_accuracy: 0.9394\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1277 - accuracy: 0.9614 - val_loss: 0.1136 - val_accuracy: 0.9685\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1524 - accuracy: 0.9529 - val_loss: 0.1235 - val_accuracy: 0.9652\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1040 - accuracy: 0.9697 - val_loss: 0.1010 - val_accuracy: 0.9727\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1022 - accuracy: 0.9708 - val_loss: 0.0989 - val_accuracy: 0.9731\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1489 - accuracy: 0.9546 - val_loss: 0.1744 - val_accuracy: 0.9471\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1640 - accuracy: 0.9478 - val_loss: 0.1760 - val_accuracy: 0.9438\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0984 - accuracy: 0.9725 - val_loss: 0.0904 - val_accuracy: 0.9754\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0987 - accuracy: 0.9726 - val_loss: 0.0914 - val_accuracy: 0.9746\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0903 - accuracy: 0.9744 - val_loss: 0.1134 - val_accuracy: 0.9663\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1250 - accuracy: 0.9644 - val_loss: 0.1680 - val_accuracy: 0.9488\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9721 - val_loss: 0.0782 - val_accuracy: 0.9812\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1084 - accuracy: 0.9682 - val_loss: 0.1186 - val_accuracy: 0.9652\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1316 - accuracy: 0.9608 - val_loss: 0.1327 - val_accuracy: 0.9608\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0942 - accuracy: 0.9739 - val_loss: 0.0876 - val_accuracy: 0.9765\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0757 - accuracy: 0.9790 - val_loss: 0.0840 - val_accuracy: 0.9792\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1924 - accuracy: 0.9431 - val_loss: 0.1115 - val_accuracy: 0.9698\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0780 - accuracy: 0.9806 - val_loss: 0.0720 - val_accuracy: 0.9823\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0973 - accuracy: 0.9724 - val_loss: 0.1140 - val_accuracy: 0.9690\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1050 - accuracy: 0.9694 - val_loss: 0.0761 - val_accuracy: 0.9798\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0699 - accuracy: 0.9812 - val_loss: 0.0847 - val_accuracy: 0.9775\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0901 - accuracy: 0.9754 - val_loss: 0.0710 - val_accuracy: 0.9819\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0560 - accuracy: 0.9861 - val_loss: 0.0609 - val_accuracy: 0.9842\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0566 - accuracy: 0.9854 - val_loss: 0.0751 - val_accuracy: 0.9808\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0693 - accuracy: 0.9815 - val_loss: 0.0898 - val_accuracy: 0.9754\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0884 - accuracy: 0.9767 - val_loss: 0.0935 - val_accuracy: 0.9746\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0715 - accuracy: 0.9783 - val_loss: 0.0660 - val_accuracy: 0.9825\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0814 - accuracy: 0.9774 - val_loss: 0.1070 - val_accuracy: 0.9717\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1250 - accuracy: 0.9615 - val_loss: 0.0665 - val_accuracy: 0.9833\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0522 - accuracy: 0.9864 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0616 - accuracy: 0.9817 - val_loss: 0.0504 - val_accuracy: 0.9875\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0531 - accuracy: 0.9857 - val_loss: 0.0510 - val_accuracy: 0.9860\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0807 - accuracy: 0.9756 - val_loss: 0.0575 - val_accuracy: 0.9860\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0426 - accuracy: 0.9890 - val_loss: 0.0542 - val_accuracy: 0.9856\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0583 - accuracy: 0.9837 - val_loss: 0.0553 - val_accuracy: 0.9848\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0735 - accuracy: 0.9811 - val_loss: 0.0682 - val_accuracy: 0.9827\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0487 - accuracy: 0.9868 - val_loss: 0.0514 - val_accuracy: 0.9875\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0674 - accuracy: 0.9819 - val_loss: 0.0587 - val_accuracy: 0.9842\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0661 - accuracy: 0.9815 - val_loss: 0.0690 - val_accuracy: 0.9812\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0667 - accuracy: 0.9810 - val_loss: 0.0518 - val_accuracy: 0.9881\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0441 - accuracy: 0.9869 - val_loss: 0.0464 - val_accuracy: 0.9877\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0404 - accuracy: 0.9893 - val_loss: 0.0486 - val_accuracy: 0.9867\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0894 - accuracy: 0.9756 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0426 - accuracy: 0.9885 - val_loss: 0.0454 - val_accuracy: 0.9885\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0392 - accuracy: 0.9896 - val_loss: 0.0450 - val_accuracy: 0.9879\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0426 - accuracy: 0.9885 - val_loss: 0.0470 - val_accuracy: 0.9865\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0343 - accuracy: 0.9906 - val_loss: 0.1132 - val_accuracy: 0.9619\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0533 - accuracy: 0.9856 - val_loss: 0.0463 - val_accuracy: 0.9873\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0317 - accuracy: 0.9918 - val_loss: 0.0447 - val_accuracy: 0.9890\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0358 - accuracy: 0.9894 - val_loss: 0.0756 - val_accuracy: 0.9808\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.0482 - val_accuracy: 0.9844\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 0.0879 - val_accuracy: 0.9712\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0591 - accuracy: 0.9829 - val_loss: 0.0517 - val_accuracy: 0.9846\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0318 - accuracy: 0.9906 - val_loss: 0.0430 - val_accuracy: 0.9869\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.0409 - val_accuracy: 0.9879\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.1332 - val_accuracy: 0.9523\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0789 - accuracy: 0.9783 - val_loss: 0.1069 - val_accuracy: 0.9733\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0311 - accuracy: 0.9926 - val_loss: 0.0349 - val_accuracy: 0.9902\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0373 - accuracy: 0.9889 - val_loss: 0.0402 - val_accuracy: 0.9885\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0208 - accuracy: 0.9953 - val_loss: 0.0375 - val_accuracy: 0.9890\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.0363 - val_accuracy: 0.9900\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.0583 - val_accuracy: 0.9860\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1066 - accuracy: 0.9776 - val_loss: 0.3482 - val_accuracy: 0.9171\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2160 - accuracy: 0.9401 - val_loss: 0.1443 - val_accuracy: 0.9577\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1160 - accuracy: 0.9650 - val_loss: 0.0828 - val_accuracy: 0.9765\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1084 - accuracy: 0.9679 - val_loss: 0.0672 - val_accuracy: 0.9831\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0576 - accuracy: 0.9846 - val_loss: 0.0969 - val_accuracy: 0.9692\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0477 - accuracy: 0.9865 - val_loss: 0.0716 - val_accuracy: 0.9800\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0315 - accuracy: 0.9919 - val_loss: 0.0549 - val_accuracy: 0.9848\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.0333 - val_accuracy: 0.9906\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.9967 - val_loss: 0.0314 - val_accuracy: 0.9902\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.0374 - val_accuracy: 0.9902\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0289 - val_accuracy: 0.9923\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0121 - accuracy: 0.9975 - val_loss: 0.0307 - val_accuracy: 0.9902\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.0396 - val_accuracy: 0.9867\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.0948 - val_accuracy: 0.9690\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0493 - accuracy: 0.9858 - val_loss: 0.0285 - val_accuracy: 0.9915\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.0269 - val_accuracy: 0.9925\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0268 - val_accuracy: 0.9919\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0305 - val_accuracy: 0.9923\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0336 - val_accuracy: 0.9917\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.0252 - val_accuracy: 0.9927\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0238 - val_accuracy: 0.9937\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0359 - val_accuracy: 0.9898\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.0289 - val_accuracy: 0.9912\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.0323 - val_accuracy: 0.9898\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.0251 - val_accuracy: 0.9925\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0460 - val_accuracy: 0.9887\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0346 - val_accuracy: 0.9912\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0517 - val_accuracy: 0.9875\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0282 - val_accuracy: 0.9923\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.0432 - val_accuracy: 0.9900\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0214 - val_accuracy: 0.9944\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.0404 - val_accuracy: 0.9912\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0315 - val_accuracy: 0.9921\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0327 - val_accuracy: 0.9929\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0335 - val_accuracy: 0.9925\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0269 - val_accuracy: 0.9925\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0246 - val_accuracy: 0.9942\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0205 - val_accuracy: 0.9942\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0237 - val_accuracy: 0.9937\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0254 - val_accuracy: 0.9942\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0214 - val_accuracy: 0.9940\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0215 - val_accuracy: 0.9940\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0256 - val_accuracy: 0.9940\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0238 - val_accuracy: 0.9937\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0219 - val_accuracy: 0.9948\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0218 - val_accuracy: 0.9946\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0227 - val_accuracy: 0.9946\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0231 - val_accuracy: 0.9948\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0237 - val_accuracy: 0.9944\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0237 - val_accuracy: 0.9948\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0232 - val_accuracy: 0.9948\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0237 - val_accuracy: 0.9948\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0243 - val_accuracy: 0.9948\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0243 - val_accuracy: 0.9948\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0261 - val_accuracy: 0.9946\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0253 - val_accuracy: 0.9946\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0249 - val_accuracy: 0.9948\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0255 - val_accuracy: 0.9948\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0255 - val_accuracy: 0.9950\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0274 - val_accuracy: 0.9948\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0268 - val_accuracy: 0.9948\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0264 - val_accuracy: 0.9952\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0273 - val_accuracy: 0.9948\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0270 - val_accuracy: 0.9952\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0278 - val_accuracy: 0.9948\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0279 - val_accuracy: 0.9952\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0285 - val_accuracy: 0.9948\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0288 - val_accuracy: 0.9950\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0292 - val_accuracy: 0.9948\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2903 - accuracy: 0.9569 - val_loss: 0.3505 - val_accuracy: 0.9242\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2265 - accuracy: 0.9325 - val_loss: 0.1024 - val_accuracy: 0.9721\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 0.0452 - val_accuracy: 0.9873\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0286 - accuracy: 0.9919 - val_loss: 0.0438 - val_accuracy: 0.9885\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 0.0335 - val_accuracy: 0.9906\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0413 - accuracy: 0.9903 - val_loss: 0.0511 - val_accuracy: 0.9858\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.0347 - val_accuracy: 0.9900\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.0907 - val_accuracy: 0.9794\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0341 - val_accuracy: 0.9912\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.0583 - val_accuracy: 0.9846\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.0472 - val_accuracy: 0.9873\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.0275 - val_accuracy: 0.9933\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0280 - val_accuracy: 0.9931\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.0290 - val_accuracy: 0.9927\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0272 - val_accuracy: 0.9942\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.0358 - val_accuracy: 0.9910\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.0279 - val_accuracy: 0.9931\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.0278 - val_accuracy: 0.9935\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.0277 - val_accuracy: 0.9937\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9941\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_111 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_111 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 13)                1976      \n",
      "                                                                 \n",
      " dense_400 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,052\n",
      "Trainable params: 2,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 16ms/step - loss: 0.6977 - accuracy: 0.5069 - val_loss: 0.6953 - val_accuracy: 0.5075\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6933 - accuracy: 0.5172 - val_loss: 0.6944 - val_accuracy: 0.5067\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6918 - accuracy: 0.5265 - val_loss: 0.6942 - val_accuracy: 0.5052\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6905 - accuracy: 0.5358 - val_loss: 0.6941 - val_accuracy: 0.5115\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6888 - accuracy: 0.5403 - val_loss: 0.6931 - val_accuracy: 0.5181\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6746 - accuracy: 0.5863 - val_loss: 0.6381 - val_accuracy: 0.6635\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5468 - accuracy: 0.7574 - val_loss: 0.4731 - val_accuracy: 0.8192\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4172 - accuracy: 0.8414 - val_loss: 0.4015 - val_accuracy: 0.8492\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3660 - accuracy: 0.8633 - val_loss: 0.3289 - val_accuracy: 0.8894\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3235 - accuracy: 0.8811 - val_loss: 0.3317 - val_accuracy: 0.8779\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3253 - accuracy: 0.8781 - val_loss: 0.2858 - val_accuracy: 0.9006\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3322 - accuracy: 0.8774 - val_loss: 0.5764 - val_accuracy: 0.7379\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3400 - accuracy: 0.8703 - val_loss: 0.2788 - val_accuracy: 0.9044\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2681 - accuracy: 0.9074 - val_loss: 0.2612 - val_accuracy: 0.9077\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2598 - accuracy: 0.9086 - val_loss: 0.3082 - val_accuracy: 0.8873\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2514 - accuracy: 0.9126 - val_loss: 0.2250 - val_accuracy: 0.9260\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2186 - accuracy: 0.9276 - val_loss: 0.2212 - val_accuracy: 0.9273\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2155 - accuracy: 0.9301 - val_loss: 0.2122 - val_accuracy: 0.9308\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2309 - accuracy: 0.9194 - val_loss: 0.2080 - val_accuracy: 0.9308\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2085 - accuracy: 0.9307 - val_loss: 0.2025 - val_accuracy: 0.9312\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2194 - accuracy: 0.9258 - val_loss: 0.1933 - val_accuracy: 0.9373\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1891 - accuracy: 0.9401 - val_loss: 0.1862 - val_accuracy: 0.9402\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1778 - accuracy: 0.9443 - val_loss: 0.3426 - val_accuracy: 0.8800\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1902 - accuracy: 0.9413 - val_loss: 0.1655 - val_accuracy: 0.9494\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1640 - accuracy: 0.9501 - val_loss: 0.1643 - val_accuracy: 0.9490\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1721 - accuracy: 0.9468 - val_loss: 0.1814 - val_accuracy: 0.9421\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1873 - accuracy: 0.9388 - val_loss: 0.1572 - val_accuracy: 0.9531\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1737 - accuracy: 0.9436 - val_loss: 0.3790 - val_accuracy: 0.8665\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1784 - accuracy: 0.9435 - val_loss: 0.1661 - val_accuracy: 0.9473\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1717 - accuracy: 0.9463 - val_loss: 0.1493 - val_accuracy: 0.9577\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1777 - accuracy: 0.9418 - val_loss: 0.1800 - val_accuracy: 0.9406\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1559 - accuracy: 0.9507 - val_loss: 0.1472 - val_accuracy: 0.9567\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1560 - accuracy: 0.9496 - val_loss: 0.1575 - val_accuracy: 0.9519\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1810 - accuracy: 0.9431 - val_loss: 0.1613 - val_accuracy: 0.9508\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1641 - accuracy: 0.9485 - val_loss: 0.1520 - val_accuracy: 0.9525\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1594 - accuracy: 0.9513 - val_loss: 0.2245 - val_accuracy: 0.9237\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1351 - accuracy: 0.9590 - val_loss: 0.1903 - val_accuracy: 0.9406\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1197 - accuracy: 0.9664 - val_loss: 0.1230 - val_accuracy: 0.9646\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1507 - accuracy: 0.9542 - val_loss: 0.1282 - val_accuracy: 0.9623\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1475 - accuracy: 0.9557 - val_loss: 0.2091 - val_accuracy: 0.9312\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1634 - accuracy: 0.9472 - val_loss: 0.1522 - val_accuracy: 0.9540\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1210 - accuracy: 0.9653 - val_loss: 0.1171 - val_accuracy: 0.9663\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1089 - accuracy: 0.9694 - val_loss: 0.1150 - val_accuracy: 0.9690\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1046 - accuracy: 0.9701 - val_loss: 0.1102 - val_accuracy: 0.9685\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1364 - accuracy: 0.9593 - val_loss: 0.1206 - val_accuracy: 0.9642\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1149 - accuracy: 0.9667 - val_loss: 0.1297 - val_accuracy: 0.9608\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1139 - accuracy: 0.9654 - val_loss: 0.1130 - val_accuracy: 0.9675\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1052 - accuracy: 0.9683 - val_loss: 0.1036 - val_accuracy: 0.9706\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1029 - accuracy: 0.9699 - val_loss: 0.1601 - val_accuracy: 0.9544\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1350 - accuracy: 0.9593 - val_loss: 0.1219 - val_accuracy: 0.9640\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1020 - accuracy: 0.9706 - val_loss: 0.0988 - val_accuracy: 0.9708\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0821 - accuracy: 0.9778 - val_loss: 0.0916 - val_accuracy: 0.9733\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0874 - accuracy: 0.9756 - val_loss: 0.1843 - val_accuracy: 0.9481\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1150 - accuracy: 0.9667 - val_loss: 0.2201 - val_accuracy: 0.9356\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1144 - accuracy: 0.9644 - val_loss: 0.1320 - val_accuracy: 0.9602\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0824 - accuracy: 0.9756 - val_loss: 0.0967 - val_accuracy: 0.9715\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0681 - accuracy: 0.9822 - val_loss: 0.0803 - val_accuracy: 0.9762\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0766 - accuracy: 0.9779 - val_loss: 0.1052 - val_accuracy: 0.9677\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0835 - accuracy: 0.9751 - val_loss: 0.0834 - val_accuracy: 0.9760\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0609 - accuracy: 0.9837 - val_loss: 0.0863 - val_accuracy: 0.9752\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0605 - accuracy: 0.9836 - val_loss: 0.1357 - val_accuracy: 0.9627\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0948 - accuracy: 0.9728 - val_loss: 0.0869 - val_accuracy: 0.9754\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0662 - accuracy: 0.9831 - val_loss: 0.0918 - val_accuracy: 0.9742\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0859 - accuracy: 0.9754 - val_loss: 0.0806 - val_accuracy: 0.9765\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0766 - accuracy: 0.9782 - val_loss: 0.0826 - val_accuracy: 0.9767\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0543 - accuracy: 0.9862 - val_loss: 0.0689 - val_accuracy: 0.9810\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0525 - accuracy: 0.9864 - val_loss: 0.0949 - val_accuracy: 0.9733\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0838 - accuracy: 0.9767 - val_loss: 0.0702 - val_accuracy: 0.9802\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0587 - accuracy: 0.9832 - val_loss: 0.0714 - val_accuracy: 0.9804\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0451 - accuracy: 0.9882 - val_loss: 0.0801 - val_accuracy: 0.9781\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1426 - accuracy: 0.9581 - val_loss: 0.0979 - val_accuracy: 0.9715\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0770 - accuracy: 0.9785 - val_loss: 0.2117 - val_accuracy: 0.9435\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0654 - accuracy: 0.9821 - val_loss: 0.0719 - val_accuracy: 0.9804\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0468 - accuracy: 0.9878 - val_loss: 0.0641 - val_accuracy: 0.9833\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0481 - accuracy: 0.9872 - val_loss: 0.0734 - val_accuracy: 0.9796\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0651 - accuracy: 0.9822 - val_loss: 0.1331 - val_accuracy: 0.9635\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0519 - accuracy: 0.9858 - val_loss: 0.0669 - val_accuracy: 0.9817\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0510 - accuracy: 0.9858 - val_loss: 0.0682 - val_accuracy: 0.9806\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0438 - accuracy: 0.9878 - val_loss: 0.0600 - val_accuracy: 0.9829\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0343 - accuracy: 0.9914 - val_loss: 0.0641 - val_accuracy: 0.9829\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 0.1847 - val_accuracy: 0.9558\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0545 - accuracy: 0.9853 - val_loss: 0.0638 - val_accuracy: 0.9812\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0429 - accuracy: 0.9874 - val_loss: 0.0886 - val_accuracy: 0.9771\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0493 - accuracy: 0.9868 - val_loss: 0.0665 - val_accuracy: 0.9812\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0519 - accuracy: 0.9878 - val_loss: 0.2962 - val_accuracy: 0.9331\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 0.0557 - val_accuracy: 0.9846\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0796 - accuracy: 0.9776 - val_loss: 0.0814 - val_accuracy: 0.9777\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0551 - accuracy: 0.9837 - val_loss: 0.0586 - val_accuracy: 0.9842\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 0.0550 - val_accuracy: 0.9852\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0250 - accuracy: 0.9939 - val_loss: 0.0541 - val_accuracy: 0.9842\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.0480 - val_accuracy: 0.9854\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0309 - accuracy: 0.9918 - val_loss: 0.0498 - val_accuracy: 0.9850\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0328 - accuracy: 0.9901 - val_loss: 0.0566 - val_accuracy: 0.9837\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0409 - accuracy: 0.9876 - val_loss: 0.0491 - val_accuracy: 0.9860\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0260 - accuracy: 0.9932 - val_loss: 0.0473 - val_accuracy: 0.9867\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.0455 - val_accuracy: 0.9869\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0304 - accuracy: 0.9922 - val_loss: 0.0482 - val_accuracy: 0.9867\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0274 - accuracy: 0.9919 - val_loss: 0.1014 - val_accuracy: 0.9758\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0446 - accuracy: 0.9879 - val_loss: 0.0471 - val_accuracy: 0.9865\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.0432 - val_accuracy: 0.9881\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.0616 - val_accuracy: 0.9842\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0429 - accuracy: 0.9876 - val_loss: 0.0513 - val_accuracy: 0.9856\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0482 - val_accuracy: 0.9869\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.0449 - val_accuracy: 0.9887\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.0496 - val_accuracy: 0.9867\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.0444 - val_accuracy: 0.9875\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.0457 - val_accuracy: 0.9879\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0409 - val_accuracy: 0.9894\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0444 - val_accuracy: 0.9881\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0396 - val_accuracy: 0.9906\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.0441 - val_accuracy: 0.9902\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0725 - accuracy: 0.9836 - val_loss: 0.0958 - val_accuracy: 0.9783\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0380 - accuracy: 0.9894 - val_loss: 0.0834 - val_accuracy: 0.9796\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 0.0490 - val_accuracy: 0.9862\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0428 - val_accuracy: 0.9881\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0431 - val_accuracy: 0.9885\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.0472 - val_accuracy: 0.9873\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.0608 - val_accuracy: 0.9854\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0621 - val_accuracy: 0.9848\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0426 - val_accuracy: 0.9885\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.0427 - val_accuracy: 0.9894\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0571 - val_accuracy: 0.9850\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.0513 - val_accuracy: 0.9883\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0406 - val_accuracy: 0.9898\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0382 - val_accuracy: 0.9896\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0370 - val_accuracy: 0.9900\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.0369 - val_accuracy: 0.9904\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0365 - val_accuracy: 0.9912\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0351 - val_accuracy: 0.9915\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0340 - val_accuracy: 0.9910\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.2094 - val_accuracy: 0.9454\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0537 - accuracy: 0.9861 - val_loss: 0.0373 - val_accuracy: 0.9887\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0726 - val_accuracy: 0.9860\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0927 - accuracy: 0.9774 - val_loss: 0.0728 - val_accuracy: 0.9775\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.0387 - val_accuracy: 0.9887\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.0354 - val_accuracy: 0.9892\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0398 - val_accuracy: 0.9900\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.0304 - val_accuracy: 0.9910\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0294 - val_accuracy: 0.9906\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0276 - val_accuracy: 0.9919\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.0261 - val_accuracy: 0.9923\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0570 - val_accuracy: 0.9890\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.0426 - val_accuracy: 0.9915\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0381 - val_accuracy: 0.9919\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.0442 - val_accuracy: 0.9908\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0308 - val_accuracy: 0.9921\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0319 - val_accuracy: 0.9923\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0307 - val_accuracy: 0.9923\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0298 - val_accuracy: 0.9923\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0313 - val_accuracy: 0.9925\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0271 - val_accuracy: 0.9933\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0278 - val_accuracy: 0.9933\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0269 - val_accuracy: 0.9935\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0247 - val_accuracy: 0.9931\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0274 - val_accuracy: 0.9933\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0262 - val_accuracy: 0.9937\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0255 - val_accuracy: 0.9937\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0287 - val_accuracy: 0.9931\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0281 - val_accuracy: 0.9933\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0276 - val_accuracy: 0.9933\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0300 - val_accuracy: 0.9925\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0263 - val_accuracy: 0.9931\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.0444 - val_accuracy: 0.9898\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1100 - accuracy: 0.9776 - val_loss: 0.1957 - val_accuracy: 0.9513\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0662 - accuracy: 0.9829 - val_loss: 0.0393 - val_accuracy: 0.9896\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.0364 - val_accuracy: 0.9904\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0303 - val_accuracy: 0.9917\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0627 - val_accuracy: 0.9867\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.0621 - val_accuracy: 0.9869\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0347 - accuracy: 0.9910 - val_loss: 0.0699 - val_accuracy: 0.9812\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.0307 - val_accuracy: 0.9912\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0365 - val_accuracy: 0.9908\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0314 - val_accuracy: 0.9915\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0318 - val_accuracy: 0.9917\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0320 - val_accuracy: 0.9921\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0296 - val_accuracy: 0.9923\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0342 - val_accuracy: 0.9917\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0308 - val_accuracy: 0.9925\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0336 - val_accuracy: 0.9915\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0310 - val_accuracy: 0.9925\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0316 - val_accuracy: 0.9925\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0322 - val_accuracy: 0.9925\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0343 - val_accuracy: 0.9925\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0296 - val_accuracy: 0.9929\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0300 - val_accuracy: 0.9929\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0362 - val_accuracy: 0.9927\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0321 - val_accuracy: 0.9931\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0303 - val_accuracy: 0.9931\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0316 - val_accuracy: 0.9929\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0298 - val_accuracy: 0.9933\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0330 - val_accuracy: 0.9933\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0325 - val_accuracy: 0.9929\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0351 - val_accuracy: 0.9927\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0336 - val_accuracy: 0.9929\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0317 - val_accuracy: 0.9935\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0313 - val_accuracy: 0.9935\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1391 - accuracy: 0.9789 - val_loss: 0.6150 - val_accuracy: 0.8994\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2162 - accuracy: 0.9543 - val_loss: 0.1044 - val_accuracy: 0.9775\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0434 - accuracy: 0.9892 - val_loss: 0.0500 - val_accuracy: 0.9892\n",
      "250/250 [==============================] - 2s 4ms/step - loss: 0.0511 - accuracy: 0.9881\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......masking\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-27 10:15:25        52976\n",
      "config.json                                    2023-03-27 10:15:25         2362\n",
      "metadata.json                                  2023-03-27 10:15:25           64\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_112 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_112 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " encode_positions_27 (Encode  (None, 95, 24)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_27 (Tra  (None, 95, 24)           2864      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_27 (Gl  (None, 24)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,962\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 13ms/step - loss: 0.9917 - accuracy: 0.5051 - val_loss: 0.7256 - val_accuracy: 0.5167\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.7004 - accuracy: 0.5506 - val_loss: 0.6900 - val_accuracy: 0.5498\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6675 - accuracy: 0.6012 - val_loss: 0.6450 - val_accuracy: 0.6390\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5814 - accuracy: 0.7128 - val_loss: 0.5501 - val_accuracy: 0.7262\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4724 - accuracy: 0.7899 - val_loss: 0.4333 - val_accuracy: 0.8202\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4233 - accuracy: 0.8153 - val_loss: 0.3977 - val_accuracy: 0.8331\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4084 - accuracy: 0.8194 - val_loss: 0.3803 - val_accuracy: 0.8425\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3852 - accuracy: 0.8328 - val_loss: 0.3913 - val_accuracy: 0.8308\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3700 - accuracy: 0.8401 - val_loss: 0.3424 - val_accuracy: 0.8590\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3358 - accuracy: 0.8576 - val_loss: 0.3351 - val_accuracy: 0.8598\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3396 - accuracy: 0.8582 - val_loss: 0.3405 - val_accuracy: 0.8523\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3299 - accuracy: 0.8604 - val_loss: 0.3827 - val_accuracy: 0.8425\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3116 - accuracy: 0.8701 - val_loss: 0.3195 - val_accuracy: 0.8696\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3135 - accuracy: 0.8712 - val_loss: 0.3198 - val_accuracy: 0.8627\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2909 - accuracy: 0.8806 - val_loss: 0.2772 - val_accuracy: 0.8898\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2786 - accuracy: 0.8869 - val_loss: 0.2827 - val_accuracy: 0.8881\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2659 - accuracy: 0.8946 - val_loss: 0.2777 - val_accuracy: 0.8917\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2511 - accuracy: 0.9021 - val_loss: 0.2678 - val_accuracy: 0.8929\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2449 - accuracy: 0.9053 - val_loss: 0.2456 - val_accuracy: 0.9040\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2466 - accuracy: 0.9031 - val_loss: 0.2429 - val_accuracy: 0.9058\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2348 - accuracy: 0.9101 - val_loss: 0.2531 - val_accuracy: 0.9071\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2299 - accuracy: 0.9107 - val_loss: 0.2326 - val_accuracy: 0.9142\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2208 - accuracy: 0.9165 - val_loss: 0.2268 - val_accuracy: 0.9156\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2124 - accuracy: 0.9196 - val_loss: 0.2258 - val_accuracy: 0.9142\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2165 - accuracy: 0.9142 - val_loss: 0.2234 - val_accuracy: 0.9142\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2061 - accuracy: 0.9194 - val_loss: 0.2270 - val_accuracy: 0.9123\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2055 - accuracy: 0.9224 - val_loss: 0.2313 - val_accuracy: 0.9104\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2059 - accuracy: 0.9206 - val_loss: 0.2143 - val_accuracy: 0.9204\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2043 - accuracy: 0.9229 - val_loss: 0.2065 - val_accuracy: 0.9221\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1970 - accuracy: 0.9232 - val_loss: 0.2192 - val_accuracy: 0.9133\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1896 - accuracy: 0.9287 - val_loss: 0.1976 - val_accuracy: 0.9246\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1863 - accuracy: 0.9282 - val_loss: 0.1963 - val_accuracy: 0.9287\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1800 - accuracy: 0.9336 - val_loss: 0.1913 - val_accuracy: 0.9315\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1831 - accuracy: 0.9315 - val_loss: 0.2009 - val_accuracy: 0.9233\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1806 - accuracy: 0.9328 - val_loss: 0.2436 - val_accuracy: 0.9098\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1788 - accuracy: 0.9328 - val_loss: 0.1832 - val_accuracy: 0.9317\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1755 - accuracy: 0.9353 - val_loss: 0.2174 - val_accuracy: 0.9212\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1686 - accuracy: 0.9381 - val_loss: 0.1987 - val_accuracy: 0.9321\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1679 - accuracy: 0.9389 - val_loss: 0.2024 - val_accuracy: 0.9233\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1690 - accuracy: 0.9379 - val_loss: 0.1951 - val_accuracy: 0.9267\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1627 - accuracy: 0.9413 - val_loss: 0.1901 - val_accuracy: 0.9331\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1616 - accuracy: 0.9408 - val_loss: 0.2043 - val_accuracy: 0.9185\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1714 - accuracy: 0.9349 - val_loss: 0.1815 - val_accuracy: 0.9360\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1614 - accuracy: 0.9415 - val_loss: 0.1806 - val_accuracy: 0.9344\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1551 - accuracy: 0.9453 - val_loss: 0.1701 - val_accuracy: 0.9375\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1649 - accuracy: 0.9371 - val_loss: 0.1916 - val_accuracy: 0.9335\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1562 - accuracy: 0.9421 - val_loss: 0.2328 - val_accuracy: 0.9162\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1527 - accuracy: 0.9460 - val_loss: 0.1712 - val_accuracy: 0.9383\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1483 - accuracy: 0.9458 - val_loss: 0.1711 - val_accuracy: 0.9369\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1508 - accuracy: 0.9436 - val_loss: 0.1700 - val_accuracy: 0.9354\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1503 - accuracy: 0.9457 - val_loss: 0.1979 - val_accuracy: 0.9246\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1506 - accuracy: 0.9450 - val_loss: 0.1680 - val_accuracy: 0.9394\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1458 - accuracy: 0.9472 - val_loss: 0.1743 - val_accuracy: 0.9335\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1545 - accuracy: 0.9447 - val_loss: 0.1685 - val_accuracy: 0.9371\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1464 - accuracy: 0.9457 - val_loss: 0.1731 - val_accuracy: 0.9348\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1434 - accuracy: 0.9485 - val_loss: 0.1625 - val_accuracy: 0.9410\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1407 - accuracy: 0.9488 - val_loss: 0.1612 - val_accuracy: 0.9419\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1414 - accuracy: 0.9496 - val_loss: 0.1589 - val_accuracy: 0.9448\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1368 - accuracy: 0.9511 - val_loss: 0.1625 - val_accuracy: 0.9406\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1403 - accuracy: 0.9507 - val_loss: 0.1739 - val_accuracy: 0.9375\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1391 - accuracy: 0.9517 - val_loss: 0.1653 - val_accuracy: 0.9415\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1446 - accuracy: 0.9468 - val_loss: 0.1659 - val_accuracy: 0.9383\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1367 - accuracy: 0.9508 - val_loss: 0.1595 - val_accuracy: 0.9421\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1355 - accuracy: 0.9525 - val_loss: 0.1685 - val_accuracy: 0.9350\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1374 - accuracy: 0.9500 - val_loss: 0.1632 - val_accuracy: 0.9392\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1282 - accuracy: 0.9544 - val_loss: 0.1596 - val_accuracy: 0.9444\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1312 - accuracy: 0.9539 - val_loss: 0.1603 - val_accuracy: 0.9448\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1267 - accuracy: 0.9554 - val_loss: 0.1520 - val_accuracy: 0.9448\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1370 - accuracy: 0.9540 - val_loss: 0.1648 - val_accuracy: 0.9419\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1305 - accuracy: 0.9518 - val_loss: 0.1621 - val_accuracy: 0.9415\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1288 - accuracy: 0.9522 - val_loss: 0.1511 - val_accuracy: 0.9442\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1205 - accuracy: 0.9557 - val_loss: 0.1486 - val_accuracy: 0.9475\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1295 - accuracy: 0.9532 - val_loss: 0.1553 - val_accuracy: 0.9431\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1257 - accuracy: 0.9553 - val_loss: 0.1495 - val_accuracy: 0.9475\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1241 - accuracy: 0.9568 - val_loss: 0.1622 - val_accuracy: 0.9400\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1234 - accuracy: 0.9551 - val_loss: 0.1661 - val_accuracy: 0.9408\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1210 - accuracy: 0.9557 - val_loss: 0.1477 - val_accuracy: 0.9490\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1239 - accuracy: 0.9551 - val_loss: 0.1469 - val_accuracy: 0.9467\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1186 - accuracy: 0.9582 - val_loss: 0.1581 - val_accuracy: 0.9448\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1159 - accuracy: 0.9583 - val_loss: 0.1522 - val_accuracy: 0.9494\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1195 - accuracy: 0.9586 - val_loss: 0.1495 - val_accuracy: 0.9454\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1214 - accuracy: 0.9594 - val_loss: 0.1434 - val_accuracy: 0.9475\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1195 - accuracy: 0.9581 - val_loss: 0.1656 - val_accuracy: 0.9377\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1206 - accuracy: 0.9582 - val_loss: 0.1745 - val_accuracy: 0.9402\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1180 - accuracy: 0.9581 - val_loss: 0.1413 - val_accuracy: 0.9490\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1120 - accuracy: 0.9603 - val_loss: 0.1415 - val_accuracy: 0.9479\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1119 - accuracy: 0.9608 - val_loss: 0.1554 - val_accuracy: 0.9496\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1116 - accuracy: 0.9624 - val_loss: 0.1461 - val_accuracy: 0.9483\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1127 - accuracy: 0.9594 - val_loss: 0.1460 - val_accuracy: 0.9460\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1094 - accuracy: 0.9618 - val_loss: 0.2088 - val_accuracy: 0.9221\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1183 - accuracy: 0.9604 - val_loss: 0.1600 - val_accuracy: 0.9442\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1137 - accuracy: 0.9600 - val_loss: 0.1501 - val_accuracy: 0.9471\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1101 - accuracy: 0.9606 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1101 - accuracy: 0.9628 - val_loss: 0.1438 - val_accuracy: 0.9500\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1088 - accuracy: 0.9631 - val_loss: 0.1485 - val_accuracy: 0.9481\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1164 - accuracy: 0.9592 - val_loss: 0.1392 - val_accuracy: 0.9510\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1083 - accuracy: 0.9628 - val_loss: 0.1422 - val_accuracy: 0.9506\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1068 - accuracy: 0.9618 - val_loss: 0.1363 - val_accuracy: 0.9500\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1075 - accuracy: 0.9629 - val_loss: 0.1435 - val_accuracy: 0.9506\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1042 - accuracy: 0.9639 - val_loss: 0.1394 - val_accuracy: 0.9510\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1073 - accuracy: 0.9643 - val_loss: 0.1355 - val_accuracy: 0.9540\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1048 - accuracy: 0.9628 - val_loss: 0.1357 - val_accuracy: 0.9500\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1093 - accuracy: 0.9640 - val_loss: 0.1463 - val_accuracy: 0.9475\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9621 - val_loss: 0.1433 - val_accuracy: 0.9504\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1050 - accuracy: 0.9642 - val_loss: 0.1358 - val_accuracy: 0.9527\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1057 - accuracy: 0.9621 - val_loss: 0.1537 - val_accuracy: 0.9452\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1073 - accuracy: 0.9624 - val_loss: 0.1504 - val_accuracy: 0.9463\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1057 - accuracy: 0.9643 - val_loss: 0.1377 - val_accuracy: 0.9529\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9660 - val_loss: 0.1380 - val_accuracy: 0.9494\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1022 - accuracy: 0.9639 - val_loss: 0.1394 - val_accuracy: 0.9488\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1033 - accuracy: 0.9639 - val_loss: 0.1378 - val_accuracy: 0.9513\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1040 - accuracy: 0.9640 - val_loss: 0.1375 - val_accuracy: 0.9492\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1014 - accuracy: 0.9624 - val_loss: 0.1442 - val_accuracy: 0.9485\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0988 - accuracy: 0.9649 - val_loss: 0.1370 - val_accuracy: 0.9500\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0978 - accuracy: 0.9665 - val_loss: 0.1330 - val_accuracy: 0.9560\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0988 - accuracy: 0.9650 - val_loss: 0.1331 - val_accuracy: 0.9538\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1011 - accuracy: 0.9656 - val_loss: 0.1407 - val_accuracy: 0.9492\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1059 - accuracy: 0.9636 - val_loss: 0.1334 - val_accuracy: 0.9529\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1008 - accuracy: 0.9657 - val_loss: 0.1328 - val_accuracy: 0.9542\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0980 - accuracy: 0.9657 - val_loss: 0.1321 - val_accuracy: 0.9529\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0998 - accuracy: 0.9654 - val_loss: 0.1308 - val_accuracy: 0.9529\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1010 - accuracy: 0.9653 - val_loss: 0.1417 - val_accuracy: 0.9513\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0934 - accuracy: 0.9681 - val_loss: 0.1365 - val_accuracy: 0.9508\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0975 - accuracy: 0.9658 - val_loss: 0.1388 - val_accuracy: 0.9525\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0903 - accuracy: 0.9704 - val_loss: 0.1433 - val_accuracy: 0.9490\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0925 - accuracy: 0.9676 - val_loss: 0.1285 - val_accuracy: 0.9542\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1063 - accuracy: 0.9618 - val_loss: 0.1335 - val_accuracy: 0.9506\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0957 - accuracy: 0.9661 - val_loss: 0.1400 - val_accuracy: 0.9508\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0910 - accuracy: 0.9682 - val_loss: 0.1353 - val_accuracy: 0.9531\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0925 - accuracy: 0.9690 - val_loss: 0.1287 - val_accuracy: 0.9533\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0939 - accuracy: 0.9644 - val_loss: 0.1362 - val_accuracy: 0.9540\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0918 - accuracy: 0.9674 - val_loss: 0.1393 - val_accuracy: 0.9540\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0972 - accuracy: 0.9656 - val_loss: 0.1288 - val_accuracy: 0.9552\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0917 - accuracy: 0.9683 - val_loss: 0.1300 - val_accuracy: 0.9546\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0892 - accuracy: 0.9678 - val_loss: 0.1329 - val_accuracy: 0.9535\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0899 - accuracy: 0.9674 - val_loss: 0.1329 - val_accuracy: 0.9552\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0900 - accuracy: 0.9692 - val_loss: 0.1332 - val_accuracy: 0.9540\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0884 - accuracy: 0.9699 - val_loss: 0.1327 - val_accuracy: 0.9544\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0924 - accuracy: 0.9681 - val_loss: 0.1534 - val_accuracy: 0.9479\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0933 - accuracy: 0.9686 - val_loss: 0.1318 - val_accuracy: 0.9554\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0891 - accuracy: 0.9692 - val_loss: 0.1311 - val_accuracy: 0.9579\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0869 - accuracy: 0.9690 - val_loss: 0.1532 - val_accuracy: 0.9490\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0915 - accuracy: 0.9674 - val_loss: 0.1412 - val_accuracy: 0.9533\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0884 - accuracy: 0.9694 - val_loss: 0.1304 - val_accuracy: 0.9569\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0860 - accuracy: 0.9719 - val_loss: 0.1297 - val_accuracy: 0.9558\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0892 - accuracy: 0.9681 - val_loss: 0.1275 - val_accuracy: 0.9567\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0818 - accuracy: 0.9717 - val_loss: 0.1262 - val_accuracy: 0.9581\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0850 - accuracy: 0.9710 - val_loss: 0.1309 - val_accuracy: 0.9535\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0864 - accuracy: 0.9694 - val_loss: 0.1295 - val_accuracy: 0.9569\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0894 - accuracy: 0.9676 - val_loss: 0.1313 - val_accuracy: 0.9558\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0834 - accuracy: 0.9706 - val_loss: 0.1276 - val_accuracy: 0.9569\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0821 - accuracy: 0.9704 - val_loss: 0.1294 - val_accuracy: 0.9552\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0856 - accuracy: 0.9699 - val_loss: 0.1381 - val_accuracy: 0.9560\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0848 - accuracy: 0.9686 - val_loss: 0.1248 - val_accuracy: 0.9563\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0875 - accuracy: 0.9706 - val_loss: 0.1240 - val_accuracy: 0.9571\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0791 - accuracy: 0.9735 - val_loss: 0.1279 - val_accuracy: 0.9592\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0805 - accuracy: 0.9756 - val_loss: 0.1326 - val_accuracy: 0.9556\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0824 - accuracy: 0.9721 - val_loss: 0.1228 - val_accuracy: 0.9567\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0825 - accuracy: 0.9711 - val_loss: 0.1275 - val_accuracy: 0.9575\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0818 - accuracy: 0.9731 - val_loss: 0.1304 - val_accuracy: 0.9550\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0773 - accuracy: 0.9740 - val_loss: 0.1517 - val_accuracy: 0.9500\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0882 - accuracy: 0.9696 - val_loss: 0.1456 - val_accuracy: 0.9502\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0769 - accuracy: 0.9740 - val_loss: 0.1230 - val_accuracy: 0.9592\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0802 - accuracy: 0.9722 - val_loss: 0.1243 - val_accuracy: 0.9588\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0772 - accuracy: 0.9733 - val_loss: 0.1313 - val_accuracy: 0.9563\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0747 - accuracy: 0.9744 - val_loss: 0.1227 - val_accuracy: 0.9573\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0761 - accuracy: 0.9771 - val_loss: 0.1265 - val_accuracy: 0.9567\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0794 - accuracy: 0.9725 - val_loss: 0.1258 - val_accuracy: 0.9573\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0794 - accuracy: 0.9736 - val_loss: 0.1472 - val_accuracy: 0.9521\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0766 - accuracy: 0.9749 - val_loss: 0.1481 - val_accuracy: 0.9533\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0726 - accuracy: 0.9750 - val_loss: 0.1218 - val_accuracy: 0.9610\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0694 - accuracy: 0.9774 - val_loss: 0.1193 - val_accuracy: 0.9610\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0751 - accuracy: 0.9736 - val_loss: 0.1309 - val_accuracy: 0.9563\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0789 - accuracy: 0.9724 - val_loss: 0.1289 - val_accuracy: 0.9552\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0789 - accuracy: 0.9731 - val_loss: 0.1378 - val_accuracy: 0.9550\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0710 - accuracy: 0.9761 - val_loss: 0.1277 - val_accuracy: 0.9610\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0707 - accuracy: 0.9764 - val_loss: 0.1259 - val_accuracy: 0.9615\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 0.1257 - val_accuracy: 0.9575\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0726 - accuracy: 0.9767 - val_loss: 0.1329 - val_accuracy: 0.9579\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0680 - accuracy: 0.9787 - val_loss: 0.1248 - val_accuracy: 0.9596\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0681 - accuracy: 0.9778 - val_loss: 0.1233 - val_accuracy: 0.9600\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0718 - accuracy: 0.9771 - val_loss: 0.1326 - val_accuracy: 0.9550\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0681 - accuracy: 0.9772 - val_loss: 0.1230 - val_accuracy: 0.9606\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0685 - accuracy: 0.9775 - val_loss: 0.1217 - val_accuracy: 0.9623\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0650 - accuracy: 0.9792 - val_loss: 0.1229 - val_accuracy: 0.9604\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0663 - accuracy: 0.9785 - val_loss: 0.1192 - val_accuracy: 0.9617\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0639 - accuracy: 0.9807 - val_loss: 0.1293 - val_accuracy: 0.9583\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0692 - accuracy: 0.9758 - val_loss: 0.1225 - val_accuracy: 0.9596\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 0.1224 - val_accuracy: 0.9588\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0656 - accuracy: 0.9792 - val_loss: 0.1246 - val_accuracy: 0.9596\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0626 - accuracy: 0.9812 - val_loss: 0.1385 - val_accuracy: 0.9556\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0649 - accuracy: 0.9799 - val_loss: 0.1239 - val_accuracy: 0.9602\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0661 - accuracy: 0.9781 - val_loss: 0.1234 - val_accuracy: 0.9615\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0649 - accuracy: 0.9783 - val_loss: 0.1175 - val_accuracy: 0.9629\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0626 - accuracy: 0.9794 - val_loss: 0.1232 - val_accuracy: 0.9617\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0643 - accuracy: 0.9786 - val_loss: 0.1247 - val_accuracy: 0.9575\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0692 - accuracy: 0.9767 - val_loss: 0.1220 - val_accuracy: 0.9615\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0622 - accuracy: 0.9794 - val_loss: 0.1326 - val_accuracy: 0.9556\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0634 - accuracy: 0.9792 - val_loss: 0.1259 - val_accuracy: 0.9588\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0598 - accuracy: 0.9814 - val_loss: 0.1168 - val_accuracy: 0.9627\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9624\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_113 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_113 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " encode_positions_28 (Encode  (None, 95, 24)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_28 (Tra  (None, 95, 24)           2864      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_28 (Gl  (None, 24)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,962\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 13ms/step - loss: 0.8030 - accuracy: 0.5011 - val_loss: 0.7153 - val_accuracy: 0.5213\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6938 - accuracy: 0.5668 - val_loss: 0.6818 - val_accuracy: 0.5863\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6691 - accuracy: 0.6083 - val_loss: 0.6539 - val_accuracy: 0.6352\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6243 - accuracy: 0.6635 - val_loss: 0.5860 - val_accuracy: 0.7094\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5505 - accuracy: 0.7394 - val_loss: 0.4958 - val_accuracy: 0.7802\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4933 - accuracy: 0.7767 - val_loss: 0.4670 - val_accuracy: 0.7950\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4598 - accuracy: 0.7946 - val_loss: 0.4441 - val_accuracy: 0.8062\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4345 - accuracy: 0.8118 - val_loss: 0.4768 - val_accuracy: 0.7800\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4244 - accuracy: 0.8164 - val_loss: 0.4118 - val_accuracy: 0.8229\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4033 - accuracy: 0.8278 - val_loss: 0.4452 - val_accuracy: 0.7983\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3957 - accuracy: 0.8292 - val_loss: 0.3966 - val_accuracy: 0.8283\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3845 - accuracy: 0.8365 - val_loss: 0.3893 - val_accuracy: 0.8331\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3746 - accuracy: 0.8426 - val_loss: 0.3762 - val_accuracy: 0.8413\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3614 - accuracy: 0.8489 - val_loss: 0.3615 - val_accuracy: 0.8496\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3584 - accuracy: 0.8511 - val_loss: 0.3738 - val_accuracy: 0.8429\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3466 - accuracy: 0.8582 - val_loss: 0.3836 - val_accuracy: 0.8385\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3566 - accuracy: 0.8528 - val_loss: 0.3881 - val_accuracy: 0.8383\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3435 - accuracy: 0.8614 - val_loss: 0.3688 - val_accuracy: 0.8475\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3380 - accuracy: 0.8633 - val_loss: 0.3206 - val_accuracy: 0.8710\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3167 - accuracy: 0.8711 - val_loss: 0.3263 - val_accuracy: 0.8681\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3152 - accuracy: 0.8739 - val_loss: 0.3350 - val_accuracy: 0.8679\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3132 - accuracy: 0.8749 - val_loss: 0.3220 - val_accuracy: 0.8679\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2958 - accuracy: 0.8824 - val_loss: 0.2969 - val_accuracy: 0.8835\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3038 - accuracy: 0.8792 - val_loss: 0.3017 - val_accuracy: 0.8806\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2954 - accuracy: 0.8831 - val_loss: 0.3159 - val_accuracy: 0.8702\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3066 - accuracy: 0.8760 - val_loss: 0.3376 - val_accuracy: 0.8573\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2952 - accuracy: 0.8825 - val_loss: 0.2857 - val_accuracy: 0.8877\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2785 - accuracy: 0.8906 - val_loss: 0.3146 - val_accuracy: 0.8754\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2798 - accuracy: 0.8919 - val_loss: 0.2812 - val_accuracy: 0.8896\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2584 - accuracy: 0.8985 - val_loss: 0.2627 - val_accuracy: 0.8979\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2696 - accuracy: 0.8956 - val_loss: 0.3154 - val_accuracy: 0.8769\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2937 - accuracy: 0.8849 - val_loss: 0.2758 - val_accuracy: 0.8933\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2695 - accuracy: 0.8971 - val_loss: 0.3637 - val_accuracy: 0.8477\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2873 - accuracy: 0.8868 - val_loss: 0.2771 - val_accuracy: 0.8921\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2542 - accuracy: 0.9015 - val_loss: 0.2521 - val_accuracy: 0.9033\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2566 - accuracy: 0.9028 - val_loss: 0.2624 - val_accuracy: 0.8979\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2534 - accuracy: 0.9028 - val_loss: 0.2567 - val_accuracy: 0.9056\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2322 - accuracy: 0.9136 - val_loss: 0.2459 - val_accuracy: 0.9104\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2272 - accuracy: 0.9143 - val_loss: 0.2518 - val_accuracy: 0.8996\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2644 - accuracy: 0.8985 - val_loss: 0.2598 - val_accuracy: 0.8958\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2542 - accuracy: 0.9043 - val_loss: 0.2333 - val_accuracy: 0.9081\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2309 - accuracy: 0.9108 - val_loss: 0.3096 - val_accuracy: 0.8712\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2566 - accuracy: 0.8994 - val_loss: 0.2477 - val_accuracy: 0.9027\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2387 - accuracy: 0.9097 - val_loss: 0.2372 - val_accuracy: 0.9119\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2202 - accuracy: 0.9175 - val_loss: 0.2235 - val_accuracy: 0.9152\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2121 - accuracy: 0.9210 - val_loss: 0.2117 - val_accuracy: 0.9177\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2512 - accuracy: 0.9043 - val_loss: 0.2694 - val_accuracy: 0.8977\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2297 - accuracy: 0.9129 - val_loss: 0.2202 - val_accuracy: 0.9187\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2229 - accuracy: 0.9179 - val_loss: 0.2199 - val_accuracy: 0.9187\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2140 - accuracy: 0.9176 - val_loss: 0.2525 - val_accuracy: 0.9035\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2269 - accuracy: 0.9164 - val_loss: 0.2165 - val_accuracy: 0.9187\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2181 - accuracy: 0.9193 - val_loss: 0.2363 - val_accuracy: 0.9112\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2022 - accuracy: 0.9272 - val_loss: 0.2143 - val_accuracy: 0.9258\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2184 - accuracy: 0.9192 - val_loss: 0.2165 - val_accuracy: 0.9221\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2188 - accuracy: 0.9187 - val_loss: 0.2233 - val_accuracy: 0.9177\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2004 - accuracy: 0.9292 - val_loss: 0.2059 - val_accuracy: 0.9219\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1964 - accuracy: 0.9283 - val_loss: 0.1979 - val_accuracy: 0.9273\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1891 - accuracy: 0.9310 - val_loss: 0.2307 - val_accuracy: 0.9065\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1921 - accuracy: 0.9299 - val_loss: 0.1946 - val_accuracy: 0.9290\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1870 - accuracy: 0.9317 - val_loss: 0.1996 - val_accuracy: 0.9302\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1971 - accuracy: 0.9303 - val_loss: 0.2111 - val_accuracy: 0.9198\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1830 - accuracy: 0.9361 - val_loss: 0.2365 - val_accuracy: 0.9071\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1879 - accuracy: 0.9318 - val_loss: 0.1821 - val_accuracy: 0.9342\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1783 - accuracy: 0.9361 - val_loss: 0.1992 - val_accuracy: 0.9281\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1929 - accuracy: 0.9317 - val_loss: 0.2277 - val_accuracy: 0.9140\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1884 - accuracy: 0.9311 - val_loss: 0.1909 - val_accuracy: 0.9292\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1726 - accuracy: 0.9365 - val_loss: 0.1767 - val_accuracy: 0.9356\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1646 - accuracy: 0.9433 - val_loss: 0.1881 - val_accuracy: 0.9398\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1732 - accuracy: 0.9392 - val_loss: 0.1874 - val_accuracy: 0.9335\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1705 - accuracy: 0.9401 - val_loss: 0.1716 - val_accuracy: 0.9388\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1768 - accuracy: 0.9371 - val_loss: 0.1693 - val_accuracy: 0.9383\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2000 - accuracy: 0.9286 - val_loss: 0.1923 - val_accuracy: 0.9306\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1634 - accuracy: 0.9421 - val_loss: 0.1760 - val_accuracy: 0.9367\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1765 - accuracy: 0.9349 - val_loss: 0.1946 - val_accuracy: 0.9262\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1633 - accuracy: 0.9406 - val_loss: 0.1924 - val_accuracy: 0.9340\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1659 - accuracy: 0.9396 - val_loss: 0.1710 - val_accuracy: 0.9402\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1576 - accuracy: 0.9440 - val_loss: 0.1833 - val_accuracy: 0.9310\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1582 - accuracy: 0.9446 - val_loss: 0.1825 - val_accuracy: 0.9337\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1614 - accuracy: 0.9442 - val_loss: 0.1688 - val_accuracy: 0.9398\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1470 - accuracy: 0.9472 - val_loss: 0.2190 - val_accuracy: 0.9196\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1735 - accuracy: 0.9362 - val_loss: 0.2269 - val_accuracy: 0.9225\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1597 - accuracy: 0.9457 - val_loss: 0.1730 - val_accuracy: 0.9379\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1580 - accuracy: 0.9442 - val_loss: 0.1753 - val_accuracy: 0.9327\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1521 - accuracy: 0.9467 - val_loss: 0.1758 - val_accuracy: 0.9367\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1478 - accuracy: 0.9494 - val_loss: 0.1637 - val_accuracy: 0.9425\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1426 - accuracy: 0.9503 - val_loss: 0.1842 - val_accuracy: 0.9315\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1570 - accuracy: 0.9426 - val_loss: 0.1690 - val_accuracy: 0.9433\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1472 - accuracy: 0.9481 - val_loss: 0.1790 - val_accuracy: 0.9410\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1588 - accuracy: 0.9443 - val_loss: 0.1606 - val_accuracy: 0.9450\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1502 - accuracy: 0.9485 - val_loss: 0.1670 - val_accuracy: 0.9417\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1508 - accuracy: 0.9476 - val_loss: 0.1814 - val_accuracy: 0.9365\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1457 - accuracy: 0.9499 - val_loss: 0.1749 - val_accuracy: 0.9390\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1375 - accuracy: 0.9542 - val_loss: 0.1598 - val_accuracy: 0.9442\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1356 - accuracy: 0.9528 - val_loss: 0.1821 - val_accuracy: 0.9371\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1482 - accuracy: 0.9476 - val_loss: 0.1547 - val_accuracy: 0.9479\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1404 - accuracy: 0.9522 - val_loss: 0.1827 - val_accuracy: 0.9396\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1349 - accuracy: 0.9539 - val_loss: 0.1583 - val_accuracy: 0.9448\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1352 - accuracy: 0.9556 - val_loss: 0.1677 - val_accuracy: 0.9431\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1345 - accuracy: 0.9567 - val_loss: 0.1558 - val_accuracy: 0.9494\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1329 - accuracy: 0.9546 - val_loss: 0.1553 - val_accuracy: 0.9438\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1752 - accuracy: 0.9393 - val_loss: 0.1767 - val_accuracy: 0.9413\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1438 - accuracy: 0.9519 - val_loss: 0.1502 - val_accuracy: 0.9473\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1435 - accuracy: 0.9482 - val_loss: 0.1520 - val_accuracy: 0.9502\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1231 - accuracy: 0.9603 - val_loss: 0.1465 - val_accuracy: 0.9517\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1372 - accuracy: 0.9524 - val_loss: 0.2314 - val_accuracy: 0.9179\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1342 - accuracy: 0.9543 - val_loss: 0.1591 - val_accuracy: 0.9473\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1324 - accuracy: 0.9553 - val_loss: 0.1490 - val_accuracy: 0.9498\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1413 - accuracy: 0.9526 - val_loss: 0.1542 - val_accuracy: 0.9467\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1229 - accuracy: 0.9599 - val_loss: 0.1517 - val_accuracy: 0.9504\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1155 - accuracy: 0.9610 - val_loss: 0.1419 - val_accuracy: 0.9523\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1247 - accuracy: 0.9586 - val_loss: 0.1507 - val_accuracy: 0.9521\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1335 - accuracy: 0.9535 - val_loss: 0.1570 - val_accuracy: 0.9469\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1217 - accuracy: 0.9579 - val_loss: 0.1520 - val_accuracy: 0.9504\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1231 - accuracy: 0.9592 - val_loss: 0.1519 - val_accuracy: 0.9477\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1158 - accuracy: 0.9632 - val_loss: 0.1415 - val_accuracy: 0.9527\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1541 - accuracy: 0.9476 - val_loss: 0.1472 - val_accuracy: 0.9508\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1179 - accuracy: 0.9611 - val_loss: 0.1508 - val_accuracy: 0.9508\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1186 - accuracy: 0.9606 - val_loss: 0.1561 - val_accuracy: 0.9458\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1141 - accuracy: 0.9614 - val_loss: 0.1622 - val_accuracy: 0.9413\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1226 - accuracy: 0.9572 - val_loss: 0.2082 - val_accuracy: 0.9246\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1167 - accuracy: 0.9621 - val_loss: 0.1511 - val_accuracy: 0.9515\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1101 - accuracy: 0.9653 - val_loss: 0.1518 - val_accuracy: 0.9513\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1337 - accuracy: 0.9536 - val_loss: 0.1539 - val_accuracy: 0.9504\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1122 - accuracy: 0.9638 - val_loss: 0.1401 - val_accuracy: 0.9567\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1125 - accuracy: 0.9639 - val_loss: 0.1533 - val_accuracy: 0.9498\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1168 - accuracy: 0.9619 - val_loss: 0.1483 - val_accuracy: 0.9508\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1206 - accuracy: 0.9588 - val_loss: 0.1526 - val_accuracy: 0.9496\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1129 - accuracy: 0.9633 - val_loss: 0.1685 - val_accuracy: 0.9381\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1267 - accuracy: 0.9576 - val_loss: 0.1837 - val_accuracy: 0.9417\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1112 - accuracy: 0.9636 - val_loss: 0.1513 - val_accuracy: 0.9483\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1088 - accuracy: 0.9629 - val_loss: 0.1632 - val_accuracy: 0.9429\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1067 - accuracy: 0.9658 - val_loss: 0.1584 - val_accuracy: 0.9481\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1183 - accuracy: 0.9606 - val_loss: 0.1489 - val_accuracy: 0.9494\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1061 - accuracy: 0.9649 - val_loss: 0.1441 - val_accuracy: 0.9548\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1077 - accuracy: 0.9664 - val_loss: 0.1649 - val_accuracy: 0.9417\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1067 - accuracy: 0.9647 - val_loss: 0.1501 - val_accuracy: 0.9517\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9646 - val_loss: 0.1380 - val_accuracy: 0.9508\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1103 - accuracy: 0.9618 - val_loss: 0.1778 - val_accuracy: 0.9440\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1103 - accuracy: 0.9664 - val_loss: 0.1397 - val_accuracy: 0.9565\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1040 - accuracy: 0.9669 - val_loss: 0.1398 - val_accuracy: 0.9554\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0991 - accuracy: 0.9663 - val_loss: 0.1567 - val_accuracy: 0.9519\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1025 - accuracy: 0.9671 - val_loss: 0.1737 - val_accuracy: 0.9381\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0997 - accuracy: 0.9678 - val_loss: 0.1333 - val_accuracy: 0.9563\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1094 - accuracy: 0.9636 - val_loss: 0.2175 - val_accuracy: 0.9281\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1173 - accuracy: 0.9606 - val_loss: 0.1485 - val_accuracy: 0.9519\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1116 - accuracy: 0.9601 - val_loss: 0.1503 - val_accuracy: 0.9463\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1027 - accuracy: 0.9663 - val_loss: 0.1305 - val_accuracy: 0.9571\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1029 - accuracy: 0.9653 - val_loss: 0.1418 - val_accuracy: 0.9527\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1012 - accuracy: 0.9678 - val_loss: 0.1570 - val_accuracy: 0.9471\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1306 - accuracy: 0.9557 - val_loss: 0.1295 - val_accuracy: 0.9604\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1021 - accuracy: 0.9640 - val_loss: 0.1414 - val_accuracy: 0.9535\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0996 - accuracy: 0.9667 - val_loss: 0.1429 - val_accuracy: 0.9510\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1131 - accuracy: 0.9618 - val_loss: 0.1488 - val_accuracy: 0.9490\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1084 - accuracy: 0.9650 - val_loss: 0.1617 - val_accuracy: 0.9467\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1047 - accuracy: 0.9660 - val_loss: 0.1366 - val_accuracy: 0.9558\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0970 - accuracy: 0.9682 - val_loss: 0.1418 - val_accuracy: 0.9571\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1195 - accuracy: 0.9575 - val_loss: 0.1642 - val_accuracy: 0.9452\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1075 - accuracy: 0.9647 - val_loss: 0.1349 - val_accuracy: 0.9542\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1027 - accuracy: 0.9669 - val_loss: 0.1520 - val_accuracy: 0.9498\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1000 - accuracy: 0.9674 - val_loss: 0.1371 - val_accuracy: 0.9563\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1017 - accuracy: 0.9665 - val_loss: 0.1408 - val_accuracy: 0.9548\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0963 - accuracy: 0.9676 - val_loss: 0.1299 - val_accuracy: 0.9592\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0933 - accuracy: 0.9692 - val_loss: 0.1360 - val_accuracy: 0.9577\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0917 - accuracy: 0.9672 - val_loss: 0.1661 - val_accuracy: 0.9454\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0945 - accuracy: 0.9699 - val_loss: 0.1570 - val_accuracy: 0.9517\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0939 - accuracy: 0.9693 - val_loss: 0.1509 - val_accuracy: 0.9510\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0895 - accuracy: 0.9717 - val_loss: 0.1477 - val_accuracy: 0.9533\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0879 - accuracy: 0.9718 - val_loss: 0.1438 - val_accuracy: 0.9554\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1037 - accuracy: 0.9628 - val_loss: 0.1387 - val_accuracy: 0.9544\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0895 - accuracy: 0.9718 - val_loss: 0.1361 - val_accuracy: 0.9585\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1164 - accuracy: 0.9589 - val_loss: 0.1521 - val_accuracy: 0.9496\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1063 - accuracy: 0.9619 - val_loss: 0.2380 - val_accuracy: 0.9137\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1257 - accuracy: 0.9571 - val_loss: 0.1372 - val_accuracy: 0.9581\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0872 - accuracy: 0.9699 - val_loss: 0.1448 - val_accuracy: 0.9538\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0927 - accuracy: 0.9693 - val_loss: 0.1668 - val_accuracy: 0.9427\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1066 - accuracy: 0.9631 - val_loss: 0.1458 - val_accuracy: 0.9554\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0869 - accuracy: 0.9711 - val_loss: 0.1350 - val_accuracy: 0.9571\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0889 - accuracy: 0.9701 - val_loss: 0.1418 - val_accuracy: 0.9573\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0859 - accuracy: 0.9711 - val_loss: 0.1307 - val_accuracy: 0.9594\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0967 - accuracy: 0.9656 - val_loss: 0.1812 - val_accuracy: 0.9342\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0843 - accuracy: 0.9700 - val_loss: 0.1322 - val_accuracy: 0.9598\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0837 - accuracy: 0.9728 - val_loss: 0.1321 - val_accuracy: 0.9606\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0880 - accuracy: 0.9704 - val_loss: 0.1524 - val_accuracy: 0.9554\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0950 - accuracy: 0.9675 - val_loss: 0.1356 - val_accuracy: 0.9590\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0910 - accuracy: 0.9693 - val_loss: 0.1604 - val_accuracy: 0.9494\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0960 - accuracy: 0.9675 - val_loss: 0.1569 - val_accuracy: 0.9454\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0805 - accuracy: 0.9746 - val_loss: 0.1328 - val_accuracy: 0.9588\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1035 - accuracy: 0.9654 - val_loss: 0.1487 - val_accuracy: 0.9525\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0940 - accuracy: 0.9671 - val_loss: 0.1350 - val_accuracy: 0.9577\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0811 - accuracy: 0.9737 - val_loss: 0.1579 - val_accuracy: 0.9502\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0913 - accuracy: 0.9706 - val_loss: 0.1305 - val_accuracy: 0.9610\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0803 - accuracy: 0.9724 - val_loss: 0.1529 - val_accuracy: 0.9542\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0871 - accuracy: 0.9703 - val_loss: 0.1772 - val_accuracy: 0.9456\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0894 - accuracy: 0.9707 - val_loss: 0.1441 - val_accuracy: 0.9506\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0891 - accuracy: 0.9699 - val_loss: 0.1647 - val_accuracy: 0.9502\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0876 - accuracy: 0.9694 - val_loss: 0.1599 - val_accuracy: 0.9492\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0859 - accuracy: 0.9692 - val_loss: 0.1821 - val_accuracy: 0.9340\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0875 - accuracy: 0.9692 - val_loss: 0.1334 - val_accuracy: 0.9581\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0852 - accuracy: 0.9707 - val_loss: 0.1486 - val_accuracy: 0.9540\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0819 - accuracy: 0.9729 - val_loss: 0.1471 - val_accuracy: 0.9552\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9542\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_114 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_114 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " encode_positions_29 (Encode  (None, 95, 24)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_29 (Tra  (None, 95, 24)           2864      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_29 (Gl  (None, 24)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,962\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 5s 14ms/step - loss: 0.7296 - accuracy: 0.5632 - val_loss: 0.6929 - val_accuracy: 0.5767\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6689 - accuracy: 0.6162 - val_loss: 0.6390 - val_accuracy: 0.6596\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6054 - accuracy: 0.7015 - val_loss: 0.5749 - val_accuracy: 0.7292\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5566 - accuracy: 0.7369 - val_loss: 0.5535 - val_accuracy: 0.7008\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5086 - accuracy: 0.7686 - val_loss: 0.4766 - val_accuracy: 0.7825\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4689 - accuracy: 0.7901 - val_loss: 0.4487 - val_accuracy: 0.8067\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4427 - accuracy: 0.8047 - val_loss: 0.4032 - val_accuracy: 0.8365\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4364 - accuracy: 0.8114 - val_loss: 0.4194 - val_accuracy: 0.8331\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4083 - accuracy: 0.8271 - val_loss: 0.3746 - val_accuracy: 0.8540\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3882 - accuracy: 0.8351 - val_loss: 0.4380 - val_accuracy: 0.8156\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4033 - accuracy: 0.8329 - val_loss: 0.3522 - val_accuracy: 0.8646\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3728 - accuracy: 0.8458 - val_loss: 0.4342 - val_accuracy: 0.8146\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3547 - accuracy: 0.8568 - val_loss: 0.3331 - val_accuracy: 0.8754\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3999 - accuracy: 0.8283 - val_loss: 0.4035 - val_accuracy: 0.8363\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3712 - accuracy: 0.8494 - val_loss: 0.3591 - val_accuracy: 0.8546\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3313 - accuracy: 0.8678 - val_loss: 0.3906 - val_accuracy: 0.8377\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3524 - accuracy: 0.8557 - val_loss: 0.3906 - val_accuracy: 0.8410\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3313 - accuracy: 0.8693 - val_loss: 0.2956 - val_accuracy: 0.8929\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2995 - accuracy: 0.8826 - val_loss: 0.3168 - val_accuracy: 0.8731\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2970 - accuracy: 0.8814 - val_loss: 0.3438 - val_accuracy: 0.8450\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2696 - accuracy: 0.8953 - val_loss: 0.2753 - val_accuracy: 0.8985\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2738 - accuracy: 0.8969 - val_loss: 0.2925 - val_accuracy: 0.8883\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2586 - accuracy: 0.9039 - val_loss: 0.2755 - val_accuracy: 0.8960\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2513 - accuracy: 0.9060 - val_loss: 0.2605 - val_accuracy: 0.9081\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2560 - accuracy: 0.9018 - val_loss: 0.2793 - val_accuracy: 0.8965\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2752 - accuracy: 0.8940 - val_loss: 0.2600 - val_accuracy: 0.9040\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2565 - accuracy: 0.9036 - val_loss: 0.2911 - val_accuracy: 0.8925\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2626 - accuracy: 0.8990 - val_loss: 0.2536 - val_accuracy: 0.9031\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2511 - accuracy: 0.9040 - val_loss: 0.2600 - val_accuracy: 0.9015\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2337 - accuracy: 0.9137 - val_loss: 0.2758 - val_accuracy: 0.8983\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2585 - accuracy: 0.9014 - val_loss: 0.2881 - val_accuracy: 0.8967\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2566 - accuracy: 0.9024 - val_loss: 0.2594 - val_accuracy: 0.9000\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2363 - accuracy: 0.9097 - val_loss: 0.4264 - val_accuracy: 0.8096\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2323 - accuracy: 0.9126 - val_loss: 0.2473 - val_accuracy: 0.9090\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2353 - accuracy: 0.9096 - val_loss: 0.2501 - val_accuracy: 0.9060\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2268 - accuracy: 0.9147 - val_loss: 0.2517 - val_accuracy: 0.9052\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2226 - accuracy: 0.9182 - val_loss: 0.2577 - val_accuracy: 0.9058\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2177 - accuracy: 0.9207 - val_loss: 0.4190 - val_accuracy: 0.7752\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2105 - accuracy: 0.9201 - val_loss: 0.2292 - val_accuracy: 0.9154\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2103 - accuracy: 0.9224 - val_loss: 0.2377 - val_accuracy: 0.9131\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2108 - accuracy: 0.9239 - val_loss: 0.2287 - val_accuracy: 0.9229\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2054 - accuracy: 0.9243 - val_loss: 0.2219 - val_accuracy: 0.9200\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2469 - accuracy: 0.9074 - val_loss: 0.2712 - val_accuracy: 0.8990\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2249 - accuracy: 0.9158 - val_loss: 0.2109 - val_accuracy: 0.9235\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1985 - accuracy: 0.9267 - val_loss: 0.2024 - val_accuracy: 0.9265\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2094 - accuracy: 0.9207 - val_loss: 0.2248 - val_accuracy: 0.9225\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2131 - accuracy: 0.9207 - val_loss: 0.2586 - val_accuracy: 0.9046\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1924 - accuracy: 0.9271 - val_loss: 0.2643 - val_accuracy: 0.9071\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2191 - accuracy: 0.9175 - val_loss: 0.2949 - val_accuracy: 0.8885\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2207 - accuracy: 0.9167 - val_loss: 0.2243 - val_accuracy: 0.9179\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1998 - accuracy: 0.9251 - val_loss: 0.2003 - val_accuracy: 0.9254\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1885 - accuracy: 0.9299 - val_loss: 0.2812 - val_accuracy: 0.8910\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1990 - accuracy: 0.9258 - val_loss: 0.2564 - val_accuracy: 0.9023\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1946 - accuracy: 0.9281 - val_loss: 0.2244 - val_accuracy: 0.9210\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1862 - accuracy: 0.9311 - val_loss: 0.2030 - val_accuracy: 0.9267\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2139 - accuracy: 0.9183 - val_loss: 0.2737 - val_accuracy: 0.8973\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1986 - accuracy: 0.9262 - val_loss: 0.2343 - val_accuracy: 0.9079\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1930 - accuracy: 0.9292 - val_loss: 0.2256 - val_accuracy: 0.9179\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2009 - accuracy: 0.9249 - val_loss: 0.1893 - val_accuracy: 0.9354\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1961 - accuracy: 0.9253 - val_loss: 0.1999 - val_accuracy: 0.9292\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1953 - accuracy: 0.9275 - val_loss: 0.1974 - val_accuracy: 0.9340\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1719 - accuracy: 0.9368 - val_loss: 0.2443 - val_accuracy: 0.9056\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1759 - accuracy: 0.9379 - val_loss: 0.1937 - val_accuracy: 0.9317\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1815 - accuracy: 0.9344 - val_loss: 0.2072 - val_accuracy: 0.9254\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1745 - accuracy: 0.9368 - val_loss: 0.2245 - val_accuracy: 0.9187\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1774 - accuracy: 0.9340 - val_loss: 0.1939 - val_accuracy: 0.9308\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1728 - accuracy: 0.9389 - val_loss: 0.2184 - val_accuracy: 0.9290\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1860 - accuracy: 0.9324 - val_loss: 0.2125 - val_accuracy: 0.9198\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1775 - accuracy: 0.9346 - val_loss: 0.2229 - val_accuracy: 0.9190\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1866 - accuracy: 0.9339 - val_loss: 0.1853 - val_accuracy: 0.9348\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2035 - accuracy: 0.9203 - val_loss: 0.2287 - val_accuracy: 0.9171\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1860 - accuracy: 0.9331 - val_loss: 0.1983 - val_accuracy: 0.9271\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1965 - accuracy: 0.9285 - val_loss: 0.2645 - val_accuracy: 0.8981\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1845 - accuracy: 0.9321 - val_loss: 0.2151 - val_accuracy: 0.9198\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1814 - accuracy: 0.9308 - val_loss: 0.2388 - val_accuracy: 0.9142\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1911 - accuracy: 0.9315 - val_loss: 0.1883 - val_accuracy: 0.9331\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1652 - accuracy: 0.9406 - val_loss: 0.1861 - val_accuracy: 0.9354\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1707 - accuracy: 0.9374 - val_loss: 0.1962 - val_accuracy: 0.9337\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1661 - accuracy: 0.9414 - val_loss: 0.1977 - val_accuracy: 0.9296\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1879 - accuracy: 0.9324 - val_loss: 0.1819 - val_accuracy: 0.9335\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1684 - accuracy: 0.9407 - val_loss: 0.1852 - val_accuracy: 0.9319\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1614 - accuracy: 0.9408 - val_loss: 0.1859 - val_accuracy: 0.9365\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1598 - accuracy: 0.9411 - val_loss: 0.1855 - val_accuracy: 0.9367\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1710 - accuracy: 0.9376 - val_loss: 0.2010 - val_accuracy: 0.9273\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1673 - accuracy: 0.9401 - val_loss: 0.1821 - val_accuracy: 0.9356\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1612 - accuracy: 0.9435 - val_loss: 0.1835 - val_accuracy: 0.9348\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1618 - accuracy: 0.9401 - val_loss: 0.1735 - val_accuracy: 0.9400\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1599 - accuracy: 0.9429 - val_loss: 0.1896 - val_accuracy: 0.9331\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1578 - accuracy: 0.9438 - val_loss: 0.1898 - val_accuracy: 0.9337\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1538 - accuracy: 0.9471 - val_loss: 0.1847 - val_accuracy: 0.9392\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1738 - accuracy: 0.9372 - val_loss: 0.1864 - val_accuracy: 0.9348\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1727 - accuracy: 0.9383 - val_loss: 0.1755 - val_accuracy: 0.9356\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1428 - accuracy: 0.9490 - val_loss: 0.1867 - val_accuracy: 0.9333\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1690 - accuracy: 0.9382 - val_loss: 0.1745 - val_accuracy: 0.9394\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1617 - accuracy: 0.9431 - val_loss: 0.1963 - val_accuracy: 0.9306\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1471 - accuracy: 0.9483 - val_loss: 0.1741 - val_accuracy: 0.9381\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1402 - accuracy: 0.9497 - val_loss: 0.2029 - val_accuracy: 0.9296\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1482 - accuracy: 0.9468 - val_loss: 0.1719 - val_accuracy: 0.9408\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1564 - accuracy: 0.9446 - val_loss: 0.1661 - val_accuracy: 0.9435\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1454 - accuracy: 0.9481 - val_loss: 0.1663 - val_accuracy: 0.9442\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1428 - accuracy: 0.9508 - val_loss: 0.1713 - val_accuracy: 0.9413\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1396 - accuracy: 0.9499 - val_loss: 0.1954 - val_accuracy: 0.9319\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1368 - accuracy: 0.9531 - val_loss: 0.1761 - val_accuracy: 0.9381\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1350 - accuracy: 0.9539 - val_loss: 0.1642 - val_accuracy: 0.9465\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1425 - accuracy: 0.9501 - val_loss: 0.1865 - val_accuracy: 0.9381\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1367 - accuracy: 0.9518 - val_loss: 0.1698 - val_accuracy: 0.9415\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1416 - accuracy: 0.9501 - val_loss: 0.1702 - val_accuracy: 0.9419\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1332 - accuracy: 0.9535 - val_loss: 0.1616 - val_accuracy: 0.9456\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1513 - accuracy: 0.9468 - val_loss: 0.1731 - val_accuracy: 0.9421\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1355 - accuracy: 0.9517 - val_loss: 0.1796 - val_accuracy: 0.9435\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1395 - accuracy: 0.9546 - val_loss: 0.1790 - val_accuracy: 0.9362\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1299 - accuracy: 0.9538 - val_loss: 0.1794 - val_accuracy: 0.9390\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1264 - accuracy: 0.9557 - val_loss: 0.1609 - val_accuracy: 0.9458\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1266 - accuracy: 0.9581 - val_loss: 0.1552 - val_accuracy: 0.9502\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1268 - accuracy: 0.9569 - val_loss: 0.1952 - val_accuracy: 0.9296\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1415 - accuracy: 0.9510 - val_loss: 0.1588 - val_accuracy: 0.9488\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1366 - accuracy: 0.9515 - val_loss: 0.1946 - val_accuracy: 0.9331\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1363 - accuracy: 0.9519 - val_loss: 0.1487 - val_accuracy: 0.9517\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1314 - accuracy: 0.9535 - val_loss: 0.1770 - val_accuracy: 0.9398\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1254 - accuracy: 0.9551 - val_loss: 0.1913 - val_accuracy: 0.9365\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1384 - accuracy: 0.9513 - val_loss: 0.2241 - val_accuracy: 0.9225\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1411 - accuracy: 0.9503 - val_loss: 0.1700 - val_accuracy: 0.9456\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1288 - accuracy: 0.9567 - val_loss: 0.1778 - val_accuracy: 0.9410\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1171 - accuracy: 0.9617 - val_loss: 0.1495 - val_accuracy: 0.9515\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1168 - accuracy: 0.9594 - val_loss: 0.1527 - val_accuracy: 0.9502\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1259 - accuracy: 0.9575 - val_loss: 0.1594 - val_accuracy: 0.9473\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1300 - accuracy: 0.9558 - val_loss: 0.1597 - val_accuracy: 0.9521\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1211 - accuracy: 0.9567 - val_loss: 0.2032 - val_accuracy: 0.9325\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1224 - accuracy: 0.9574 - val_loss: 0.1612 - val_accuracy: 0.9446\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1127 - accuracy: 0.9604 - val_loss: 0.1730 - val_accuracy: 0.9454\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1236 - accuracy: 0.9557 - val_loss: 0.1700 - val_accuracy: 0.9440\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1169 - accuracy: 0.9597 - val_loss: 0.1498 - val_accuracy: 0.9527\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1135 - accuracy: 0.9607 - val_loss: 0.1391 - val_accuracy: 0.9565\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1418 - accuracy: 0.9493 - val_loss: 0.2037 - val_accuracy: 0.9342\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1152 - accuracy: 0.9600 - val_loss: 0.1679 - val_accuracy: 0.9452\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1142 - accuracy: 0.9617 - val_loss: 0.1507 - val_accuracy: 0.9519\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1068 - accuracy: 0.9628 - val_loss: 0.1579 - val_accuracy: 0.9500\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1172 - accuracy: 0.9586 - val_loss: 0.1809 - val_accuracy: 0.9458\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1401 - accuracy: 0.9492 - val_loss: 0.1636 - val_accuracy: 0.9469\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1239 - accuracy: 0.9572 - val_loss: 0.1628 - val_accuracy: 0.9452\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1062 - accuracy: 0.9617 - val_loss: 0.1633 - val_accuracy: 0.9452\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1799 - accuracy: 0.9331 - val_loss: 0.3233 - val_accuracy: 0.8769\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2061 - accuracy: 0.9226 - val_loss: 0.1863 - val_accuracy: 0.9375\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1132 - accuracy: 0.9597 - val_loss: 0.1536 - val_accuracy: 0.9477\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1080 - accuracy: 0.9600 - val_loss: 0.1464 - val_accuracy: 0.9513\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1053 - accuracy: 0.9631 - val_loss: 0.1568 - val_accuracy: 0.9492\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1107 - accuracy: 0.9614 - val_loss: 0.1547 - val_accuracy: 0.9508\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1066 - accuracy: 0.9622 - val_loss: 0.1615 - val_accuracy: 0.9485\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1116 - accuracy: 0.9597 - val_loss: 0.1429 - val_accuracy: 0.9558\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1061 - accuracy: 0.9618 - val_loss: 0.1436 - val_accuracy: 0.9583\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1025 - accuracy: 0.9643 - val_loss: 0.1512 - val_accuracy: 0.9513\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1199 - accuracy: 0.9579 - val_loss: 0.1462 - val_accuracy: 0.9546\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1082 - accuracy: 0.9622 - val_loss: 0.1454 - val_accuracy: 0.9560\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1089 - accuracy: 0.9610 - val_loss: 0.1440 - val_accuracy: 0.9540\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1079 - accuracy: 0.9628 - val_loss: 0.1583 - val_accuracy: 0.9494\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1070 - accuracy: 0.9611 - val_loss: 0.1533 - val_accuracy: 0.9525\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0971 - accuracy: 0.9660 - val_loss: 0.1466 - val_accuracy: 0.9529\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1010 - accuracy: 0.9632 - val_loss: 0.1522 - val_accuracy: 0.9515\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0991 - accuracy: 0.9646 - val_loss: 0.1451 - val_accuracy: 0.9552\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1065 - accuracy: 0.9615 - val_loss: 0.1668 - val_accuracy: 0.9467\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9639 - val_loss: 0.1437 - val_accuracy: 0.9519\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1477 - accuracy: 0.9469 - val_loss: 0.1629 - val_accuracy: 0.9517\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1001 - accuracy: 0.9663 - val_loss: 0.1555 - val_accuracy: 0.9502\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0997 - accuracy: 0.9635 - val_loss: 0.1476 - val_accuracy: 0.9554\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0898 - accuracy: 0.9708 - val_loss: 0.1526 - val_accuracy: 0.9554\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1014 - accuracy: 0.9657 - val_loss: 0.1518 - val_accuracy: 0.9517\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1020 - accuracy: 0.9639 - val_loss: 0.1405 - val_accuracy: 0.9575\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0947 - accuracy: 0.9664 - val_loss: 0.1930 - val_accuracy: 0.9396\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1229 - accuracy: 0.9563 - val_loss: 0.1514 - val_accuracy: 0.9540\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0991 - accuracy: 0.9653 - val_loss: 0.1477 - val_accuracy: 0.9577\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1008 - accuracy: 0.9663 - val_loss: 0.2060 - val_accuracy: 0.9375\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1328 - accuracy: 0.9543 - val_loss: 0.2076 - val_accuracy: 0.9342\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1221 - accuracy: 0.9563 - val_loss: 0.1630 - val_accuracy: 0.9498\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0956 - accuracy: 0.9657 - val_loss: 0.1520 - val_accuracy: 0.9531\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0919 - accuracy: 0.9682 - val_loss: 0.1378 - val_accuracy: 0.9579\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0871 - accuracy: 0.9710 - val_loss: 0.1532 - val_accuracy: 0.9546\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0930 - accuracy: 0.9675 - val_loss: 0.1666 - val_accuracy: 0.9494\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9640 - val_loss: 0.1451 - val_accuracy: 0.9569\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0958 - accuracy: 0.9668 - val_loss: 0.1740 - val_accuracy: 0.9471\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0864 - accuracy: 0.9700 - val_loss: 0.1371 - val_accuracy: 0.9594\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0819 - accuracy: 0.9725 - val_loss: 0.1516 - val_accuracy: 0.9533\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0838 - accuracy: 0.9714 - val_loss: 0.1412 - val_accuracy: 0.9575\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1072 - accuracy: 0.9629 - val_loss: 0.1495 - val_accuracy: 0.9581\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1014 - accuracy: 0.9639 - val_loss: 0.2093 - val_accuracy: 0.9352\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1043 - accuracy: 0.9649 - val_loss: 0.1597 - val_accuracy: 0.9515\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0937 - accuracy: 0.9671 - val_loss: 0.1496 - val_accuracy: 0.9540\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0951 - accuracy: 0.9650 - val_loss: 0.2349 - val_accuracy: 0.9319\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1014 - accuracy: 0.9649 - val_loss: 0.1501 - val_accuracy: 0.9565\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0897 - accuracy: 0.9693 - val_loss: 0.1448 - val_accuracy: 0.9546\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0863 - accuracy: 0.9703 - val_loss: 0.1777 - val_accuracy: 0.9452\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0934 - accuracy: 0.9674 - val_loss: 0.1451 - val_accuracy: 0.9581\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0872 - accuracy: 0.9706 - val_loss: 0.2121 - val_accuracy: 0.9369\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1073 - accuracy: 0.9631 - val_loss: 0.1359 - val_accuracy: 0.9600\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0897 - accuracy: 0.9678 - val_loss: 0.2220 - val_accuracy: 0.9356\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1082 - accuracy: 0.9606 - val_loss: 0.1772 - val_accuracy: 0.9458\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0868 - accuracy: 0.9701 - val_loss: 0.1497 - val_accuracy: 0.9544\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0818 - accuracy: 0.9729 - val_loss: 0.1465 - val_accuracy: 0.9583\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0809 - accuracy: 0.9721 - val_loss: 0.1426 - val_accuracy: 0.9606\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0768 - accuracy: 0.9750 - val_loss: 0.1709 - val_accuracy: 0.9500\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0838 - accuracy: 0.9711 - val_loss: 0.1560 - val_accuracy: 0.9556\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1489 - accuracy: 0.9546\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_115 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_115 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " encode_positions_30 (Encode  (None, 95, 24)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_30 (Tra  (None, 95, 24)           2864      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_30 (Gl  (None, 24)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,962\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 14ms/step - loss: 0.7869 - accuracy: 0.5242 - val_loss: 0.7126 - val_accuracy: 0.5535\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6885 - accuracy: 0.5765 - val_loss: 0.6651 - val_accuracy: 0.6067\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6403 - accuracy: 0.6551 - val_loss: 0.6011 - val_accuracy: 0.7031\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5572 - accuracy: 0.7331 - val_loss: 0.5855 - val_accuracy: 0.6885\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5062 - accuracy: 0.7524 - val_loss: 0.4447 - val_accuracy: 0.8010\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4472 - accuracy: 0.7958 - val_loss: 0.4171 - val_accuracy: 0.8112\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4319 - accuracy: 0.7999 - val_loss: 0.4522 - val_accuracy: 0.7817\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4079 - accuracy: 0.8171 - val_loss: 0.3778 - val_accuracy: 0.8342\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3841 - accuracy: 0.8378 - val_loss: 0.3666 - val_accuracy: 0.8575\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3966 - accuracy: 0.8231 - val_loss: 0.3623 - val_accuracy: 0.8423\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3502 - accuracy: 0.8529 - val_loss: 0.3407 - val_accuracy: 0.8598\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4269 - accuracy: 0.8068 - val_loss: 0.3431 - val_accuracy: 0.8631\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3330 - accuracy: 0.8649 - val_loss: 0.3242 - val_accuracy: 0.8675\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3419 - accuracy: 0.8622 - val_loss: 0.3304 - val_accuracy: 0.8687\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3474 - accuracy: 0.8589 - val_loss: 0.3432 - val_accuracy: 0.8587\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3231 - accuracy: 0.8699 - val_loss: 0.3195 - val_accuracy: 0.8727\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3245 - accuracy: 0.8689 - val_loss: 0.3760 - val_accuracy: 0.8358\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3244 - accuracy: 0.8711 - val_loss: 0.3061 - val_accuracy: 0.8756\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3092 - accuracy: 0.8790 - val_loss: 0.3093 - val_accuracy: 0.8806\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3161 - accuracy: 0.8742 - val_loss: 0.3183 - val_accuracy: 0.8648\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3048 - accuracy: 0.8803 - val_loss: 0.2943 - val_accuracy: 0.8829\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2979 - accuracy: 0.8843 - val_loss: 0.3365 - val_accuracy: 0.8485\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3584 - accuracy: 0.8499 - val_loss: 0.2948 - val_accuracy: 0.8796\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3028 - accuracy: 0.8808 - val_loss: 0.3035 - val_accuracy: 0.8740\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2924 - accuracy: 0.8851 - val_loss: 0.2872 - val_accuracy: 0.8852\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2853 - accuracy: 0.8867 - val_loss: 0.3039 - val_accuracy: 0.8773\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2871 - accuracy: 0.8857 - val_loss: 0.3007 - val_accuracy: 0.8758\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2847 - accuracy: 0.8881 - val_loss: 0.2612 - val_accuracy: 0.8979\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2754 - accuracy: 0.8924 - val_loss: 0.2744 - val_accuracy: 0.8917\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2674 - accuracy: 0.8975 - val_loss: 0.2716 - val_accuracy: 0.8921\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2702 - accuracy: 0.8971 - val_loss: 0.2779 - val_accuracy: 0.8888\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2724 - accuracy: 0.8935 - val_loss: 0.2764 - val_accuracy: 0.8873\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2547 - accuracy: 0.9019 - val_loss: 0.2484 - val_accuracy: 0.9010\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2482 - accuracy: 0.9050 - val_loss: 0.2750 - val_accuracy: 0.8856\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2599 - accuracy: 0.8957 - val_loss: 0.2718 - val_accuracy: 0.8942\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2470 - accuracy: 0.9060 - val_loss: 0.2335 - val_accuracy: 0.9100\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2387 - accuracy: 0.9086 - val_loss: 0.2535 - val_accuracy: 0.8954\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2439 - accuracy: 0.9069 - val_loss: 0.2439 - val_accuracy: 0.9019\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2298 - accuracy: 0.9126 - val_loss: 0.2331 - val_accuracy: 0.9077\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2276 - accuracy: 0.9132 - val_loss: 0.2296 - val_accuracy: 0.9119\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2172 - accuracy: 0.9146 - val_loss: 0.2319 - val_accuracy: 0.9092\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2124 - accuracy: 0.9171 - val_loss: 0.2382 - val_accuracy: 0.9067\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2131 - accuracy: 0.9174 - val_loss: 0.2228 - val_accuracy: 0.9108\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2144 - accuracy: 0.9171 - val_loss: 0.2026 - val_accuracy: 0.9223\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2032 - accuracy: 0.9210 - val_loss: 0.2280 - val_accuracy: 0.9102\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2061 - accuracy: 0.9190 - val_loss: 0.2150 - val_accuracy: 0.9140\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2042 - accuracy: 0.9231 - val_loss: 0.2191 - val_accuracy: 0.9102\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1935 - accuracy: 0.9256 - val_loss: 0.1952 - val_accuracy: 0.9229\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2013 - accuracy: 0.9217 - val_loss: 0.2138 - val_accuracy: 0.9150\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1953 - accuracy: 0.9226 - val_loss: 0.2190 - val_accuracy: 0.9104\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1876 - accuracy: 0.9269 - val_loss: 0.2104 - val_accuracy: 0.9165\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1918 - accuracy: 0.9281 - val_loss: 0.1932 - val_accuracy: 0.9227\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1904 - accuracy: 0.9256 - val_loss: 0.1881 - val_accuracy: 0.9235\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1716 - accuracy: 0.9350 - val_loss: 0.1830 - val_accuracy: 0.9265\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1812 - accuracy: 0.9271 - val_loss: 0.1985 - val_accuracy: 0.9171\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1865 - accuracy: 0.9264 - val_loss: 0.1937 - val_accuracy: 0.9273\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1767 - accuracy: 0.9308 - val_loss: 0.1830 - val_accuracy: 0.9258\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1739 - accuracy: 0.9346 - val_loss: 0.1729 - val_accuracy: 0.9315\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1673 - accuracy: 0.9354 - val_loss: 0.1786 - val_accuracy: 0.9294\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1712 - accuracy: 0.9357 - val_loss: 0.1924 - val_accuracy: 0.9271\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1722 - accuracy: 0.9329 - val_loss: 0.2135 - val_accuracy: 0.9094\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1722 - accuracy: 0.9325 - val_loss: 0.1832 - val_accuracy: 0.9260\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1567 - accuracy: 0.9401 - val_loss: 0.1671 - val_accuracy: 0.9344\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1568 - accuracy: 0.9429 - val_loss: 0.1648 - val_accuracy: 0.9333\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1541 - accuracy: 0.9400 - val_loss: 0.1749 - val_accuracy: 0.9317\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1624 - accuracy: 0.9374 - val_loss: 0.1657 - val_accuracy: 0.9298\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1764 - accuracy: 0.9322 - val_loss: 0.1746 - val_accuracy: 0.9310\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1551 - accuracy: 0.9432 - val_loss: 0.1704 - val_accuracy: 0.9327\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1431 - accuracy: 0.9451 - val_loss: 0.1584 - val_accuracy: 0.9377\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1437 - accuracy: 0.9449 - val_loss: 0.1642 - val_accuracy: 0.9352\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1461 - accuracy: 0.9449 - val_loss: 0.1686 - val_accuracy: 0.9342\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1419 - accuracy: 0.9472 - val_loss: 0.1626 - val_accuracy: 0.9381\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1447 - accuracy: 0.9446 - val_loss: 0.1618 - val_accuracy: 0.9392\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1457 - accuracy: 0.9411 - val_loss: 0.1710 - val_accuracy: 0.9362\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1532 - accuracy: 0.9415 - val_loss: 0.1656 - val_accuracy: 0.9327\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1383 - accuracy: 0.9472 - val_loss: 0.1874 - val_accuracy: 0.9277\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1422 - accuracy: 0.9432 - val_loss: 0.1934 - val_accuracy: 0.9225\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1379 - accuracy: 0.9479 - val_loss: 0.1873 - val_accuracy: 0.9312\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1355 - accuracy: 0.9486 - val_loss: 0.1681 - val_accuracy: 0.9354\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1333 - accuracy: 0.9494 - val_loss: 0.1545 - val_accuracy: 0.9371\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1294 - accuracy: 0.9517 - val_loss: 0.1804 - val_accuracy: 0.9296\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1468 - accuracy: 0.9443 - val_loss: 0.1518 - val_accuracy: 0.9410\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1281 - accuracy: 0.9536 - val_loss: 0.1551 - val_accuracy: 0.9390\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1349 - accuracy: 0.9483 - val_loss: 0.1607 - val_accuracy: 0.9360\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1327 - accuracy: 0.9486 - val_loss: 0.1486 - val_accuracy: 0.9442\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1298 - accuracy: 0.9513 - val_loss: 0.1483 - val_accuracy: 0.9435\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1268 - accuracy: 0.9511 - val_loss: 0.1456 - val_accuracy: 0.9454\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1270 - accuracy: 0.9538 - val_loss: 0.1511 - val_accuracy: 0.9406\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1304 - accuracy: 0.9528 - val_loss: 0.1608 - val_accuracy: 0.9352\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1226 - accuracy: 0.9521 - val_loss: 0.1620 - val_accuracy: 0.9394\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1280 - accuracy: 0.9546 - val_loss: 0.1564 - val_accuracy: 0.9410\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1241 - accuracy: 0.9549 - val_loss: 0.1575 - val_accuracy: 0.9419\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1182 - accuracy: 0.9539 - val_loss: 0.1448 - val_accuracy: 0.9471\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1135 - accuracy: 0.9586 - val_loss: 0.1406 - val_accuracy: 0.9481\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1168 - accuracy: 0.9569 - val_loss: 0.1460 - val_accuracy: 0.9469\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1174 - accuracy: 0.9557 - val_loss: 0.1552 - val_accuracy: 0.9415\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1251 - accuracy: 0.9557 - val_loss: 0.1624 - val_accuracy: 0.9375\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1182 - accuracy: 0.9568 - val_loss: 0.1692 - val_accuracy: 0.9344\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1199 - accuracy: 0.9557 - val_loss: 0.1762 - val_accuracy: 0.9346\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1107 - accuracy: 0.9617 - val_loss: 0.1411 - val_accuracy: 0.9460\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1063 - accuracy: 0.9604 - val_loss: 0.1473 - val_accuracy: 0.9456\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1074 - accuracy: 0.9607 - val_loss: 0.1439 - val_accuracy: 0.9483\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1090 - accuracy: 0.9581 - val_loss: 0.1525 - val_accuracy: 0.9446\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1167 - accuracy: 0.9576 - val_loss: 0.1374 - val_accuracy: 0.9502\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1069 - accuracy: 0.9619 - val_loss: 0.1296 - val_accuracy: 0.9531\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1075 - accuracy: 0.9628 - val_loss: 0.1422 - val_accuracy: 0.9471\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1078 - accuracy: 0.9619 - val_loss: 0.1512 - val_accuracy: 0.9467\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1070 - accuracy: 0.9618 - val_loss: 0.1328 - val_accuracy: 0.9527\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1052 - accuracy: 0.9619 - val_loss: 0.1379 - val_accuracy: 0.9498\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1071 - accuracy: 0.9597 - val_loss: 0.1375 - val_accuracy: 0.9494\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1030 - accuracy: 0.9622 - val_loss: 0.1725 - val_accuracy: 0.9352\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1070 - accuracy: 0.9611 - val_loss: 0.1432 - val_accuracy: 0.9483\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1071 - accuracy: 0.9608 - val_loss: 0.1320 - val_accuracy: 0.9513\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1014 - accuracy: 0.9653 - val_loss: 0.1254 - val_accuracy: 0.9548\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0954 - accuracy: 0.9647 - val_loss: 0.1373 - val_accuracy: 0.9504\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0963 - accuracy: 0.9658 - val_loss: 0.1257 - val_accuracy: 0.9533\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1009 - accuracy: 0.9650 - val_loss: 0.1267 - val_accuracy: 0.9540\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0934 - accuracy: 0.9678 - val_loss: 0.1294 - val_accuracy: 0.9542\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0964 - accuracy: 0.9663 - val_loss: 0.1491 - val_accuracy: 0.9431\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0951 - accuracy: 0.9679 - val_loss: 0.1332 - val_accuracy: 0.9544\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1076 - accuracy: 0.9631 - val_loss: 0.1349 - val_accuracy: 0.9469\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0927 - accuracy: 0.9668 - val_loss: 0.1244 - val_accuracy: 0.9527\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0883 - accuracy: 0.9697 - val_loss: 0.1244 - val_accuracy: 0.9552\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0910 - accuracy: 0.9671 - val_loss: 0.1340 - val_accuracy: 0.9513\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0980 - accuracy: 0.9638 - val_loss: 0.1469 - val_accuracy: 0.9465\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0930 - accuracy: 0.9688 - val_loss: 0.1355 - val_accuracy: 0.9521\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0871 - accuracy: 0.9688 - val_loss: 0.1163 - val_accuracy: 0.9556\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0911 - accuracy: 0.9671 - val_loss: 0.1278 - val_accuracy: 0.9548\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0853 - accuracy: 0.9712 - val_loss: 0.1149 - val_accuracy: 0.9594\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0883 - accuracy: 0.9696 - val_loss: 0.1360 - val_accuracy: 0.9544\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0846 - accuracy: 0.9700 - val_loss: 0.1146 - val_accuracy: 0.9600\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0821 - accuracy: 0.9721 - val_loss: 0.1155 - val_accuracy: 0.9592\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0859 - accuracy: 0.9714 - val_loss: 0.1251 - val_accuracy: 0.9558\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0875 - accuracy: 0.9704 - val_loss: 0.1367 - val_accuracy: 0.9533\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0858 - accuracy: 0.9704 - val_loss: 0.1260 - val_accuracy: 0.9567\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0883 - accuracy: 0.9697 - val_loss: 0.1227 - val_accuracy: 0.9583\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0805 - accuracy: 0.9726 - val_loss: 0.1125 - val_accuracy: 0.9608\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0833 - accuracy: 0.9735 - val_loss: 0.1220 - val_accuracy: 0.9538\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0788 - accuracy: 0.9736 - val_loss: 0.1211 - val_accuracy: 0.9560\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0746 - accuracy: 0.9758 - val_loss: 0.1202 - val_accuracy: 0.9542\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0844 - accuracy: 0.9718 - val_loss: 0.1217 - val_accuracy: 0.9569\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0758 - accuracy: 0.9742 - val_loss: 0.1522 - val_accuracy: 0.9494\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0778 - accuracy: 0.9736 - val_loss: 0.1232 - val_accuracy: 0.9548\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0798 - accuracy: 0.9725 - val_loss: 0.1436 - val_accuracy: 0.9483\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0784 - accuracy: 0.9739 - val_loss: 0.1183 - val_accuracy: 0.9573\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0839 - accuracy: 0.9732 - val_loss: 0.1363 - val_accuracy: 0.9533\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0801 - accuracy: 0.9729 - val_loss: 0.1190 - val_accuracy: 0.9577\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0859 - accuracy: 0.9692 - val_loss: 0.1278 - val_accuracy: 0.9554\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0717 - accuracy: 0.9747 - val_loss: 0.1260 - val_accuracy: 0.9571\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0764 - accuracy: 0.9757 - val_loss: 0.1135 - val_accuracy: 0.9579\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0740 - accuracy: 0.9757 - val_loss: 0.1198 - val_accuracy: 0.9544\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0785 - accuracy: 0.9740 - val_loss: 0.1158 - val_accuracy: 0.9560\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0754 - accuracy: 0.9746 - val_loss: 0.1182 - val_accuracy: 0.9596\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0793 - accuracy: 0.9731 - val_loss: 0.1195 - val_accuracy: 0.9567\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0752 - accuracy: 0.9747 - val_loss: 0.1094 - val_accuracy: 0.9640\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0700 - accuracy: 0.9757 - val_loss: 0.1258 - val_accuracy: 0.9567\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0761 - accuracy: 0.9733 - val_loss: 0.1221 - val_accuracy: 0.9567\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0680 - accuracy: 0.9781 - val_loss: 0.1465 - val_accuracy: 0.9490\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0716 - accuracy: 0.9757 - val_loss: 0.1230 - val_accuracy: 0.9575\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0743 - accuracy: 0.9753 - val_loss: 0.1160 - val_accuracy: 0.9581\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0701 - accuracy: 0.9764 - val_loss: 0.1223 - val_accuracy: 0.9600\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0686 - accuracy: 0.9778 - val_loss: 0.1094 - val_accuracy: 0.9619\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0812 - accuracy: 0.9719 - val_loss: 0.1272 - val_accuracy: 0.9567\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0749 - accuracy: 0.9749 - val_loss: 0.1236 - val_accuracy: 0.9546\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0678 - accuracy: 0.9781 - val_loss: 0.1100 - val_accuracy: 0.9596\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0718 - accuracy: 0.9769 - val_loss: 0.1250 - val_accuracy: 0.9565\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0718 - accuracy: 0.9771 - val_loss: 0.1087 - val_accuracy: 0.9621\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0649 - accuracy: 0.9772 - val_loss: 0.1098 - val_accuracy: 0.9596\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0684 - accuracy: 0.9758 - val_loss: 0.1243 - val_accuracy: 0.9519\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0758 - accuracy: 0.9728 - val_loss: 0.1189 - val_accuracy: 0.9588\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0697 - accuracy: 0.9762 - val_loss: 0.1379 - val_accuracy: 0.9498\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0804 - accuracy: 0.9725 - val_loss: 0.1591 - val_accuracy: 0.9463\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0736 - accuracy: 0.9750 - val_loss: 0.1187 - val_accuracy: 0.9613\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0664 - accuracy: 0.9764 - val_loss: 0.1245 - val_accuracy: 0.9550\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0723 - accuracy: 0.9731 - val_loss: 0.1098 - val_accuracy: 0.9631\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0616 - accuracy: 0.9804 - val_loss: 0.1097 - val_accuracy: 0.9633\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0606 - accuracy: 0.9794 - val_loss: 0.1121 - val_accuracy: 0.9617\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0624 - accuracy: 0.9781 - val_loss: 0.1071 - val_accuracy: 0.9617\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.1183 - val_accuracy: 0.9590\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0599 - accuracy: 0.9807 - val_loss: 0.1036 - val_accuracy: 0.9648\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0621 - accuracy: 0.9790 - val_loss: 0.1098 - val_accuracy: 0.9592\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0617 - accuracy: 0.9799 - val_loss: 0.1111 - val_accuracy: 0.9594\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0594 - accuracy: 0.9789 - val_loss: 0.1206 - val_accuracy: 0.9590\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0625 - accuracy: 0.9782 - val_loss: 0.1273 - val_accuracy: 0.9550\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0747 - accuracy: 0.9747 - val_loss: 0.1238 - val_accuracy: 0.9565\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0588 - accuracy: 0.9799 - val_loss: 0.1252 - val_accuracy: 0.9538\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0590 - accuracy: 0.9787 - val_loss: 0.1067 - val_accuracy: 0.9631\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 0.1147 - val_accuracy: 0.9621\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0545 - accuracy: 0.9815 - val_loss: 0.1180 - val_accuracy: 0.9563\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 0.1048 - val_accuracy: 0.9633\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0620 - accuracy: 0.9790 - val_loss: 0.1045 - val_accuracy: 0.9640\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0550 - accuracy: 0.9819 - val_loss: 0.1155 - val_accuracy: 0.9606\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0609 - accuracy: 0.9800 - val_loss: 0.1097 - val_accuracy: 0.9602\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0558 - accuracy: 0.9812 - val_loss: 0.1076 - val_accuracy: 0.9608\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0596 - accuracy: 0.9803 - val_loss: 0.1056 - val_accuracy: 0.9621\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0536 - accuracy: 0.9818 - val_loss: 0.1221 - val_accuracy: 0.9535\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0617 - accuracy: 0.9786 - val_loss: 0.1093 - val_accuracy: 0.9625\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0549 - accuracy: 0.9825 - val_loss: 0.1080 - val_accuracy: 0.9617\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.1032 - val_accuracy: 0.9613\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.1035 - val_accuracy: 0.9625\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9640\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_116 (Masking)       (None, 95, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_116 (La  (None, 95, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " encode_positions_31 (Encode  (None, 95, 24)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_31 (Tra  (None, 95, 24)           2864      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_31 (Gl  (None, 24)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,962\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "113/113 [==============================] - 3s 14ms/step - loss: 0.8794 - accuracy: 0.5132 - val_loss: 0.7156 - val_accuracy: 0.5373\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6926 - accuracy: 0.5661 - val_loss: 0.6545 - val_accuracy: 0.6342\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6146 - accuracy: 0.6774 - val_loss: 0.5862 - val_accuracy: 0.7171\n",
      "Epoch 4/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5504 - accuracy: 0.7389 - val_loss: 0.5101 - val_accuracy: 0.7806\n",
      "Epoch 5/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5318 - accuracy: 0.7387 - val_loss: 0.5167 - val_accuracy: 0.7412\n",
      "Epoch 6/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4911 - accuracy: 0.7804 - val_loss: 0.4746 - val_accuracy: 0.7935\n",
      "Epoch 7/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4807 - accuracy: 0.7828 - val_loss: 0.4470 - val_accuracy: 0.8104\n",
      "Epoch 8/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4489 - accuracy: 0.8060 - val_loss: 0.5280 - val_accuracy: 0.7396\n",
      "Epoch 9/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4488 - accuracy: 0.8040 - val_loss: 0.4736 - val_accuracy: 0.7833\n",
      "Epoch 10/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4323 - accuracy: 0.8086 - val_loss: 0.4091 - val_accuracy: 0.8319\n",
      "Epoch 11/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4226 - accuracy: 0.8146 - val_loss: 0.4108 - val_accuracy: 0.8308\n",
      "Epoch 12/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4199 - accuracy: 0.8178 - val_loss: 0.4466 - val_accuracy: 0.7935\n",
      "Epoch 13/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4237 - accuracy: 0.8118 - val_loss: 0.4221 - val_accuracy: 0.8098\n",
      "Epoch 14/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3943 - accuracy: 0.8292 - val_loss: 0.3740 - val_accuracy: 0.8458\n",
      "Epoch 15/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3952 - accuracy: 0.8322 - val_loss: 0.3956 - val_accuracy: 0.8300\n",
      "Epoch 16/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3858 - accuracy: 0.8347 - val_loss: 0.3656 - val_accuracy: 0.8446\n",
      "Epoch 17/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3653 - accuracy: 0.8454 - val_loss: 0.4241 - val_accuracy: 0.8104\n",
      "Epoch 18/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4641 - accuracy: 0.7847 - val_loss: 0.4710 - val_accuracy: 0.7917\n",
      "Epoch 19/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4029 - accuracy: 0.8285 - val_loss: 0.3973 - val_accuracy: 0.8321\n",
      "Epoch 20/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4015 - accuracy: 0.8283 - val_loss: 0.4187 - val_accuracy: 0.8285\n",
      "Epoch 21/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3737 - accuracy: 0.8447 - val_loss: 0.3821 - val_accuracy: 0.8375\n",
      "Epoch 22/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3697 - accuracy: 0.8449 - val_loss: 0.3523 - val_accuracy: 0.8579\n",
      "Epoch 23/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3418 - accuracy: 0.8650 - val_loss: 0.4010 - val_accuracy: 0.8338\n",
      "Epoch 24/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3534 - accuracy: 0.8565 - val_loss: 0.3371 - val_accuracy: 0.8650\n",
      "Epoch 25/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3531 - accuracy: 0.8556 - val_loss: 0.3371 - val_accuracy: 0.8654\n",
      "Epoch 26/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3292 - accuracy: 0.8676 - val_loss: 0.7442 - val_accuracy: 0.5119\n",
      "Epoch 27/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3620 - accuracy: 0.8539 - val_loss: 0.3130 - val_accuracy: 0.8790\n",
      "Epoch 28/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3218 - accuracy: 0.8725 - val_loss: 0.3267 - val_accuracy: 0.8677\n",
      "Epoch 29/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3329 - accuracy: 0.8671 - val_loss: 0.3940 - val_accuracy: 0.8354\n",
      "Epoch 30/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3302 - accuracy: 0.8664 - val_loss: 0.3215 - val_accuracy: 0.8763\n",
      "Epoch 31/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3195 - accuracy: 0.8758 - val_loss: 0.2992 - val_accuracy: 0.8865\n",
      "Epoch 32/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3148 - accuracy: 0.8721 - val_loss: 0.3181 - val_accuracy: 0.8748\n",
      "Epoch 33/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3051 - accuracy: 0.8806 - val_loss: 0.2937 - val_accuracy: 0.8854\n",
      "Epoch 34/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3167 - accuracy: 0.8710 - val_loss: 0.2803 - val_accuracy: 0.8931\n",
      "Epoch 35/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2979 - accuracy: 0.8803 - val_loss: 0.3095 - val_accuracy: 0.8760\n",
      "Epoch 36/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3044 - accuracy: 0.8776 - val_loss: 0.3045 - val_accuracy: 0.8815\n",
      "Epoch 37/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3141 - accuracy: 0.8743 - val_loss: 0.3430 - val_accuracy: 0.8604\n",
      "Epoch 38/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3063 - accuracy: 0.8803 - val_loss: 0.2860 - val_accuracy: 0.8898\n",
      "Epoch 39/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2864 - accuracy: 0.8897 - val_loss: 0.3251 - val_accuracy: 0.8654\n",
      "Epoch 40/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2678 - accuracy: 0.8999 - val_loss: 0.2873 - val_accuracy: 0.8873\n",
      "Epoch 41/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2985 - accuracy: 0.8828 - val_loss: 0.3057 - val_accuracy: 0.8752\n",
      "Epoch 42/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2732 - accuracy: 0.8972 - val_loss: 0.2543 - val_accuracy: 0.8971\n",
      "Epoch 43/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2879 - accuracy: 0.8878 - val_loss: 0.4216 - val_accuracy: 0.8258\n",
      "Epoch 44/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3064 - accuracy: 0.8796 - val_loss: 0.2906 - val_accuracy: 0.8946\n",
      "Epoch 45/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2933 - accuracy: 0.8846 - val_loss: 0.2960 - val_accuracy: 0.8913\n",
      "Epoch 46/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2856 - accuracy: 0.8889 - val_loss: 0.3353 - val_accuracy: 0.8550\n",
      "Epoch 47/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2608 - accuracy: 0.8997 - val_loss: 0.2813 - val_accuracy: 0.8952\n",
      "Epoch 48/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2630 - accuracy: 0.9001 - val_loss: 0.2558 - val_accuracy: 0.8981\n",
      "Epoch 49/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2541 - accuracy: 0.9011 - val_loss: 0.2646 - val_accuracy: 0.9021\n",
      "Epoch 50/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2481 - accuracy: 0.9032 - val_loss: 0.2673 - val_accuracy: 0.8942\n",
      "Epoch 51/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2385 - accuracy: 0.9107 - val_loss: 0.2232 - val_accuracy: 0.9167\n",
      "Epoch 52/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2390 - accuracy: 0.9079 - val_loss: 0.2202 - val_accuracy: 0.9175\n",
      "Epoch 53/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2412 - accuracy: 0.9069 - val_loss: 0.3442 - val_accuracy: 0.8656\n",
      "Epoch 54/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2444 - accuracy: 0.9025 - val_loss: 0.2328 - val_accuracy: 0.9104\n",
      "Epoch 55/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2378 - accuracy: 0.9090 - val_loss: 0.2464 - val_accuracy: 0.9027\n",
      "Epoch 56/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2185 - accuracy: 0.9186 - val_loss: 0.2209 - val_accuracy: 0.9131\n",
      "Epoch 57/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2421 - accuracy: 0.9089 - val_loss: 0.2044 - val_accuracy: 0.9225\n",
      "Epoch 58/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2271 - accuracy: 0.9131 - val_loss: 0.2130 - val_accuracy: 0.9229\n",
      "Epoch 59/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2330 - accuracy: 0.9133 - val_loss: 0.2181 - val_accuracy: 0.9154\n",
      "Epoch 60/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2281 - accuracy: 0.9122 - val_loss: 0.2817 - val_accuracy: 0.8904\n",
      "Epoch 61/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2213 - accuracy: 0.9179 - val_loss: 0.2123 - val_accuracy: 0.9171\n",
      "Epoch 62/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2122 - accuracy: 0.9161 - val_loss: 0.2514 - val_accuracy: 0.9004\n",
      "Epoch 63/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2081 - accuracy: 0.9256 - val_loss: 0.2692 - val_accuracy: 0.8908\n",
      "Epoch 64/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2167 - accuracy: 0.9201 - val_loss: 0.2560 - val_accuracy: 0.9013\n",
      "Epoch 65/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2313 - accuracy: 0.9149 - val_loss: 0.2353 - val_accuracy: 0.9062\n",
      "Epoch 66/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2109 - accuracy: 0.9201 - val_loss: 0.2173 - val_accuracy: 0.9237\n",
      "Epoch 67/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1969 - accuracy: 0.9278 - val_loss: 0.1945 - val_accuracy: 0.9277\n",
      "Epoch 68/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1956 - accuracy: 0.9296 - val_loss: 0.2058 - val_accuracy: 0.9281\n",
      "Epoch 69/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1924 - accuracy: 0.9281 - val_loss: 0.2133 - val_accuracy: 0.9133\n",
      "Epoch 70/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1979 - accuracy: 0.9274 - val_loss: 0.2241 - val_accuracy: 0.9083\n",
      "Epoch 71/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1859 - accuracy: 0.9336 - val_loss: 0.2085 - val_accuracy: 0.9221\n",
      "Epoch 72/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1870 - accuracy: 0.9310 - val_loss: 0.2006 - val_accuracy: 0.9248\n",
      "Epoch 73/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1878 - accuracy: 0.9301 - val_loss: 0.2056 - val_accuracy: 0.9292\n",
      "Epoch 74/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1862 - accuracy: 0.9339 - val_loss: 0.2112 - val_accuracy: 0.9150\n",
      "Epoch 75/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1875 - accuracy: 0.9325 - val_loss: 0.1866 - val_accuracy: 0.9300\n",
      "Epoch 76/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1857 - accuracy: 0.9336 - val_loss: 0.1953 - val_accuracy: 0.9262\n",
      "Epoch 77/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1814 - accuracy: 0.9349 - val_loss: 0.1793 - val_accuracy: 0.9354\n",
      "Epoch 78/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1712 - accuracy: 0.9396 - val_loss: 0.1814 - val_accuracy: 0.9333\n",
      "Epoch 79/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1796 - accuracy: 0.9343 - val_loss: 0.1979 - val_accuracy: 0.9204\n",
      "Epoch 80/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1878 - accuracy: 0.9307 - val_loss: 0.2192 - val_accuracy: 0.9154\n",
      "Epoch 81/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1817 - accuracy: 0.9361 - val_loss: 0.1898 - val_accuracy: 0.9300\n",
      "Epoch 82/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1753 - accuracy: 0.9354 - val_loss: 0.1783 - val_accuracy: 0.9358\n",
      "Epoch 83/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1817 - accuracy: 0.9350 - val_loss: 0.1751 - val_accuracy: 0.9329\n",
      "Epoch 84/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1734 - accuracy: 0.9349 - val_loss: 0.2295 - val_accuracy: 0.9044\n",
      "Epoch 85/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1785 - accuracy: 0.9343 - val_loss: 0.2065 - val_accuracy: 0.9290\n",
      "Epoch 86/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1907 - accuracy: 0.9312 - val_loss: 0.2536 - val_accuracy: 0.9025\n",
      "Epoch 87/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1887 - accuracy: 0.9319 - val_loss: 0.2004 - val_accuracy: 0.9229\n",
      "Epoch 88/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1736 - accuracy: 0.9383 - val_loss: 0.2386 - val_accuracy: 0.9058\n",
      "Epoch 89/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1727 - accuracy: 0.9356 - val_loss: 0.2196 - val_accuracy: 0.9208\n",
      "Epoch 90/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1702 - accuracy: 0.9382 - val_loss: 0.1753 - val_accuracy: 0.9315\n",
      "Epoch 91/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1659 - accuracy: 0.9385 - val_loss: 0.1751 - val_accuracy: 0.9365\n",
      "Epoch 92/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1579 - accuracy: 0.9428 - val_loss: 0.1676 - val_accuracy: 0.9396\n",
      "Epoch 93/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1526 - accuracy: 0.9457 - val_loss: 0.1789 - val_accuracy: 0.9290\n",
      "Epoch 94/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1574 - accuracy: 0.9413 - val_loss: 0.2043 - val_accuracy: 0.9231\n",
      "Epoch 95/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1581 - accuracy: 0.9404 - val_loss: 0.1936 - val_accuracy: 0.9315\n",
      "Epoch 96/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1617 - accuracy: 0.9374 - val_loss: 0.2154 - val_accuracy: 0.9208\n",
      "Epoch 97/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1528 - accuracy: 0.9453 - val_loss: 0.1618 - val_accuracy: 0.9404\n",
      "Epoch 98/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1480 - accuracy: 0.9467 - val_loss: 0.1719 - val_accuracy: 0.9360\n",
      "Epoch 99/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1496 - accuracy: 0.9488 - val_loss: 0.1660 - val_accuracy: 0.9352\n",
      "Epoch 100/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1456 - accuracy: 0.9496 - val_loss: 0.1654 - val_accuracy: 0.9369\n",
      "Epoch 101/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1470 - accuracy: 0.9478 - val_loss: 0.1683 - val_accuracy: 0.9394\n",
      "Epoch 102/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1528 - accuracy: 0.9440 - val_loss: 0.1866 - val_accuracy: 0.9319\n",
      "Epoch 103/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1464 - accuracy: 0.9478 - val_loss: 0.1758 - val_accuracy: 0.9367\n",
      "Epoch 104/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1444 - accuracy: 0.9481 - val_loss: 0.1499 - val_accuracy: 0.9444\n",
      "Epoch 105/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1379 - accuracy: 0.9519 - val_loss: 0.1551 - val_accuracy: 0.9450\n",
      "Epoch 106/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1373 - accuracy: 0.9517 - val_loss: 0.1667 - val_accuracy: 0.9365\n",
      "Epoch 107/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1366 - accuracy: 0.9500 - val_loss: 0.1613 - val_accuracy: 0.9388\n",
      "Epoch 108/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1342 - accuracy: 0.9513 - val_loss: 0.1732 - val_accuracy: 0.9331\n",
      "Epoch 109/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1326 - accuracy: 0.9544 - val_loss: 0.1523 - val_accuracy: 0.9452\n",
      "Epoch 110/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1289 - accuracy: 0.9543 - val_loss: 0.1552 - val_accuracy: 0.9454\n",
      "Epoch 111/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1308 - accuracy: 0.9533 - val_loss: 0.1681 - val_accuracy: 0.9375\n",
      "Epoch 112/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1352 - accuracy: 0.9486 - val_loss: 0.1816 - val_accuracy: 0.9333\n",
      "Epoch 113/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1337 - accuracy: 0.9525 - val_loss: 0.1848 - val_accuracy: 0.9335\n",
      "Epoch 114/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1317 - accuracy: 0.9538 - val_loss: 0.1544 - val_accuracy: 0.9408\n",
      "Epoch 115/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1272 - accuracy: 0.9544 - val_loss: 0.1668 - val_accuracy: 0.9388\n",
      "Epoch 116/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1272 - accuracy: 0.9556 - val_loss: 0.1795 - val_accuracy: 0.9373\n",
      "Epoch 117/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1258 - accuracy: 0.9574 - val_loss: 0.1550 - val_accuracy: 0.9446\n",
      "Epoch 118/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1211 - accuracy: 0.9579 - val_loss: 0.1584 - val_accuracy: 0.9427\n",
      "Epoch 119/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1274 - accuracy: 0.9567 - val_loss: 0.1587 - val_accuracy: 0.9452\n",
      "Epoch 120/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1213 - accuracy: 0.9567 - val_loss: 0.1459 - val_accuracy: 0.9448\n",
      "Epoch 121/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1238 - accuracy: 0.9563 - val_loss: 0.1538 - val_accuracy: 0.9423\n",
      "Epoch 122/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1153 - accuracy: 0.9604 - val_loss: 0.1419 - val_accuracy: 0.9473\n",
      "Epoch 123/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1171 - accuracy: 0.9600 - val_loss: 0.1595 - val_accuracy: 0.9419\n",
      "Epoch 124/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1153 - accuracy: 0.9618 - val_loss: 0.1420 - val_accuracy: 0.9479\n",
      "Epoch 125/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1176 - accuracy: 0.9589 - val_loss: 0.1386 - val_accuracy: 0.9500\n",
      "Epoch 126/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1119 - accuracy: 0.9614 - val_loss: 0.1466 - val_accuracy: 0.9460\n",
      "Epoch 127/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1168 - accuracy: 0.9599 - val_loss: 0.1722 - val_accuracy: 0.9404\n",
      "Epoch 128/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1112 - accuracy: 0.9639 - val_loss: 0.1671 - val_accuracy: 0.9396\n",
      "Epoch 129/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1188 - accuracy: 0.9599 - val_loss: 0.1523 - val_accuracy: 0.9429\n",
      "Epoch 130/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1145 - accuracy: 0.9596 - val_loss: 0.1846 - val_accuracy: 0.9306\n",
      "Epoch 131/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1216 - accuracy: 0.9565 - val_loss: 0.1445 - val_accuracy: 0.9463\n",
      "Epoch 132/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1133 - accuracy: 0.9618 - val_loss: 0.1457 - val_accuracy: 0.9460\n",
      "Epoch 133/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1183 - accuracy: 0.9590 - val_loss: 0.1626 - val_accuracy: 0.9415\n",
      "Epoch 134/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1191 - accuracy: 0.9567 - val_loss: 0.1427 - val_accuracy: 0.9498\n",
      "Epoch 135/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1133 - accuracy: 0.9629 - val_loss: 0.1626 - val_accuracy: 0.9419\n",
      "Epoch 136/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1123 - accuracy: 0.9607 - val_loss: 0.1479 - val_accuracy: 0.9471\n",
      "Epoch 137/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1115 - accuracy: 0.9608 - val_loss: 0.1905 - val_accuracy: 0.9365\n",
      "Epoch 138/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1146 - accuracy: 0.9611 - val_loss: 0.1743 - val_accuracy: 0.9419\n",
      "Epoch 139/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1172 - accuracy: 0.9563 - val_loss: 0.1657 - val_accuracy: 0.9419\n",
      "Epoch 140/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1131 - accuracy: 0.9636 - val_loss: 0.1388 - val_accuracy: 0.9500\n",
      "Epoch 141/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1132 - accuracy: 0.9592 - val_loss: 0.1441 - val_accuracy: 0.9465\n",
      "Epoch 142/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1138 - accuracy: 0.9593 - val_loss: 0.1449 - val_accuracy: 0.9479\n",
      "Epoch 143/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1122 - accuracy: 0.9607 - val_loss: 0.1475 - val_accuracy: 0.9471\n",
      "Epoch 144/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1088 - accuracy: 0.9622 - val_loss: 0.1889 - val_accuracy: 0.9304\n",
      "Epoch 145/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1110 - accuracy: 0.9622 - val_loss: 0.1428 - val_accuracy: 0.9494\n",
      "Epoch 146/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1104 - accuracy: 0.9626 - val_loss: 0.1366 - val_accuracy: 0.9502\n",
      "Epoch 147/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1121 - accuracy: 0.9618 - val_loss: 0.1443 - val_accuracy: 0.9515\n",
      "Epoch 148/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9640 - val_loss: 0.1557 - val_accuracy: 0.9456\n",
      "Epoch 149/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1065 - accuracy: 0.9642 - val_loss: 0.1412 - val_accuracy: 0.9504\n",
      "Epoch 150/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9654 - val_loss: 0.1307 - val_accuracy: 0.9535\n",
      "Epoch 151/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1102 - accuracy: 0.9622 - val_loss: 0.1616 - val_accuracy: 0.9419\n",
      "Epoch 152/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1037 - accuracy: 0.9632 - val_loss: 0.1720 - val_accuracy: 0.9406\n",
      "Epoch 153/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1062 - accuracy: 0.9638 - val_loss: 0.1424 - val_accuracy: 0.9490\n",
      "Epoch 154/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1032 - accuracy: 0.9656 - val_loss: 0.1622 - val_accuracy: 0.9425\n",
      "Epoch 155/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9654 - val_loss: 0.1480 - val_accuracy: 0.9504\n",
      "Epoch 156/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1082 - accuracy: 0.9632 - val_loss: 0.1494 - val_accuracy: 0.9454\n",
      "Epoch 157/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1025 - accuracy: 0.9638 - val_loss: 0.1500 - val_accuracy: 0.9483\n",
      "Epoch 158/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0963 - accuracy: 0.9686 - val_loss: 0.1438 - val_accuracy: 0.9502\n",
      "Epoch 159/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1042 - accuracy: 0.9638 - val_loss: 0.1638 - val_accuracy: 0.9417\n",
      "Epoch 160/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1051 - accuracy: 0.9647 - val_loss: 0.1544 - val_accuracy: 0.9485\n",
      "Epoch 161/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0990 - accuracy: 0.9678 - val_loss: 0.1568 - val_accuracy: 0.9490\n",
      "Epoch 162/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9660 - val_loss: 0.1482 - val_accuracy: 0.9467\n",
      "Epoch 163/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0983 - accuracy: 0.9679 - val_loss: 0.1353 - val_accuracy: 0.9529\n",
      "Epoch 164/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1055 - accuracy: 0.9650 - val_loss: 0.1410 - val_accuracy: 0.9513\n",
      "Epoch 165/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0958 - accuracy: 0.9679 - val_loss: 0.1539 - val_accuracy: 0.9471\n",
      "Epoch 166/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0973 - accuracy: 0.9697 - val_loss: 0.1480 - val_accuracy: 0.9481\n",
      "Epoch 167/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1003 - accuracy: 0.9644 - val_loss: 0.1516 - val_accuracy: 0.9475\n",
      "Epoch 168/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1007 - accuracy: 0.9650 - val_loss: 0.1502 - val_accuracy: 0.9454\n",
      "Epoch 169/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.1050 - accuracy: 0.9633 - val_loss: 0.1337 - val_accuracy: 0.9544\n",
      "Epoch 170/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0971 - accuracy: 0.9679 - val_loss: 0.1617 - val_accuracy: 0.9465\n",
      "Epoch 171/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0937 - accuracy: 0.9679 - val_loss: 0.1385 - val_accuracy: 0.9540\n",
      "Epoch 172/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0959 - accuracy: 0.9681 - val_loss: 0.1447 - val_accuracy: 0.9477\n",
      "Epoch 173/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0969 - accuracy: 0.9671 - val_loss: 0.1471 - val_accuracy: 0.9479\n",
      "Epoch 174/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0979 - accuracy: 0.9660 - val_loss: 0.1486 - val_accuracy: 0.9475\n",
      "Epoch 175/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0950 - accuracy: 0.9686 - val_loss: 0.1514 - val_accuracy: 0.9488\n",
      "Epoch 176/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0919 - accuracy: 0.9693 - val_loss: 0.1785 - val_accuracy: 0.9356\n",
      "Epoch 177/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0978 - accuracy: 0.9681 - val_loss: 0.1442 - val_accuracy: 0.9521\n",
      "Epoch 178/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0906 - accuracy: 0.9694 - val_loss: 0.1444 - val_accuracy: 0.9508\n",
      "Epoch 179/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0922 - accuracy: 0.9685 - val_loss: 0.1514 - val_accuracy: 0.9460\n",
      "Epoch 180/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0953 - accuracy: 0.9674 - val_loss: 0.1426 - val_accuracy: 0.9488\n",
      "Epoch 181/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0925 - accuracy: 0.9704 - val_loss: 0.1345 - val_accuracy: 0.9525\n",
      "Epoch 182/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0899 - accuracy: 0.9701 - val_loss: 0.1365 - val_accuracy: 0.9535\n",
      "Epoch 183/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0902 - accuracy: 0.9700 - val_loss: 0.1423 - val_accuracy: 0.9523\n",
      "Epoch 184/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0879 - accuracy: 0.9715 - val_loss: 0.1548 - val_accuracy: 0.9485\n",
      "Epoch 185/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0957 - accuracy: 0.9686 - val_loss: 0.1538 - val_accuracy: 0.9477\n",
      "Epoch 186/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0932 - accuracy: 0.9678 - val_loss: 0.1563 - val_accuracy: 0.9427\n",
      "Epoch 187/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0905 - accuracy: 0.9707 - val_loss: 0.1466 - val_accuracy: 0.9492\n",
      "Epoch 188/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0909 - accuracy: 0.9701 - val_loss: 0.1536 - val_accuracy: 0.9488\n",
      "Epoch 189/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0912 - accuracy: 0.9686 - val_loss: 0.1459 - val_accuracy: 0.9473\n",
      "Epoch 190/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0896 - accuracy: 0.9694 - val_loss: 0.1528 - val_accuracy: 0.9483\n",
      "Epoch 191/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0983 - accuracy: 0.9669 - val_loss: 0.1642 - val_accuracy: 0.9425\n",
      "Epoch 192/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0900 - accuracy: 0.9693 - val_loss: 0.1520 - val_accuracy: 0.9494\n",
      "Epoch 193/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0925 - accuracy: 0.9672 - val_loss: 0.1731 - val_accuracy: 0.9425\n",
      "Epoch 194/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0996 - accuracy: 0.9647 - val_loss: 0.1611 - val_accuracy: 0.9450\n",
      "Epoch 195/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0915 - accuracy: 0.9699 - val_loss: 0.1553 - val_accuracy: 0.9492\n",
      "Epoch 196/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0917 - accuracy: 0.9706 - val_loss: 0.1483 - val_accuracy: 0.9490\n",
      "Epoch 197/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0875 - accuracy: 0.9711 - val_loss: 0.1404 - val_accuracy: 0.9517\n",
      "Epoch 198/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0847 - accuracy: 0.9721 - val_loss: 0.1389 - val_accuracy: 0.9519\n",
      "Epoch 199/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0909 - accuracy: 0.9697 - val_loss: 0.1612 - val_accuracy: 0.9450\n",
      "Epoch 200/200\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0874 - accuracy: 0.9714 - val_loss: 0.1414 - val_accuracy: 0.9519\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1269 - accuracy: 0.9541\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......encode_positions\n",
      ".........vars\n",
      "......global_max_pooling1d\n",
      ".........vars\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......masking\n",
      ".........vars\n",
      "......transformer_encoder\n",
      ".........encoder_layers\n",
      "............transformer_encoder_block\n",
      "..............._attention_dropout\n",
      "..................vars\n",
      "..............._attention_layer\n",
      ".................._dropout_layer\n",
      ".....................vars\n",
      ".................._key_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._output_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._query_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._softmax\n",
      ".....................vars\n",
      ".................._value_dense\n",
      ".....................vars\n",
      "........................0\n",
      "..................vars\n",
      "..............._attention_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._inner_dropout_layer\n",
      "..................vars\n",
      "..............._intermediate_activation_layer\n",
      "..................vars\n",
      "..............._intermediate_dense\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._output_dense\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._output_dropout\n",
      "..................vars\n",
      "..............._output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      ".........output_normalization\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........33\n",
      ".........34\n",
      ".........35\n",
      ".........36\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-27 10:37:58       110744\n",
      "config.json                                    2023-03-27 10:37:58         2177\n",
      "metadata.json                                  2023-03-27 10:37:58           64\n",
      "250/250 [==============================] - 206s 823ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0199 - accuracy: 0.9941\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9640\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Large training dataset with low holdout share, 7200 examples\n",
    "experiment(3, ipv6_task, 0.4, input_shape=(95, 24), output_shape=2, activation='softmax')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 4: Limited available data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 92, 24)\n",
      "y_train shape: (800, 2)\n",
      "X_val shape: (3200, 92, 24)\n",
      "y_val shape: (3200, 2)\n",
      "X_test shape: (16000, 92, 24)\n",
      "y_test shape: (16000, 2)\n",
      "X_train example: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "y_train example: [0. 1.]\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_118 (Masking)       (None, 92, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_118 (La  (None, 92, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                2086      \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,152\n",
      "Trainable params: 1,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 1128, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 14s 643ms/step - loss: 0.6973 - accuracy: 0.4812 - val_loss: 0.6956 - val_accuracy: 0.4853\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6954 - accuracy: 0.4963 - val_loss: 0.6948 - val_accuracy: 0.4903\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.6945 - accuracy: 0.5063 - val_loss: 0.6942 - val_accuracy: 0.4991\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.6937 - accuracy: 0.5113 - val_loss: 0.6936 - val_accuracy: 0.5019\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.6927 - accuracy: 0.5263 - val_loss: 0.6931 - val_accuracy: 0.5053\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.6919 - accuracy: 0.5412 - val_loss: 0.6925 - val_accuracy: 0.5147\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.6909 - accuracy: 0.5537 - val_loss: 0.6918 - val_accuracy: 0.5244\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6898 - accuracy: 0.5550 - val_loss: 0.6909 - val_accuracy: 0.5238\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6877 - accuracy: 0.5638 - val_loss: 0.6897 - val_accuracy: 0.5412\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.6852 - accuracy: 0.5788 - val_loss: 0.6878 - val_accuracy: 0.5544\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6819 - accuracy: 0.5813 - val_loss: 0.6851 - val_accuracy: 0.5606\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.6765 - accuracy: 0.5925 - val_loss: 0.6809 - val_accuracy: 0.5772\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6691 - accuracy: 0.6212 - val_loss: 0.6751 - val_accuracy: 0.5875\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.6601 - accuracy: 0.6137 - val_loss: 0.6668 - val_accuracy: 0.6056\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.6439 - accuracy: 0.6463 - val_loss: 0.6573 - val_accuracy: 0.6141\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.6272 - accuracy: 0.6625 - val_loss: 0.6470 - val_accuracy: 0.6281\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.6075 - accuracy: 0.6850 - val_loss: 0.6313 - val_accuracy: 0.6413\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.5824 - accuracy: 0.7063 - val_loss: 0.6165 - val_accuracy: 0.6612\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.5547 - accuracy: 0.7262 - val_loss: 0.5914 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.5167 - accuracy: 0.7538 - val_loss: 0.5718 - val_accuracy: 0.7056\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.4831 - accuracy: 0.7837 - val_loss: 0.5422 - val_accuracy: 0.7284\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.4528 - accuracy: 0.7887 - val_loss: 0.5253 - val_accuracy: 0.7369\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.4219 - accuracy: 0.8175 - val_loss: 0.4976 - val_accuracy: 0.7681\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.3938 - accuracy: 0.8313 - val_loss: 0.4742 - val_accuracy: 0.7822\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.3669 - accuracy: 0.8438 - val_loss: 0.4666 - val_accuracy: 0.7906\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.3433 - accuracy: 0.8612 - val_loss: 0.4410 - val_accuracy: 0.8072\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.3200 - accuracy: 0.8737 - val_loss: 0.4321 - val_accuracy: 0.8153\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.3048 - accuracy: 0.8813 - val_loss: 0.4170 - val_accuracy: 0.8241\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2940 - accuracy: 0.8850 - val_loss: 0.4129 - val_accuracy: 0.8313\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2752 - accuracy: 0.8888 - val_loss: 0.4031 - val_accuracy: 0.8369\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.2669 - accuracy: 0.8988 - val_loss: 0.4612 - val_accuracy: 0.8034\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 0.3094 - accuracy: 0.8700 - val_loss: 0.4486 - val_accuracy: 0.8103\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 8s 600ms/step - loss: 0.2809 - accuracy: 0.8813 - val_loss: 0.4101 - val_accuracy: 0.8278\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.2586 - accuracy: 0.8963 - val_loss: 0.4265 - val_accuracy: 0.8194\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.2375 - accuracy: 0.9075 - val_loss: 0.3984 - val_accuracy: 0.8372\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.2336 - accuracy: 0.9112 - val_loss: 0.4050 - val_accuracy: 0.8400\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2253 - accuracy: 0.9225 - val_loss: 0.4194 - val_accuracy: 0.8322\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.2304 - accuracy: 0.9112 - val_loss: 0.3858 - val_accuracy: 0.8550\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2188 - accuracy: 0.9175 - val_loss: 0.4038 - val_accuracy: 0.8438\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.2097 - accuracy: 0.9212 - val_loss: 0.3928 - val_accuracy: 0.8553\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2061 - accuracy: 0.9200 - val_loss: 0.3908 - val_accuracy: 0.8591\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 0.1969 - accuracy: 0.9237 - val_loss: 0.3893 - val_accuracy: 0.8587\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 0.1941 - accuracy: 0.9275 - val_loss: 0.3959 - val_accuracy: 0.8566\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1872 - accuracy: 0.9312 - val_loss: 0.4236 - val_accuracy: 0.8491\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1856 - accuracy: 0.9212 - val_loss: 0.4116 - val_accuracy: 0.8584\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.1783 - accuracy: 0.9362 - val_loss: 0.4043 - val_accuracy: 0.8622\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1777 - accuracy: 0.9388 - val_loss: 0.3940 - val_accuracy: 0.8616\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1769 - accuracy: 0.9325 - val_loss: 0.4163 - val_accuracy: 0.8587\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1718 - accuracy: 0.9438 - val_loss: 0.4036 - val_accuracy: 0.8634\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.1666 - accuracy: 0.9350 - val_loss: 0.4045 - val_accuracy: 0.8659\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1671 - accuracy: 0.9375 - val_loss: 0.4368 - val_accuracy: 0.8559\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.1536 - accuracy: 0.9475 - val_loss: 0.4790 - val_accuracy: 0.8422\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.1590 - accuracy: 0.9463 - val_loss: 0.4747 - val_accuracy: 0.8425\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.1628 - accuracy: 0.9362 - val_loss: 0.4080 - val_accuracy: 0.8681\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1569 - accuracy: 0.9400 - val_loss: 0.4106 - val_accuracy: 0.8681\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.1588 - accuracy: 0.9425 - val_loss: 0.4274 - val_accuracy: 0.8634\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.1416 - accuracy: 0.9563 - val_loss: 0.4380 - val_accuracy: 0.8587\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.1360 - accuracy: 0.9563 - val_loss: 0.4380 - val_accuracy: 0.8625\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.1339 - accuracy: 0.9588 - val_loss: 0.4528 - val_accuracy: 0.8575\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.1387 - accuracy: 0.9488 - val_loss: 0.4476 - val_accuracy: 0.8600\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1395 - accuracy: 0.9488 - val_loss: 0.4257 - val_accuracy: 0.8694\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.1374 - accuracy: 0.9525 - val_loss: 0.4410 - val_accuracy: 0.8656\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1275 - accuracy: 0.9538 - val_loss: 0.5172 - val_accuracy: 0.8425\n",
      "500/500 [==============================] - 34s 67ms/step - loss: 0.3797 - accuracy: 0.8511\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_119 (Masking)       (None, 92, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_119 (La  (None, 92, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                2086      \n",
      "                                                                 \n",
      " dense_426 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,152\n",
      "Trainable params: 1,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 1128, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 16s 653ms/step - loss: 0.6990 - accuracy: 0.5025 - val_loss: 0.6949 - val_accuracy: 0.4991\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6946 - accuracy: 0.5163 - val_loss: 0.6932 - val_accuracy: 0.5109\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 8s 600ms/step - loss: 0.6918 - accuracy: 0.5225 - val_loss: 0.6916 - val_accuracy: 0.5206\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.6888 - accuracy: 0.5625 - val_loss: 0.6895 - val_accuracy: 0.5375\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.6852 - accuracy: 0.5863 - val_loss: 0.6867 - val_accuracy: 0.5600\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 0.6799 - accuracy: 0.6212 - val_loss: 0.6819 - val_accuracy: 0.5928\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6715 - accuracy: 0.6488 - val_loss: 0.6730 - val_accuracy: 0.6181\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.6565 - accuracy: 0.6675 - val_loss: 0.6581 - val_accuracy: 0.6322\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6364 - accuracy: 0.6737 - val_loss: 0.6438 - val_accuracy: 0.6328\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.6133 - accuracy: 0.6862 - val_loss: 0.6288 - val_accuracy: 0.6581\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.5871 - accuracy: 0.7163 - val_loss: 0.6123 - val_accuracy: 0.6728\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.5616 - accuracy: 0.7387 - val_loss: 0.5960 - val_accuracy: 0.6891\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.5278 - accuracy: 0.7462 - val_loss: 0.5743 - val_accuracy: 0.7022\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.4995 - accuracy: 0.7725 - val_loss: 0.5501 - val_accuracy: 0.7281\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.4657 - accuracy: 0.7950 - val_loss: 0.5394 - val_accuracy: 0.7228\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.4395 - accuracy: 0.8087 - val_loss: 0.5028 - val_accuracy: 0.7597\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 8s 600ms/step - loss: 0.4260 - accuracy: 0.8100 - val_loss: 0.4904 - val_accuracy: 0.7716\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.3978 - accuracy: 0.8313 - val_loss: 0.4825 - val_accuracy: 0.7788\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.3788 - accuracy: 0.8413 - val_loss: 0.4709 - val_accuracy: 0.7816\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.3702 - accuracy: 0.8475 - val_loss: 0.4646 - val_accuracy: 0.7869\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.3522 - accuracy: 0.8575 - val_loss: 0.4587 - val_accuracy: 0.7937\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.3453 - accuracy: 0.8575 - val_loss: 0.4706 - val_accuracy: 0.7887\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.3341 - accuracy: 0.8687 - val_loss: 0.4692 - val_accuracy: 0.7872\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.3363 - accuracy: 0.8575 - val_loss: 0.4873 - val_accuracy: 0.7788\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.3187 - accuracy: 0.8775 - val_loss: 0.4457 - val_accuracy: 0.7997\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.3135 - accuracy: 0.8788 - val_loss: 0.4445 - val_accuracy: 0.8047\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.3014 - accuracy: 0.8800 - val_loss: 0.4405 - val_accuracy: 0.8097\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2977 - accuracy: 0.8875 - val_loss: 0.4470 - val_accuracy: 0.8059\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2908 - accuracy: 0.8938 - val_loss: 0.4349 - val_accuracy: 0.8209\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.3096 - accuracy: 0.8813 - val_loss: 0.4285 - val_accuracy: 0.8256\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2969 - accuracy: 0.8813 - val_loss: 0.4271 - val_accuracy: 0.8209\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2735 - accuracy: 0.8925 - val_loss: 0.4184 - val_accuracy: 0.8303\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.2733 - accuracy: 0.8963 - val_loss: 0.4179 - val_accuracy: 0.8291\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2705 - accuracy: 0.8963 - val_loss: 0.4202 - val_accuracy: 0.8213\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.2567 - accuracy: 0.9075 - val_loss: 0.4207 - val_accuracy: 0.8303\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2626 - accuracy: 0.9025 - val_loss: 0.4538 - val_accuracy: 0.8112\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.2608 - accuracy: 0.9025 - val_loss: 0.4142 - val_accuracy: 0.8350\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.2513 - accuracy: 0.9087 - val_loss: 0.4306 - val_accuracy: 0.8284\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2439 - accuracy: 0.9175 - val_loss: 0.4191 - val_accuracy: 0.8353\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2469 - accuracy: 0.9125 - val_loss: 0.4375 - val_accuracy: 0.8225\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2481 - accuracy: 0.9062 - val_loss: 0.4127 - val_accuracy: 0.8447\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2617 - accuracy: 0.9013 - val_loss: 0.4215 - val_accuracy: 0.8416\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2833 - accuracy: 0.8863 - val_loss: 0.4023 - val_accuracy: 0.8441\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.2378 - accuracy: 0.9087 - val_loss: 0.4089 - val_accuracy: 0.8416\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2291 - accuracy: 0.9162 - val_loss: 0.4334 - val_accuracy: 0.8228\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.2168 - accuracy: 0.9187 - val_loss: 0.4128 - val_accuracy: 0.8419\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2076 - accuracy: 0.9275 - val_loss: 0.4094 - val_accuracy: 0.8481\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2058 - accuracy: 0.9187 - val_loss: 0.4190 - val_accuracy: 0.8450\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 0.2123 - accuracy: 0.9275 - val_loss: 0.4240 - val_accuracy: 0.8444\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2066 - accuracy: 0.9262 - val_loss: 0.4086 - val_accuracy: 0.8550\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 8s 600ms/step - loss: 0.2541 - accuracy: 0.9038 - val_loss: 0.4156 - val_accuracy: 0.8441\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2273 - accuracy: 0.9187 - val_loss: 0.5002 - val_accuracy: 0.8144\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2364 - accuracy: 0.9025 - val_loss: 0.4860 - val_accuracy: 0.8128\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.2126 - accuracy: 0.9237 - val_loss: 0.4254 - val_accuracy: 0.8403\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1837 - accuracy: 0.9325 - val_loss: 0.3997 - val_accuracy: 0.8553\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1902 - accuracy: 0.9300 - val_loss: 0.4517 - val_accuracy: 0.8344\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.1806 - accuracy: 0.9350 - val_loss: 0.4346 - val_accuracy: 0.8422\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1665 - accuracy: 0.9463 - val_loss: 0.4188 - val_accuracy: 0.8525\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1679 - accuracy: 0.9388 - val_loss: 0.4348 - val_accuracy: 0.8484\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.1985 - accuracy: 0.9225 - val_loss: 0.4980 - val_accuracy: 0.8178\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.1758 - accuracy: 0.9362 - val_loss: 0.4294 - val_accuracy: 0.8506\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 7s 595ms/step - loss: 0.1602 - accuracy: 0.9475 - val_loss: 0.4230 - val_accuracy: 0.8584\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1787 - accuracy: 0.9262 - val_loss: 0.4585 - val_accuracy: 0.8372\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 7s 596ms/step - loss: 0.1573 - accuracy: 0.9438 - val_loss: 0.4621 - val_accuracy: 0.8363\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1446 - accuracy: 0.9488 - val_loss: 0.5346 - val_accuracy: 0.8153\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1563 - accuracy: 0.9438 - val_loss: 0.4330 - val_accuracy: 0.8512\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1746 - accuracy: 0.9337 - val_loss: 0.4383 - val_accuracy: 0.8612\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1552 - accuracy: 0.9413 - val_loss: 0.4265 - val_accuracy: 0.8566\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1328 - accuracy: 0.9588 - val_loss: 0.4603 - val_accuracy: 0.8428\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1239 - accuracy: 0.9613 - val_loss: 0.4785 - val_accuracy: 0.8453\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1407 - accuracy: 0.9513 - val_loss: 0.4385 - val_accuracy: 0.8662\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 8s 600ms/step - loss: 0.1427 - accuracy: 0.9413 - val_loss: 0.4545 - val_accuracy: 0.8641\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1297 - accuracy: 0.9550 - val_loss: 0.4753 - val_accuracy: 0.8472\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1084 - accuracy: 0.9712 - val_loss: 0.4560 - val_accuracy: 0.8594\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1106 - accuracy: 0.9650 - val_loss: 0.4954 - val_accuracy: 0.8469\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1038 - accuracy: 0.9675 - val_loss: 0.5035 - val_accuracy: 0.8494\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1010 - accuracy: 0.9688 - val_loss: 0.5242 - val_accuracy: 0.8428\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1016 - accuracy: 0.9688 - val_loss: 0.4936 - val_accuracy: 0.8612\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1038 - accuracy: 0.9625 - val_loss: 0.5120 - val_accuracy: 0.8509\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1118 - accuracy: 0.9625 - val_loss: 0.5294 - val_accuracy: 0.8494\n",
      "500/500 [==============================] - 34s 67ms/step - loss: 0.3857 - accuracy: 0.8592\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_120 (Masking)       (None, 92, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_120 (La  (None, 92, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 8)                2086      \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,152\n",
      "Trainable params: 1,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "C: 1128, P: 406, W: 96, R: 16, O: 184, M(n): 256\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 14s 642ms/step - loss: 0.6935 - accuracy: 0.5013 - val_loss: 0.6938 - val_accuracy: 0.5084\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.6920 - accuracy: 0.5362 - val_loss: 0.6932 - val_accuracy: 0.5184\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6909 - accuracy: 0.5462 - val_loss: 0.6926 - val_accuracy: 0.5194\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6893 - accuracy: 0.5537 - val_loss: 0.6918 - val_accuracy: 0.5281\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.6873 - accuracy: 0.5713 - val_loss: 0.6907 - val_accuracy: 0.5312\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.6849 - accuracy: 0.5838 - val_loss: 0.6890 - val_accuracy: 0.5372\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.6800 - accuracy: 0.6125 - val_loss: 0.6862 - val_accuracy: 0.5594\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.6727 - accuracy: 0.6400 - val_loss: 0.6812 - val_accuracy: 0.5672\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.6615 - accuracy: 0.6513 - val_loss: 0.6735 - val_accuracy: 0.5850\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.6449 - accuracy: 0.6675 - val_loss: 0.6663 - val_accuracy: 0.5969\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.6256 - accuracy: 0.6725 - val_loss: 0.6609 - val_accuracy: 0.6062\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.6036 - accuracy: 0.7100 - val_loss: 0.6558 - val_accuracy: 0.6153\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 0.5816 - accuracy: 0.7275 - val_loss: 0.6598 - val_accuracy: 0.6350\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.5591 - accuracy: 0.7400 - val_loss: 0.6464 - val_accuracy: 0.6509\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.5357 - accuracy: 0.7575 - val_loss: 0.6331 - val_accuracy: 0.6472\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.5126 - accuracy: 0.7638 - val_loss: 0.6356 - val_accuracy: 0.6503\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.4966 - accuracy: 0.7650 - val_loss: 0.6163 - val_accuracy: 0.6700\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.4777 - accuracy: 0.7875 - val_loss: 0.6094 - val_accuracy: 0.6853\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.4561 - accuracy: 0.8062 - val_loss: 0.6062 - val_accuracy: 0.6866\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.4300 - accuracy: 0.8288 - val_loss: 0.5996 - val_accuracy: 0.7016\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.4202 - accuracy: 0.8163 - val_loss: 0.5892 - val_accuracy: 0.7166\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.4017 - accuracy: 0.8350 - val_loss: 0.5850 - val_accuracy: 0.7256\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.3869 - accuracy: 0.8413 - val_loss: 0.5692 - val_accuracy: 0.7306\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 8s 600ms/step - loss: 0.3891 - accuracy: 0.8363 - val_loss: 0.5762 - val_accuracy: 0.7400\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.3700 - accuracy: 0.8462 - val_loss: 0.5534 - val_accuracy: 0.7484\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.3524 - accuracy: 0.8650 - val_loss: 0.5547 - val_accuracy: 0.7475\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.3442 - accuracy: 0.8687 - val_loss: 0.5412 - val_accuracy: 0.7516\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.3328 - accuracy: 0.8763 - val_loss: 0.5395 - val_accuracy: 0.7550\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.3199 - accuracy: 0.8788 - val_loss: 0.5363 - val_accuracy: 0.7650\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.3150 - accuracy: 0.8850 - val_loss: 0.5349 - val_accuracy: 0.7772\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.3072 - accuracy: 0.8763 - val_loss: 0.5222 - val_accuracy: 0.7791\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2921 - accuracy: 0.8900 - val_loss: 0.5214 - val_accuracy: 0.7825\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.2829 - accuracy: 0.8938 - val_loss: 0.5118 - val_accuracy: 0.7906\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.2790 - accuracy: 0.9038 - val_loss: 0.5118 - val_accuracy: 0.7953\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2681 - accuracy: 0.9100 - val_loss: 0.5099 - val_accuracy: 0.7884\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.2620 - accuracy: 0.9087 - val_loss: 0.5186 - val_accuracy: 0.8041\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2523 - accuracy: 0.9112 - val_loss: 0.5134 - val_accuracy: 0.7872\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.2453 - accuracy: 0.9100 - val_loss: 0.5057 - val_accuracy: 0.7987\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2423 - accuracy: 0.9125 - val_loss: 0.5015 - val_accuracy: 0.7975\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.2305 - accuracy: 0.9162 - val_loss: 0.5078 - val_accuracy: 0.8019\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2275 - accuracy: 0.9237 - val_loss: 0.5195 - val_accuracy: 0.8031\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.2204 - accuracy: 0.9225 - val_loss: 0.5060 - val_accuracy: 0.8078\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2179 - accuracy: 0.9262 - val_loss: 0.5094 - val_accuracy: 0.8128\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2230 - accuracy: 0.9237 - val_loss: 0.5323 - val_accuracy: 0.8228\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.2113 - accuracy: 0.9250 - val_loss: 0.5000 - val_accuracy: 0.8281\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.2020 - accuracy: 0.9275 - val_loss: 0.5036 - val_accuracy: 0.8166\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.2000 - accuracy: 0.9262 - val_loss: 0.5185 - val_accuracy: 0.7997\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.2196 - accuracy: 0.9150 - val_loss: 0.5173 - val_accuracy: 0.7981\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.1899 - accuracy: 0.9300 - val_loss: 0.5024 - val_accuracy: 0.8094\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1875 - accuracy: 0.9388 - val_loss: 0.5288 - val_accuracy: 0.8050\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1808 - accuracy: 0.9300 - val_loss: 0.5179 - val_accuracy: 0.8138\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 7s 597ms/step - loss: 0.1714 - accuracy: 0.9450 - val_loss: 0.5383 - val_accuracy: 0.8209\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1644 - accuracy: 0.9413 - val_loss: 0.5442 - val_accuracy: 0.8238\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1614 - accuracy: 0.9450 - val_loss: 0.5607 - val_accuracy: 0.8225\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 0.1603 - accuracy: 0.9400 - val_loss: 0.5540 - val_accuracy: 0.8313\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1616 - accuracy: 0.9425 - val_loss: 0.5673 - val_accuracy: 0.8344\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1543 - accuracy: 0.9438 - val_loss: 0.5667 - val_accuracy: 0.8134\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1471 - accuracy: 0.9463 - val_loss: 0.5949 - val_accuracy: 0.8366\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1376 - accuracy: 0.9538 - val_loss: 0.6215 - val_accuracy: 0.8363\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1378 - accuracy: 0.9488 - val_loss: 0.6110 - val_accuracy: 0.8269\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1348 - accuracy: 0.9463 - val_loss: 0.6310 - val_accuracy: 0.8316\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1237 - accuracy: 0.9575 - val_loss: 0.6489 - val_accuracy: 0.8313\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.1183 - accuracy: 0.9575 - val_loss: 0.6757 - val_accuracy: 0.8338\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1206 - accuracy: 0.9613 - val_loss: 0.6659 - val_accuracy: 0.8359\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.1264 - accuracy: 0.9525 - val_loss: 0.6389 - val_accuracy: 0.8388\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1303 - accuracy: 0.9550 - val_loss: 0.5741 - val_accuracy: 0.8431\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 0.1165 - accuracy: 0.9538 - val_loss: 0.6155 - val_accuracy: 0.8462\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 7s 599ms/step - loss: 0.1123 - accuracy: 0.9600 - val_loss: 0.6459 - val_accuracy: 0.8259\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 7s 598ms/step - loss: 0.1059 - accuracy: 0.9663 - val_loss: 0.6670 - val_accuracy: 0.8378\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 7s 600ms/step - loss: 0.1030 - accuracy: 0.9538 - val_loss: 0.7083 - val_accuracy: 0.8431\n",
      "500/500 [==============================] - 34s 67ms/step - loss: 0.5037 - accuracy: 0.8216\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......masking\n",
      ".........vars\n",
      "......rnn\n",
      ".........cell\n",
      "............controller\n",
      "...............cells\n",
      "..................lstm_cell\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "........................2\n",
      "...............vars\n",
      "............output_layer\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............parameters_layer\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "............read_layers\n",
      "...............dense\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_1\n",
      "..................vars\n",
      ".....................0\n",
      "............vars\n",
      "...............0\n",
      "............w_layers\n",
      "...............dense\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_1\n",
      "..................vars\n",
      ".....................0\n",
      "...............dense_2\n",
      "..................vars\n",
      ".....................0\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-27 11:18:55        82448\n",
      "config.json                                    2023-03-27 11:18:55         2129\n",
      "metadata.json                                  2023-03-27 11:18:55           64\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_121 (Masking)       (None, 92, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_121 (La  (None, 92, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 13)                1976      \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,052\n",
      "Trainable params: 2,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 60ms/step - loss: 0.6973 - accuracy: 0.5088 - val_loss: 0.6958 - val_accuracy: 0.5022\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 0.6943 - accuracy: 0.5225 - val_loss: 0.6953 - val_accuracy: 0.5047\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.6921 - accuracy: 0.5300 - val_loss: 0.6950 - val_accuracy: 0.5034\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.6901 - accuracy: 0.5450 - val_loss: 0.6949 - val_accuracy: 0.5063\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6884 - accuracy: 0.5537 - val_loss: 0.6947 - val_accuracy: 0.5069\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6864 - accuracy: 0.5462 - val_loss: 0.6946 - val_accuracy: 0.5091\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6847 - accuracy: 0.5525 - val_loss: 0.6944 - val_accuracy: 0.5081\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6824 - accuracy: 0.5575 - val_loss: 0.6943 - val_accuracy: 0.5097\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6805 - accuracy: 0.5725 - val_loss: 0.6942 - val_accuracy: 0.5156\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6779 - accuracy: 0.5825 - val_loss: 0.6939 - val_accuracy: 0.5188\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6753 - accuracy: 0.5913 - val_loss: 0.6936 - val_accuracy: 0.5256\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6716 - accuracy: 0.6037 - val_loss: 0.6931 - val_accuracy: 0.5284\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6671 - accuracy: 0.6087 - val_loss: 0.6920 - val_accuracy: 0.5378\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6621 - accuracy: 0.6175 - val_loss: 0.6900 - val_accuracy: 0.5447\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6546 - accuracy: 0.6275 - val_loss: 0.6852 - val_accuracy: 0.5591\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6416 - accuracy: 0.6438 - val_loss: 0.6751 - val_accuracy: 0.5825\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6234 - accuracy: 0.6725 - val_loss: 0.6610 - val_accuracy: 0.6125\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6042 - accuracy: 0.7075 - val_loss: 0.6480 - val_accuracy: 0.6366\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5824 - accuracy: 0.7113 - val_loss: 0.6409 - val_accuracy: 0.6450\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5603 - accuracy: 0.7325 - val_loss: 0.6213 - val_accuracy: 0.6678\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5294 - accuracy: 0.7638 - val_loss: 0.6099 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5197 - accuracy: 0.7538 - val_loss: 0.5892 - val_accuracy: 0.7031\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4697 - accuracy: 0.8062 - val_loss: 0.5869 - val_accuracy: 0.7003\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4616 - accuracy: 0.7987 - val_loss: 0.5608 - val_accuracy: 0.7337\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4266 - accuracy: 0.8388 - val_loss: 0.5539 - val_accuracy: 0.7381\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3975 - accuracy: 0.8637 - val_loss: 0.5505 - val_accuracy: 0.7387\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3877 - accuracy: 0.8587 - val_loss: 0.5680 - val_accuracy: 0.7509\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3942 - accuracy: 0.8525 - val_loss: 0.5550 - val_accuracy: 0.7359\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3628 - accuracy: 0.8637 - val_loss: 0.5425 - val_accuracy: 0.7487\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3439 - accuracy: 0.8788 - val_loss: 0.5277 - val_accuracy: 0.7731\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3400 - accuracy: 0.8850 - val_loss: 0.5332 - val_accuracy: 0.7650\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3258 - accuracy: 0.8850 - val_loss: 0.5730 - val_accuracy: 0.7366\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3456 - accuracy: 0.8612 - val_loss: 0.5278 - val_accuracy: 0.7809\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3315 - accuracy: 0.8813 - val_loss: 0.5136 - val_accuracy: 0.7828\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3151 - accuracy: 0.8863 - val_loss: 0.5502 - val_accuracy: 0.7559\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3019 - accuracy: 0.8963 - val_loss: 0.5451 - val_accuracy: 0.7556\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2884 - accuracy: 0.9025 - val_loss: 0.5234 - val_accuracy: 0.7784\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2870 - accuracy: 0.9062 - val_loss: 0.5107 - val_accuracy: 0.7931\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2622 - accuracy: 0.9200 - val_loss: 0.5192 - val_accuracy: 0.7837\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2599 - accuracy: 0.9175 - val_loss: 0.5028 - val_accuracy: 0.7981\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2491 - accuracy: 0.9250 - val_loss: 0.5389 - val_accuracy: 0.7781\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2398 - accuracy: 0.9275 - val_loss: 0.5455 - val_accuracy: 0.7766\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2367 - accuracy: 0.9237 - val_loss: 0.5224 - val_accuracy: 0.7891\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2239 - accuracy: 0.9362 - val_loss: 0.5264 - val_accuracy: 0.7922\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2318 - accuracy: 0.9312 - val_loss: 0.5583 - val_accuracy: 0.7722\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2363 - accuracy: 0.9300 - val_loss: 0.5031 - val_accuracy: 0.8075\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2179 - accuracy: 0.9325 - val_loss: 0.5316 - val_accuracy: 0.7844\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2074 - accuracy: 0.9438 - val_loss: 0.5034 - val_accuracy: 0.8087\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2003 - accuracy: 0.9463 - val_loss: 0.5016 - val_accuracy: 0.8169\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1927 - accuracy: 0.9488 - val_loss: 0.5323 - val_accuracy: 0.7937\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.2076 - accuracy: 0.9375 - val_loss: 0.5238 - val_accuracy: 0.8016\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1948 - accuracy: 0.9450 - val_loss: 0.5164 - val_accuracy: 0.8094\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.2040 - accuracy: 0.9388 - val_loss: 0.5051 - val_accuracy: 0.8134\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1793 - accuracy: 0.9550 - val_loss: 0.5020 - val_accuracy: 0.8181\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1856 - accuracy: 0.9513 - val_loss: 0.5088 - val_accuracy: 0.8141\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1711 - accuracy: 0.9588 - val_loss: 0.5386 - val_accuracy: 0.7978\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1706 - accuracy: 0.9575 - val_loss: 0.5238 - val_accuracy: 0.8053\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1593 - accuracy: 0.9625 - val_loss: 0.5444 - val_accuracy: 0.7994\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1613 - accuracy: 0.9625 - val_loss: 0.5258 - val_accuracy: 0.8144\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1692 - accuracy: 0.9513 - val_loss: 0.5279 - val_accuracy: 0.8103\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1517 - accuracy: 0.9650 - val_loss: 0.5214 - val_accuracy: 0.8159\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1489 - accuracy: 0.9663 - val_loss: 0.5275 - val_accuracy: 0.8159\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1480 - accuracy: 0.9675 - val_loss: 0.5185 - val_accuracy: 0.8213\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1613 - accuracy: 0.9588 - val_loss: 0.5739 - val_accuracy: 0.7859\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1518 - accuracy: 0.9638 - val_loss: 0.5647 - val_accuracy: 0.8009\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1431 - accuracy: 0.9663 - val_loss: 0.5750 - val_accuracy: 0.7941\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1387 - accuracy: 0.9663 - val_loss: 0.5292 - val_accuracy: 0.8206\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1412 - accuracy: 0.9700 - val_loss: 0.5961 - val_accuracy: 0.7828\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1456 - accuracy: 0.9663 - val_loss: 0.5340 - val_accuracy: 0.8209\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1427 - accuracy: 0.9588 - val_loss: 0.5863 - val_accuracy: 0.7931\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1554 - accuracy: 0.9525 - val_loss: 0.5362 - val_accuracy: 0.8188\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1546 - accuracy: 0.9600 - val_loss: 0.6270 - val_accuracy: 0.7638\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1786 - accuracy: 0.9475 - val_loss: 0.5432 - val_accuracy: 0.8103\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1636 - accuracy: 0.9588 - val_loss: 0.5597 - val_accuracy: 0.8006\n",
      "500/500 [==============================] - 3s 4ms/step - loss: 0.4946 - accuracy: 0.8129\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_122 (Masking)       (None, 92, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_122 (La  (None, 92, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 13)                1976      \n",
      "                                                                 \n",
      " dense_435 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,052\n",
      "Trainable params: 2,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 4s 201ms/step - loss: 0.7017 - accuracy: 0.5013 - val_loss: 0.6998 - val_accuracy: 0.5047\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.6980 - accuracy: 0.5063 - val_loss: 0.6987 - val_accuracy: 0.5056\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.6954 - accuracy: 0.5125 - val_loss: 0.6979 - val_accuracy: 0.5081\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.6931 - accuracy: 0.5225 - val_loss: 0.6972 - val_accuracy: 0.5091\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6911 - accuracy: 0.5350 - val_loss: 0.6967 - val_accuracy: 0.5113\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6892 - accuracy: 0.5450 - val_loss: 0.6964 - val_accuracy: 0.5109\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6873 - accuracy: 0.5437 - val_loss: 0.6961 - val_accuracy: 0.5147\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6854 - accuracy: 0.5550 - val_loss: 0.6959 - val_accuracy: 0.5144\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6838 - accuracy: 0.5663 - val_loss: 0.6958 - val_accuracy: 0.5134\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6818 - accuracy: 0.5725 - val_loss: 0.6957 - val_accuracy: 0.5113\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6799 - accuracy: 0.5775 - val_loss: 0.6956 - val_accuracy: 0.5134\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6775 - accuracy: 0.5813 - val_loss: 0.6955 - val_accuracy: 0.5178\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6751 - accuracy: 0.5838 - val_loss: 0.6954 - val_accuracy: 0.5169\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6721 - accuracy: 0.5875 - val_loss: 0.6951 - val_accuracy: 0.5219\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6690 - accuracy: 0.5938 - val_loss: 0.6946 - val_accuracy: 0.5259\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6649 - accuracy: 0.6012 - val_loss: 0.6938 - val_accuracy: 0.5316\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6600 - accuracy: 0.6212 - val_loss: 0.6925 - val_accuracy: 0.5384\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6537 - accuracy: 0.6388 - val_loss: 0.6897 - val_accuracy: 0.5491\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6456 - accuracy: 0.6450 - val_loss: 0.6852 - val_accuracy: 0.5566\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6357 - accuracy: 0.6725 - val_loss: 0.6793 - val_accuracy: 0.5731\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6237 - accuracy: 0.6662 - val_loss: 0.6712 - val_accuracy: 0.5962\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6072 - accuracy: 0.6938 - val_loss: 0.6628 - val_accuracy: 0.6091\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5853 - accuracy: 0.7250 - val_loss: 0.6499 - val_accuracy: 0.6303\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5627 - accuracy: 0.7375 - val_loss: 0.6343 - val_accuracy: 0.6544\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5355 - accuracy: 0.7675 - val_loss: 0.6227 - val_accuracy: 0.6678\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5130 - accuracy: 0.7812 - val_loss: 0.5993 - val_accuracy: 0.6947\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4842 - accuracy: 0.7875 - val_loss: 0.5812 - val_accuracy: 0.7106\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4542 - accuracy: 0.8163 - val_loss: 0.5606 - val_accuracy: 0.7284\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4501 - accuracy: 0.8100 - val_loss: 0.5633 - val_accuracy: 0.7231\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4077 - accuracy: 0.8413 - val_loss: 0.5306 - val_accuracy: 0.7531\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3799 - accuracy: 0.8662 - val_loss: 0.5353 - val_accuracy: 0.7456\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3640 - accuracy: 0.8700 - val_loss: 0.5165 - val_accuracy: 0.7634\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3488 - accuracy: 0.8750 - val_loss: 0.5248 - val_accuracy: 0.7553\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3269 - accuracy: 0.8975 - val_loss: 0.5230 - val_accuracy: 0.7603\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3277 - accuracy: 0.8800 - val_loss: 0.5193 - val_accuracy: 0.7725\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3219 - accuracy: 0.8850 - val_loss: 0.5102 - val_accuracy: 0.7750\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2935 - accuracy: 0.9038 - val_loss: 0.5193 - val_accuracy: 0.7759\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3255 - accuracy: 0.8675 - val_loss: 0.5137 - val_accuracy: 0.7797\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2866 - accuracy: 0.9000 - val_loss: 0.5380 - val_accuracy: 0.7653\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2886 - accuracy: 0.9038 - val_loss: 0.5033 - val_accuracy: 0.7828\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2761 - accuracy: 0.9087 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2776 - accuracy: 0.9050 - val_loss: 0.5115 - val_accuracy: 0.7791\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2571 - accuracy: 0.9187 - val_loss: 0.5131 - val_accuracy: 0.7812\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2489 - accuracy: 0.9200 - val_loss: 0.5351 - val_accuracy: 0.7731\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2479 - accuracy: 0.9162 - val_loss: 0.4975 - val_accuracy: 0.7909\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2322 - accuracy: 0.9275 - val_loss: 0.5019 - val_accuracy: 0.7934\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2260 - accuracy: 0.9287 - val_loss: 0.5015 - val_accuracy: 0.7969\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2237 - accuracy: 0.9300 - val_loss: 0.5304 - val_accuracy: 0.7850\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2172 - accuracy: 0.9362 - val_loss: 0.5020 - val_accuracy: 0.7984\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2098 - accuracy: 0.9388 - val_loss: 0.5040 - val_accuracy: 0.7997\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2035 - accuracy: 0.9450 - val_loss: 0.5068 - val_accuracy: 0.8022\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2051 - accuracy: 0.9388 - val_loss: 0.5277 - val_accuracy: 0.7919\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1989 - accuracy: 0.9413 - val_loss: 0.5108 - val_accuracy: 0.8031\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1904 - accuracy: 0.9450 - val_loss: 0.5268 - val_accuracy: 0.7956\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1867 - accuracy: 0.9488 - val_loss: 0.5593 - val_accuracy: 0.7825\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1831 - accuracy: 0.9463 - val_loss: 0.5219 - val_accuracy: 0.8022\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1819 - accuracy: 0.9500 - val_loss: 0.5186 - val_accuracy: 0.8009\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2452 - accuracy: 0.9100 - val_loss: 0.5484 - val_accuracy: 0.7906\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1973 - accuracy: 0.9388 - val_loss: 0.5361 - val_accuracy: 0.7937\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1842 - accuracy: 0.9488 - val_loss: 0.5284 - val_accuracy: 0.8009\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1739 - accuracy: 0.9500 - val_loss: 0.5237 - val_accuracy: 0.8022\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1736 - accuracy: 0.9513 - val_loss: 0.5560 - val_accuracy: 0.7931\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1657 - accuracy: 0.9550 - val_loss: 0.5263 - val_accuracy: 0.8047\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1603 - accuracy: 0.9575 - val_loss: 0.5481 - val_accuracy: 0.7997\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1612 - accuracy: 0.9563 - val_loss: 0.5794 - val_accuracy: 0.7916\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1591 - accuracy: 0.9538 - val_loss: 0.5439 - val_accuracy: 0.8044\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1558 - accuracy: 0.9588 - val_loss: 0.5745 - val_accuracy: 0.7916\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1521 - accuracy: 0.9625 - val_loss: 0.5558 - val_accuracy: 0.8050\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1534 - accuracy: 0.9563 - val_loss: 0.5310 - val_accuracy: 0.8081\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1481 - accuracy: 0.9625 - val_loss: 0.5400 - val_accuracy: 0.8062\n",
      "500/500 [==============================] - 3s 4ms/step - loss: 0.4990 - accuracy: 0.7865\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_123 (Masking)       (None, 92, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_123 (La  (None, 92, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 13)                1976      \n",
      "                                                                 \n",
      " dense_436 (Dense)           (None, 2)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,052\n",
      "Trainable params: 2,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 66ms/step - loss: 0.7059 - accuracy: 0.4888 - val_loss: 0.7029 - val_accuracy: 0.5131\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 0.7008 - accuracy: 0.4938 - val_loss: 0.7006 - val_accuracy: 0.5172\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.6973 - accuracy: 0.5000 - val_loss: 0.6989 - val_accuracy: 0.5134\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.6946 - accuracy: 0.5063 - val_loss: 0.6978 - val_accuracy: 0.5134\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6922 - accuracy: 0.5188 - val_loss: 0.6970 - val_accuracy: 0.5116\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.6903 - accuracy: 0.5288 - val_loss: 0.6965 - val_accuracy: 0.5113\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6884 - accuracy: 0.5400 - val_loss: 0.6962 - val_accuracy: 0.5059\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6867 - accuracy: 0.5462 - val_loss: 0.6960 - val_accuracy: 0.5066\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6849 - accuracy: 0.5562 - val_loss: 0.6959 - val_accuracy: 0.5084\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6832 - accuracy: 0.5625 - val_loss: 0.6958 - val_accuracy: 0.5109\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6812 - accuracy: 0.5725 - val_loss: 0.6958 - val_accuracy: 0.5100\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6793 - accuracy: 0.5875 - val_loss: 0.6957 - val_accuracy: 0.5084\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6768 - accuracy: 0.5987 - val_loss: 0.6955 - val_accuracy: 0.5138\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6739 - accuracy: 0.6062 - val_loss: 0.6951 - val_accuracy: 0.5159\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6701 - accuracy: 0.6237 - val_loss: 0.6940 - val_accuracy: 0.5203\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6651 - accuracy: 0.6263 - val_loss: 0.6919 - val_accuracy: 0.5366\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6572 - accuracy: 0.6450 - val_loss: 0.6867 - val_accuracy: 0.5537\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6446 - accuracy: 0.6562 - val_loss: 0.6773 - val_accuracy: 0.5850\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6267 - accuracy: 0.6775 - val_loss: 0.6787 - val_accuracy: 0.5853\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.6204 - accuracy: 0.6775 - val_loss: 0.6557 - val_accuracy: 0.6269\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5959 - accuracy: 0.7100 - val_loss: 0.6481 - val_accuracy: 0.6491\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5698 - accuracy: 0.7337 - val_loss: 0.6504 - val_accuracy: 0.6481\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5489 - accuracy: 0.7462 - val_loss: 0.6152 - val_accuracy: 0.6837\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5229 - accuracy: 0.7713 - val_loss: 0.6110 - val_accuracy: 0.6909\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5105 - accuracy: 0.7713 - val_loss: 0.5886 - val_accuracy: 0.7131\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4738 - accuracy: 0.8100 - val_loss: 0.5924 - val_accuracy: 0.7128\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4536 - accuracy: 0.8175 - val_loss: 0.5602 - val_accuracy: 0.7275\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4339 - accuracy: 0.8238 - val_loss: 0.5520 - val_accuracy: 0.7337\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4141 - accuracy: 0.8388 - val_loss: 0.5337 - val_accuracy: 0.7578\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.4011 - accuracy: 0.8525 - val_loss: 0.5289 - val_accuracy: 0.7584\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3830 - accuracy: 0.8575 - val_loss: 0.5235 - val_accuracy: 0.7675\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3690 - accuracy: 0.8600 - val_loss: 0.5163 - val_accuracy: 0.7663\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3666 - accuracy: 0.8587 - val_loss: 0.5042 - val_accuracy: 0.7756\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3716 - accuracy: 0.8525 - val_loss: 0.5140 - val_accuracy: 0.7725\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3440 - accuracy: 0.8700 - val_loss: 0.5140 - val_accuracy: 0.7638\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3263 - accuracy: 0.8913 - val_loss: 0.5011 - val_accuracy: 0.7856\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3693 - accuracy: 0.8500 - val_loss: 0.4988 - val_accuracy: 0.7850\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3224 - accuracy: 0.8875 - val_loss: 0.4837 - val_accuracy: 0.7941\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3061 - accuracy: 0.8925 - val_loss: 0.4775 - val_accuracy: 0.7937\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2903 - accuracy: 0.9062 - val_loss: 0.4797 - val_accuracy: 0.7897\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2925 - accuracy: 0.9025 - val_loss: 0.4877 - val_accuracy: 0.7872\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2841 - accuracy: 0.9025 - val_loss: 0.5003 - val_accuracy: 0.7903\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.2979 - accuracy: 0.8925 - val_loss: 0.4797 - val_accuracy: 0.7984\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.3372 - accuracy: 0.8637 - val_loss: 0.5451 - val_accuracy: 0.7519\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3000 - accuracy: 0.8875 - val_loss: 0.4798 - val_accuracy: 0.7956\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2702 - accuracy: 0.9038 - val_loss: 0.4685 - val_accuracy: 0.8028\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2614 - accuracy: 0.9075 - val_loss: 0.4645 - val_accuracy: 0.8056\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2569 - accuracy: 0.9100 - val_loss: 0.4690 - val_accuracy: 0.8072\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2454 - accuracy: 0.9212 - val_loss: 0.4662 - val_accuracy: 0.8081\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2384 - accuracy: 0.9237 - val_loss: 0.4793 - val_accuracy: 0.8003\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2333 - accuracy: 0.9250 - val_loss: 0.4623 - val_accuracy: 0.8103\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2320 - accuracy: 0.9237 - val_loss: 0.4643 - val_accuracy: 0.8103\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2583 - accuracy: 0.9062 - val_loss: 0.6143 - val_accuracy: 0.7328\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2814 - accuracy: 0.8925 - val_loss: 0.5064 - val_accuracy: 0.7828\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2248 - accuracy: 0.9300 - val_loss: 0.5112 - val_accuracy: 0.7812\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2286 - accuracy: 0.9212 - val_loss: 0.4706 - val_accuracy: 0.8059\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2095 - accuracy: 0.9300 - val_loss: 0.4693 - val_accuracy: 0.8091\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2260 - accuracy: 0.9137 - val_loss: 0.4724 - val_accuracy: 0.8094\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2053 - accuracy: 0.9287 - val_loss: 0.4768 - val_accuracy: 0.8072\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1977 - accuracy: 0.9350 - val_loss: 0.4813 - val_accuracy: 0.8075\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1927 - accuracy: 0.9388 - val_loss: 0.4787 - val_accuracy: 0.8056\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1844 - accuracy: 0.9400 - val_loss: 0.4922 - val_accuracy: 0.8022\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1819 - accuracy: 0.9400 - val_loss: 0.4817 - val_accuracy: 0.8119\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1853 - accuracy: 0.9362 - val_loss: 0.4962 - val_accuracy: 0.8075\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1706 - accuracy: 0.9450 - val_loss: 0.4803 - val_accuracy: 0.8144\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1702 - accuracy: 0.9463 - val_loss: 0.5124 - val_accuracy: 0.7991\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1665 - accuracy: 0.9475 - val_loss: 0.5300 - val_accuracy: 0.7941\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1730 - accuracy: 0.9463 - val_loss: 0.4724 - val_accuracy: 0.8222\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1677 - accuracy: 0.9475 - val_loss: 0.4901 - val_accuracy: 0.8153\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1651 - accuracy: 0.9513 - val_loss: 0.4700 - val_accuracy: 0.8234\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1773 - accuracy: 0.9362 - val_loss: 0.5025 - val_accuracy: 0.8084\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1813 - accuracy: 0.9375 - val_loss: 0.5057 - val_accuracy: 0.8059\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1550 - accuracy: 0.9563 - val_loss: 0.4847 - val_accuracy: 0.8181\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1678 - accuracy: 0.9463 - val_loss: 0.4906 - val_accuracy: 0.8156\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1720 - accuracy: 0.9388 - val_loss: 0.5785 - val_accuracy: 0.7781\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1728 - accuracy: 0.9375 - val_loss: 0.4897 - val_accuracy: 0.8166\n",
      "500/500 [==============================] - 3s 4ms/step - loss: 0.4643 - accuracy: 0.8125\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......masking\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-27 11:20:25        52976\n",
      "config.json                                    2023-03-27 11:20:25         2362\n",
      "metadata.json                                  2023-03-27 11:20:25           64\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_124 (Masking)       (None, 92, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_124 (La  (None, 92, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " encode_positions_32 (Encode  (None, 92, 24)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_32 (Tra  (None, 92, 24)           2864      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_32 (Gl  (None, 24)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,962\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 36ms/step - loss: 1.4277 - accuracy: 0.5013 - val_loss: 0.9812 - val_accuracy: 0.4916\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.8288 - accuracy: 0.4812 - val_loss: 0.7883 - val_accuracy: 0.4769\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7776 - accuracy: 0.4800 - val_loss: 0.7625 - val_accuracy: 0.4784\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7422 - accuracy: 0.4875 - val_loss: 0.7432 - val_accuracy: 0.4897\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7300 - accuracy: 0.5088 - val_loss: 0.7339 - val_accuracy: 0.4978\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7206 - accuracy: 0.5213 - val_loss: 0.7282 - val_accuracy: 0.5038\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7151 - accuracy: 0.5200 - val_loss: 0.7234 - val_accuracy: 0.5053\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7093 - accuracy: 0.5263 - val_loss: 0.7197 - val_accuracy: 0.5009\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7059 - accuracy: 0.5275 - val_loss: 0.7167 - val_accuracy: 0.5022\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7024 - accuracy: 0.5362 - val_loss: 0.7150 - val_accuracy: 0.5081\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6987 - accuracy: 0.5462 - val_loss: 0.7122 - val_accuracy: 0.5131\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6947 - accuracy: 0.5475 - val_loss: 0.7098 - val_accuracy: 0.5138\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6921 - accuracy: 0.5462 - val_loss: 0.7077 - val_accuracy: 0.5231\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6879 - accuracy: 0.5638 - val_loss: 0.7053 - val_accuracy: 0.5241\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6889 - accuracy: 0.5550 - val_loss: 0.7035 - val_accuracy: 0.5325\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6825 - accuracy: 0.5738 - val_loss: 0.6995 - val_accuracy: 0.5422\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6782 - accuracy: 0.5775 - val_loss: 0.6971 - val_accuracy: 0.5466\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6745 - accuracy: 0.5813 - val_loss: 0.6939 - val_accuracy: 0.5522\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6711 - accuracy: 0.5987 - val_loss: 0.6919 - val_accuracy: 0.5566\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6696 - accuracy: 0.6000 - val_loss: 0.6900 - val_accuracy: 0.5606\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6659 - accuracy: 0.5950 - val_loss: 0.6865 - val_accuracy: 0.5697\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6604 - accuracy: 0.6137 - val_loss: 0.6829 - val_accuracy: 0.5719\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6533 - accuracy: 0.6150 - val_loss: 0.6792 - val_accuracy: 0.5822\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6531 - accuracy: 0.6275 - val_loss: 0.6799 - val_accuracy: 0.5984\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6455 - accuracy: 0.6400 - val_loss: 0.6710 - val_accuracy: 0.6103\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6361 - accuracy: 0.6587 - val_loss: 0.6676 - val_accuracy: 0.6156\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6354 - accuracy: 0.6700 - val_loss: 0.6632 - val_accuracy: 0.6191\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6231 - accuracy: 0.6687 - val_loss: 0.6594 - val_accuracy: 0.6153\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6168 - accuracy: 0.6850 - val_loss: 0.6532 - val_accuracy: 0.6253\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6102 - accuracy: 0.6975 - val_loss: 0.6562 - val_accuracy: 0.6162\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5998 - accuracy: 0.7000 - val_loss: 0.6544 - val_accuracy: 0.6372\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6063 - accuracy: 0.6787 - val_loss: 0.6323 - val_accuracy: 0.6444\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5856 - accuracy: 0.6875 - val_loss: 0.6257 - val_accuracy: 0.6672\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6067 - accuracy: 0.6575 - val_loss: 0.6599 - val_accuracy: 0.6369\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5953 - accuracy: 0.7063 - val_loss: 0.6249 - val_accuracy: 0.6525\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5608 - accuracy: 0.7300 - val_loss: 0.6306 - val_accuracy: 0.6428\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5484 - accuracy: 0.7262 - val_loss: 0.5983 - val_accuracy: 0.6862\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5346 - accuracy: 0.7387 - val_loss: 0.5872 - val_accuracy: 0.6953\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5441 - accuracy: 0.7337 - val_loss: 0.5869 - val_accuracy: 0.6878\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5366 - accuracy: 0.7300 - val_loss: 0.5767 - val_accuracy: 0.7134\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5012 - accuracy: 0.7912 - val_loss: 0.5671 - val_accuracy: 0.7219\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4863 - accuracy: 0.7750 - val_loss: 0.5896 - val_accuracy: 0.6837\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5245 - accuracy: 0.7337 - val_loss: 0.5506 - val_accuracy: 0.7331\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4993 - accuracy: 0.7675 - val_loss: 0.5534 - val_accuracy: 0.7328\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4735 - accuracy: 0.7925 - val_loss: 0.5606 - val_accuracy: 0.7216\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4814 - accuracy: 0.7788 - val_loss: 0.5565 - val_accuracy: 0.7203\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4815 - accuracy: 0.7775 - val_loss: 0.5349 - val_accuracy: 0.7444\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4646 - accuracy: 0.7912 - val_loss: 0.5303 - val_accuracy: 0.7497\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4488 - accuracy: 0.7975 - val_loss: 0.5438 - val_accuracy: 0.7325\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4470 - accuracy: 0.7987 - val_loss: 0.5213 - val_accuracy: 0.7609\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4516 - accuracy: 0.7862 - val_loss: 0.5194 - val_accuracy: 0.7547\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4361 - accuracy: 0.8062 - val_loss: 0.5187 - val_accuracy: 0.7603\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4242 - accuracy: 0.8200 - val_loss: 0.5141 - val_accuracy: 0.7650\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4233 - accuracy: 0.8163 - val_loss: 0.5489 - val_accuracy: 0.7369\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4269 - accuracy: 0.8175 - val_loss: 0.5055 - val_accuracy: 0.7672\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4161 - accuracy: 0.8062 - val_loss: 0.5090 - val_accuracy: 0.7697\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3990 - accuracy: 0.8213 - val_loss: 0.5123 - val_accuracy: 0.7647\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4025 - accuracy: 0.8175 - val_loss: 0.5101 - val_accuracy: 0.7619\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4156 - accuracy: 0.7975 - val_loss: 0.5934 - val_accuracy: 0.6909\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4110 - accuracy: 0.8163 - val_loss: 0.5059 - val_accuracy: 0.7700\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3971 - accuracy: 0.8175 - val_loss: 0.5151 - val_accuracy: 0.7616\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4188 - accuracy: 0.8125 - val_loss: 0.5323 - val_accuracy: 0.7409\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4080 - accuracy: 0.8275 - val_loss: 0.4955 - val_accuracy: 0.7713\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4140 - accuracy: 0.8075 - val_loss: 0.5343 - val_accuracy: 0.7362\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3781 - accuracy: 0.8450 - val_loss: 0.5374 - val_accuracy: 0.7437\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3778 - accuracy: 0.8300 - val_loss: 0.5082 - val_accuracy: 0.7653\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3872 - accuracy: 0.8250 - val_loss: 0.4961 - val_accuracy: 0.7731\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3779 - accuracy: 0.8475 - val_loss: 0.5057 - val_accuracy: 0.7694\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3715 - accuracy: 0.8350 - val_loss: 0.5088 - val_accuracy: 0.7691\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3842 - accuracy: 0.8263 - val_loss: 0.5307 - val_accuracy: 0.7466\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3804 - accuracy: 0.8388 - val_loss: 0.4956 - val_accuracy: 0.7731\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3586 - accuracy: 0.8475 - val_loss: 0.5482 - val_accuracy: 0.7450\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3587 - accuracy: 0.8462 - val_loss: 0.5051 - val_accuracy: 0.7663\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3610 - accuracy: 0.8525 - val_loss: 0.4958 - val_accuracy: 0.7750\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3587 - accuracy: 0.8413 - val_loss: 0.5162 - val_accuracy: 0.7628\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3542 - accuracy: 0.8500 - val_loss: 0.4946 - val_accuracy: 0.7747\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3467 - accuracy: 0.8600 - val_loss: 0.5291 - val_accuracy: 0.7619\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3720 - accuracy: 0.8375 - val_loss: 0.5171 - val_accuracy: 0.7597\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3699 - accuracy: 0.8537 - val_loss: 0.4901 - val_accuracy: 0.7797\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3561 - accuracy: 0.8413 - val_loss: 0.5910 - val_accuracy: 0.7097\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3683 - accuracy: 0.8338 - val_loss: 0.4888 - val_accuracy: 0.7784\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3523 - accuracy: 0.8475 - val_loss: 0.4964 - val_accuracy: 0.7747\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3358 - accuracy: 0.8525 - val_loss: 0.5097 - val_accuracy: 0.7722\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3400 - accuracy: 0.8550 - val_loss: 0.4960 - val_accuracy: 0.7763\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3252 - accuracy: 0.8675 - val_loss: 0.5173 - val_accuracy: 0.7625\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3524 - accuracy: 0.8575 - val_loss: 0.4939 - val_accuracy: 0.7778\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3384 - accuracy: 0.8612 - val_loss: 0.5478 - val_accuracy: 0.7403\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3512 - accuracy: 0.8375 - val_loss: 0.4966 - val_accuracy: 0.7700\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3358 - accuracy: 0.8650 - val_loss: 0.4918 - val_accuracy: 0.7812\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3466 - accuracy: 0.8438 - val_loss: 0.4978 - val_accuracy: 0.7728\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3420 - accuracy: 0.8662 - val_loss: 0.4938 - val_accuracy: 0.7725\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3229 - accuracy: 0.8687 - val_loss: 0.4942 - val_accuracy: 0.7759\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3073 - accuracy: 0.8750 - val_loss: 0.5006 - val_accuracy: 0.7741\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3064 - accuracy: 0.8775 - val_loss: 0.4941 - val_accuracy: 0.7844\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3203 - accuracy: 0.8650 - val_loss: 0.5002 - val_accuracy: 0.7788\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3181 - accuracy: 0.8737 - val_loss: 0.5002 - val_accuracy: 0.7741\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3172 - accuracy: 0.8637 - val_loss: 0.5023 - val_accuracy: 0.7703\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3055 - accuracy: 0.8788 - val_loss: 0.4997 - val_accuracy: 0.7784\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3104 - accuracy: 0.8712 - val_loss: 0.5148 - val_accuracy: 0.7741\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3056 - accuracy: 0.8813 - val_loss: 0.4972 - val_accuracy: 0.7794\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2964 - accuracy: 0.8838 - val_loss: 0.5472 - val_accuracy: 0.7647\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3247 - accuracy: 0.8662 - val_loss: 0.4888 - val_accuracy: 0.7856\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3146 - accuracy: 0.8687 - val_loss: 0.5176 - val_accuracy: 0.7691\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2946 - accuracy: 0.8813 - val_loss: 0.4942 - val_accuracy: 0.7869\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2908 - accuracy: 0.8875 - val_loss: 0.5008 - val_accuracy: 0.7769\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2934 - accuracy: 0.8788 - val_loss: 0.5509 - val_accuracy: 0.7669\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.4830 - accuracy: 0.7769\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_125 (Masking)       (None, 92, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_125 (La  (None, 92, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " encode_positions_33 (Encode  (None, 92, 24)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_33 (Tra  (None, 92, 24)           2864      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_33 (Gl  (None, 24)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_438 (Dense)           (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,962\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 36ms/step - loss: 1.0721 - accuracy: 0.5075 - val_loss: 0.8793 - val_accuracy: 0.5063\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.8484 - accuracy: 0.5013 - val_loss: 0.8416 - val_accuracy: 0.5063\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.8100 - accuracy: 0.5025 - val_loss: 0.7929 - val_accuracy: 0.5156\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7753 - accuracy: 0.5150 - val_loss: 0.7689 - val_accuracy: 0.5128\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7507 - accuracy: 0.5225 - val_loss: 0.7499 - val_accuracy: 0.5219\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7313 - accuracy: 0.5325 - val_loss: 0.7371 - val_accuracy: 0.5219\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7178 - accuracy: 0.5500 - val_loss: 0.7266 - val_accuracy: 0.5244\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7065 - accuracy: 0.5575 - val_loss: 0.7206 - val_accuracy: 0.5309\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7000 - accuracy: 0.5775 - val_loss: 0.7153 - val_accuracy: 0.5337\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6941 - accuracy: 0.5750 - val_loss: 0.7115 - val_accuracy: 0.5387\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6895 - accuracy: 0.5738 - val_loss: 0.7071 - val_accuracy: 0.5434\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6876 - accuracy: 0.5863 - val_loss: 0.7048 - val_accuracy: 0.5441\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6811 - accuracy: 0.5888 - val_loss: 0.7028 - val_accuracy: 0.5481\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6756 - accuracy: 0.5975 - val_loss: 0.6990 - val_accuracy: 0.5494\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6714 - accuracy: 0.5938 - val_loss: 0.6963 - val_accuracy: 0.5541\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6668 - accuracy: 0.6025 - val_loss: 0.6933 - val_accuracy: 0.5553\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6617 - accuracy: 0.6162 - val_loss: 0.6907 - val_accuracy: 0.5572\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6595 - accuracy: 0.6225 - val_loss: 0.6879 - val_accuracy: 0.5591\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6542 - accuracy: 0.6237 - val_loss: 0.6868 - val_accuracy: 0.5634\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6542 - accuracy: 0.6250 - val_loss: 0.6841 - val_accuracy: 0.5663\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6489 - accuracy: 0.6425 - val_loss: 0.6835 - val_accuracy: 0.5700\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.6424 - accuracy: 0.6500 - val_loss: 0.6851 - val_accuracy: 0.5678\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6395 - accuracy: 0.6575 - val_loss: 0.6782 - val_accuracy: 0.5778\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6335 - accuracy: 0.6587 - val_loss: 0.6760 - val_accuracy: 0.5775\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.6292 - accuracy: 0.6700 - val_loss: 0.6772 - val_accuracy: 0.5769\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.6231 - accuracy: 0.6750 - val_loss: 0.6808 - val_accuracy: 0.5962\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6262 - accuracy: 0.6737 - val_loss: 0.6701 - val_accuracy: 0.5856\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6158 - accuracy: 0.6938 - val_loss: 0.6656 - val_accuracy: 0.5997\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6081 - accuracy: 0.6963 - val_loss: 0.6649 - val_accuracy: 0.5962\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6051 - accuracy: 0.6988 - val_loss: 0.6594 - val_accuracy: 0.6009\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.6031 - accuracy: 0.6850 - val_loss: 0.6861 - val_accuracy: 0.5853\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6176 - accuracy: 0.6662 - val_loss: 0.6548 - val_accuracy: 0.6106\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5957 - accuracy: 0.7075 - val_loss: 0.6527 - val_accuracy: 0.6313\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.5862 - accuracy: 0.7038 - val_loss: 0.6548 - val_accuracy: 0.6334\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5830 - accuracy: 0.7050 - val_loss: 0.6435 - val_accuracy: 0.6291\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5744 - accuracy: 0.7400 - val_loss: 0.6416 - val_accuracy: 0.6334\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5653 - accuracy: 0.7400 - val_loss: 0.6367 - val_accuracy: 0.6484\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5648 - accuracy: 0.7387 - val_loss: 0.6448 - val_accuracy: 0.6244\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5516 - accuracy: 0.7487 - val_loss: 0.6298 - val_accuracy: 0.6481\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5436 - accuracy: 0.7563 - val_loss: 0.6218 - val_accuracy: 0.6612\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5372 - accuracy: 0.7450 - val_loss: 0.6157 - val_accuracy: 0.6700\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5301 - accuracy: 0.7538 - val_loss: 0.6110 - val_accuracy: 0.6734\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.5325 - accuracy: 0.7663 - val_loss: 0.6141 - val_accuracy: 0.6709\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5308 - accuracy: 0.7713 - val_loss: 0.6044 - val_accuracy: 0.6822\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5192 - accuracy: 0.7788 - val_loss: 0.6002 - val_accuracy: 0.6825\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5063 - accuracy: 0.7763 - val_loss: 0.5914 - val_accuracy: 0.6950\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5028 - accuracy: 0.7738 - val_loss: 0.5918 - val_accuracy: 0.6903\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5126 - accuracy: 0.7663 - val_loss: 0.5940 - val_accuracy: 0.6909\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4945 - accuracy: 0.7862 - val_loss: 0.5835 - val_accuracy: 0.7044\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4832 - accuracy: 0.7962 - val_loss: 0.5760 - val_accuracy: 0.7081\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4720 - accuracy: 0.8062 - val_loss: 0.5770 - val_accuracy: 0.7050\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4643 - accuracy: 0.8000 - val_loss: 0.5687 - val_accuracy: 0.7144\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4583 - accuracy: 0.8125 - val_loss: 0.5930 - val_accuracy: 0.6872\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4721 - accuracy: 0.8062 - val_loss: 0.5735 - val_accuracy: 0.7025\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4516 - accuracy: 0.8100 - val_loss: 0.5564 - val_accuracy: 0.7206\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4385 - accuracy: 0.8313 - val_loss: 0.5429 - val_accuracy: 0.7347\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4358 - accuracy: 0.8238 - val_loss: 0.5616 - val_accuracy: 0.7141\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4341 - accuracy: 0.8138 - val_loss: 0.5365 - val_accuracy: 0.7362\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4281 - accuracy: 0.8163 - val_loss: 0.5344 - val_accuracy: 0.7403\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4604 - accuracy: 0.7962 - val_loss: 0.5315 - val_accuracy: 0.7397\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4208 - accuracy: 0.8238 - val_loss: 0.5391 - val_accuracy: 0.7350\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4098 - accuracy: 0.8338 - val_loss: 0.5282 - val_accuracy: 0.7475\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4085 - accuracy: 0.8313 - val_loss: 0.5336 - val_accuracy: 0.7344\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3971 - accuracy: 0.8325 - val_loss: 0.5109 - val_accuracy: 0.7516\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4033 - accuracy: 0.8450 - val_loss: 0.5155 - val_accuracy: 0.7513\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3842 - accuracy: 0.8550 - val_loss: 0.5155 - val_accuracy: 0.7472\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3743 - accuracy: 0.8637 - val_loss: 0.5093 - val_accuracy: 0.7516\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3791 - accuracy: 0.8450 - val_loss: 0.5054 - val_accuracy: 0.7522\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3750 - accuracy: 0.8500 - val_loss: 0.4932 - val_accuracy: 0.7631\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4008 - accuracy: 0.8275 - val_loss: 0.5030 - val_accuracy: 0.7581\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3751 - accuracy: 0.8637 - val_loss: 0.4963 - val_accuracy: 0.7706\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3749 - accuracy: 0.8363 - val_loss: 0.5453 - val_accuracy: 0.7309\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3780 - accuracy: 0.8487 - val_loss: 0.4895 - val_accuracy: 0.7697\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3571 - accuracy: 0.8462 - val_loss: 0.4949 - val_accuracy: 0.7675\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3483 - accuracy: 0.8625 - val_loss: 0.4782 - val_accuracy: 0.7763\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3436 - accuracy: 0.8750 - val_loss: 0.4763 - val_accuracy: 0.7756\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3411 - accuracy: 0.8687 - val_loss: 0.4731 - val_accuracy: 0.7791\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3318 - accuracy: 0.8800 - val_loss: 0.4809 - val_accuracy: 0.7719\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3316 - accuracy: 0.8788 - val_loss: 0.4831 - val_accuracy: 0.7778\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3435 - accuracy: 0.8438 - val_loss: 0.4782 - val_accuracy: 0.7731\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3273 - accuracy: 0.8763 - val_loss: 0.4709 - val_accuracy: 0.7825\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3199 - accuracy: 0.8838 - val_loss: 0.4819 - val_accuracy: 0.7794\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3415 - accuracy: 0.8562 - val_loss: 0.4663 - val_accuracy: 0.7847\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3167 - accuracy: 0.8863 - val_loss: 0.4661 - val_accuracy: 0.7897\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3092 - accuracy: 0.8838 - val_loss: 0.4622 - val_accuracy: 0.7919\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3107 - accuracy: 0.8725 - val_loss: 0.5015 - val_accuracy: 0.7597\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3342 - accuracy: 0.8562 - val_loss: 0.4553 - val_accuracy: 0.7925\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3040 - accuracy: 0.8925 - val_loss: 0.4660 - val_accuracy: 0.7931\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3142 - accuracy: 0.8788 - val_loss: 0.4653 - val_accuracy: 0.7853\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3008 - accuracy: 0.8875 - val_loss: 0.4542 - val_accuracy: 0.7962\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2965 - accuracy: 0.8888 - val_loss: 0.4472 - val_accuracy: 0.8006\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2930 - accuracy: 0.8875 - val_loss: 0.4373 - val_accuracy: 0.8044\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2957 - accuracy: 0.8838 - val_loss: 0.5455 - val_accuracy: 0.7228\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3284 - accuracy: 0.8562 - val_loss: 0.4424 - val_accuracy: 0.8003\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2958 - accuracy: 0.8925 - val_loss: 0.4535 - val_accuracy: 0.7950\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3060 - accuracy: 0.8788 - val_loss: 0.4772 - val_accuracy: 0.7822\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3025 - accuracy: 0.8925 - val_loss: 0.4383 - val_accuracy: 0.8003\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2801 - accuracy: 0.8975 - val_loss: 0.4390 - val_accuracy: 0.8094\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2826 - accuracy: 0.8938 - val_loss: 0.5035 - val_accuracy: 0.7672\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2774 - accuracy: 0.8938 - val_loss: 0.4406 - val_accuracy: 0.8041\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2907 - accuracy: 0.8863 - val_loss: 0.4648 - val_accuracy: 0.7769\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2754 - accuracy: 0.9087 - val_loss: 0.4525 - val_accuracy: 0.8003\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2688 - accuracy: 0.9038 - val_loss: 0.4424 - val_accuracy: 0.8044\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2742 - accuracy: 0.8900 - val_loss: 0.4534 - val_accuracy: 0.8003\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2660 - accuracy: 0.8963 - val_loss: 0.4359 - val_accuracy: 0.8122\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2775 - accuracy: 0.8925 - val_loss: 0.4354 - val_accuracy: 0.8125\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2548 - accuracy: 0.9087 - val_loss: 0.4297 - val_accuracy: 0.8112\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2610 - accuracy: 0.8938 - val_loss: 0.4298 - val_accuracy: 0.8141\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2519 - accuracy: 0.9162 - val_loss: 0.4288 - val_accuracy: 0.8147\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2485 - accuracy: 0.9100 - val_loss: 0.4201 - val_accuracy: 0.8188\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2403 - accuracy: 0.9137 - val_loss: 0.4204 - val_accuracy: 0.8219\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2395 - accuracy: 0.9175 - val_loss: 0.4122 - val_accuracy: 0.8244\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2522 - accuracy: 0.9000 - val_loss: 0.4293 - val_accuracy: 0.8169\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2448 - accuracy: 0.9075 - val_loss: 0.4181 - val_accuracy: 0.8247\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2317 - accuracy: 0.9225 - val_loss: 0.4161 - val_accuracy: 0.8259\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2395 - accuracy: 0.9162 - val_loss: 0.4096 - val_accuracy: 0.8278\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2433 - accuracy: 0.9062 - val_loss: 0.4320 - val_accuracy: 0.8163\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2416 - accuracy: 0.9025 - val_loss: 0.4265 - val_accuracy: 0.8159\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2718 - accuracy: 0.8913 - val_loss: 0.4430 - val_accuracy: 0.8119\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2706 - accuracy: 0.8963 - val_loss: 0.4586 - val_accuracy: 0.8034\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2413 - accuracy: 0.9175 - val_loss: 0.4481 - val_accuracy: 0.8072\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2423 - accuracy: 0.9050 - val_loss: 0.4210 - val_accuracy: 0.8209\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2285 - accuracy: 0.9250 - val_loss: 0.4252 - val_accuracy: 0.8234\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2233 - accuracy: 0.9212 - val_loss: 0.4218 - val_accuracy: 0.8197\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2190 - accuracy: 0.9275 - val_loss: 0.4246 - val_accuracy: 0.8222\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2170 - accuracy: 0.9262 - val_loss: 0.4075 - val_accuracy: 0.8328\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2100 - accuracy: 0.9287 - val_loss: 0.4065 - val_accuracy: 0.8338\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2111 - accuracy: 0.9300 - val_loss: 0.4332 - val_accuracy: 0.8087\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2209 - accuracy: 0.9287 - val_loss: 0.4210 - val_accuracy: 0.8278\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2472 - accuracy: 0.8988 - val_loss: 0.4283 - val_accuracy: 0.8191\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2399 - accuracy: 0.9162 - val_loss: 0.4077 - val_accuracy: 0.8272\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2167 - accuracy: 0.9262 - val_loss: 0.4139 - val_accuracy: 0.8300\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2157 - accuracy: 0.9212 - val_loss: 0.4128 - val_accuracy: 0.8272\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2031 - accuracy: 0.9350 - val_loss: 0.4139 - val_accuracy: 0.8331\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2062 - accuracy: 0.9388 - val_loss: 0.4021 - val_accuracy: 0.8334\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1926 - accuracy: 0.9337 - val_loss: 0.4015 - val_accuracy: 0.8353\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2015 - accuracy: 0.9287 - val_loss: 0.4161 - val_accuracy: 0.8291\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1954 - accuracy: 0.9350 - val_loss: 0.4064 - val_accuracy: 0.8372\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1861 - accuracy: 0.9438 - val_loss: 0.4113 - val_accuracy: 0.8281\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1831 - accuracy: 0.9475 - val_loss: 0.4043 - val_accuracy: 0.8347\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1937 - accuracy: 0.9350 - val_loss: 0.5199 - val_accuracy: 0.7591\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2022 - accuracy: 0.9312 - val_loss: 0.4001 - val_accuracy: 0.8406\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1878 - accuracy: 0.9388 - val_loss: 0.4022 - val_accuracy: 0.8331\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1795 - accuracy: 0.9488 - val_loss: 0.4094 - val_accuracy: 0.8378\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1915 - accuracy: 0.9413 - val_loss: 0.4136 - val_accuracy: 0.8297\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2022 - accuracy: 0.9262 - val_loss: 0.4194 - val_accuracy: 0.8234\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1772 - accuracy: 0.9525 - val_loss: 0.4193 - val_accuracy: 0.8319\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1777 - accuracy: 0.9463 - val_loss: 0.3974 - val_accuracy: 0.8409\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1670 - accuracy: 0.9600 - val_loss: 0.4013 - val_accuracy: 0.8394\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1683 - accuracy: 0.9538 - val_loss: 0.4075 - val_accuracy: 0.8403\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1738 - accuracy: 0.9450 - val_loss: 0.4568 - val_accuracy: 0.7941\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1706 - accuracy: 0.9500 - val_loss: 0.4177 - val_accuracy: 0.8372\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1824 - accuracy: 0.9400 - val_loss: 0.4112 - val_accuracy: 0.8263\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1635 - accuracy: 0.9513 - val_loss: 0.4416 - val_accuracy: 0.8059\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1673 - accuracy: 0.9525 - val_loss: 0.3981 - val_accuracy: 0.8425\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1619 - accuracy: 0.9525 - val_loss: 0.4076 - val_accuracy: 0.8406\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1788 - accuracy: 0.9413 - val_loss: 0.4070 - val_accuracy: 0.8409\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1762 - accuracy: 0.9438 - val_loss: 0.4244 - val_accuracy: 0.8275\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1618 - accuracy: 0.9600 - val_loss: 0.4012 - val_accuracy: 0.8406\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1664 - accuracy: 0.9438 - val_loss: 0.4066 - val_accuracy: 0.8400\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1540 - accuracy: 0.9575 - val_loss: 0.4036 - val_accuracy: 0.8338\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1580 - accuracy: 0.9475 - val_loss: 0.4024 - val_accuracy: 0.8363\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1459 - accuracy: 0.9600 - val_loss: 0.4008 - val_accuracy: 0.8450\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1470 - accuracy: 0.9663 - val_loss: 0.4100 - val_accuracy: 0.8288\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1550 - accuracy: 0.9638 - val_loss: 0.4055 - val_accuracy: 0.8381\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1396 - accuracy: 0.9600 - val_loss: 0.4037 - val_accuracy: 0.8375\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1348 - accuracy: 0.9650 - val_loss: 0.4187 - val_accuracy: 0.8269\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1417 - accuracy: 0.9650 - val_loss: 0.3981 - val_accuracy: 0.8472\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1378 - accuracy: 0.9600 - val_loss: 0.3965 - val_accuracy: 0.8406\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1381 - accuracy: 0.9638 - val_loss: 0.4007 - val_accuracy: 0.8466\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1428 - accuracy: 0.9613 - val_loss: 0.3956 - val_accuracy: 0.8494\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1513 - accuracy: 0.9538 - val_loss: 0.3977 - val_accuracy: 0.8453\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1652 - accuracy: 0.9425 - val_loss: 0.4510 - val_accuracy: 0.8150\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1720 - accuracy: 0.9400 - val_loss: 0.4265 - val_accuracy: 0.8269\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1555 - accuracy: 0.9550 - val_loss: 0.4069 - val_accuracy: 0.8413\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1384 - accuracy: 0.9600 - val_loss: 0.4001 - val_accuracy: 0.8459\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1251 - accuracy: 0.9675 - val_loss: 0.4125 - val_accuracy: 0.8322\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1252 - accuracy: 0.9700 - val_loss: 0.3920 - val_accuracy: 0.8484\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1275 - accuracy: 0.9663 - val_loss: 0.3916 - val_accuracy: 0.8487\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1174 - accuracy: 0.9725 - val_loss: 0.3948 - val_accuracy: 0.8472\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1213 - accuracy: 0.9675 - val_loss: 0.3934 - val_accuracy: 0.8534\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1284 - accuracy: 0.9625 - val_loss: 0.4182 - val_accuracy: 0.8272\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1322 - accuracy: 0.9575 - val_loss: 0.4032 - val_accuracy: 0.8509\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1208 - accuracy: 0.9737 - val_loss: 0.4033 - val_accuracy: 0.8434\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1167 - accuracy: 0.9675 - val_loss: 0.3965 - val_accuracy: 0.8528\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1254 - accuracy: 0.9650 - val_loss: 0.4136 - val_accuracy: 0.8275\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1163 - accuracy: 0.9700 - val_loss: 0.4077 - val_accuracy: 0.8416\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1169 - accuracy: 0.9688 - val_loss: 0.3950 - val_accuracy: 0.8509\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1100 - accuracy: 0.9775 - val_loss: 0.4047 - val_accuracy: 0.8484\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1085 - accuracy: 0.9750 - val_loss: 0.3906 - val_accuracy: 0.8537\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1094 - accuracy: 0.9725 - val_loss: 0.4084 - val_accuracy: 0.8444\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1117 - accuracy: 0.9775 - val_loss: 0.3956 - val_accuracy: 0.8537\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1255 - accuracy: 0.9575 - val_loss: 0.4215 - val_accuracy: 0.8350\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1422 - accuracy: 0.9550 - val_loss: 0.4133 - val_accuracy: 0.8378\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1284 - accuracy: 0.9625 - val_loss: 0.4291 - val_accuracy: 0.8359\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1400 - accuracy: 0.9575 - val_loss: 0.4126 - val_accuracy: 0.8481\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1168 - accuracy: 0.9737 - val_loss: 0.4230 - val_accuracy: 0.8294\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1050 - accuracy: 0.9750 - val_loss: 0.4002 - val_accuracy: 0.8512\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1095 - accuracy: 0.9688 - val_loss: 0.4062 - val_accuracy: 0.8512\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1040 - accuracy: 0.9737 - val_loss: 0.4008 - val_accuracy: 0.8503\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3896 - accuracy: 0.8524\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_126 (Masking)       (None, 92, 24)            0         \n",
      "                                                                 \n",
      " layer_normalization_126 (La  (None, 92, 24)           48        \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " encode_positions_34 (Encode  (None, 92, 24)           0         \n",
      " Positions)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_34 (Tra  (None, 92, 24)           2864      \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_34 (Gl  (None, 24)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,962\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 36ms/step - loss: 1.4871 - accuracy: 0.4725 - val_loss: 1.1281 - val_accuracy: 0.4597\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.9971 - accuracy: 0.4387 - val_loss: 0.8889 - val_accuracy: 0.4547\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.8842 - accuracy: 0.4263 - val_loss: 0.8570 - val_accuracy: 0.4647\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.8329 - accuracy: 0.4412 - val_loss: 0.8047 - val_accuracy: 0.4706\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7882 - accuracy: 0.4800 - val_loss: 0.7727 - val_accuracy: 0.4803\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7585 - accuracy: 0.5075 - val_loss: 0.7494 - val_accuracy: 0.4966\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7406 - accuracy: 0.4850 - val_loss: 0.7353 - val_accuracy: 0.5022\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7246 - accuracy: 0.5200 - val_loss: 0.7234 - val_accuracy: 0.5169\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.7110 - accuracy: 0.5263 - val_loss: 0.7148 - val_accuracy: 0.5197\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6996 - accuracy: 0.5387 - val_loss: 0.7053 - val_accuracy: 0.5434\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6918 - accuracy: 0.5675 - val_loss: 0.6990 - val_accuracy: 0.5469\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6868 - accuracy: 0.5813 - val_loss: 0.6941 - val_accuracy: 0.5494\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6761 - accuracy: 0.5950 - val_loss: 0.6893 - val_accuracy: 0.5669\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6746 - accuracy: 0.5962 - val_loss: 0.6823 - val_accuracy: 0.5816\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6654 - accuracy: 0.6050 - val_loss: 0.6787 - val_accuracy: 0.5825\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.6604 - accuracy: 0.6062 - val_loss: 0.6792 - val_accuracy: 0.5872\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6519 - accuracy: 0.6363 - val_loss: 0.6692 - val_accuracy: 0.5950\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6441 - accuracy: 0.6600 - val_loss: 0.6613 - val_accuracy: 0.6206\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6370 - accuracy: 0.6687 - val_loss: 0.6593 - val_accuracy: 0.6109\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6271 - accuracy: 0.6762 - val_loss: 0.6448 - val_accuracy: 0.6425\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6189 - accuracy: 0.6925 - val_loss: 0.6447 - val_accuracy: 0.6363\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6141 - accuracy: 0.6775 - val_loss: 0.6454 - val_accuracy: 0.6338\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.6096 - accuracy: 0.6988 - val_loss: 0.6441 - val_accuracy: 0.6322\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5976 - accuracy: 0.7138 - val_loss: 0.6219 - val_accuracy: 0.6619\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5980 - accuracy: 0.6938 - val_loss: 0.6124 - val_accuracy: 0.6794\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5892 - accuracy: 0.6925 - val_loss: 0.6070 - val_accuracy: 0.6781\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5810 - accuracy: 0.7075 - val_loss: 0.6605 - val_accuracy: 0.5859\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5812 - accuracy: 0.7175 - val_loss: 0.6003 - val_accuracy: 0.6794\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5566 - accuracy: 0.7513 - val_loss: 0.5917 - val_accuracy: 0.6919\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5447 - accuracy: 0.7613 - val_loss: 0.6033 - val_accuracy: 0.6625\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5505 - accuracy: 0.7300 - val_loss: 0.6059 - val_accuracy: 0.6625\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5476 - accuracy: 0.7250 - val_loss: 0.5783 - val_accuracy: 0.7022\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5499 - accuracy: 0.7175 - val_loss: 0.5884 - val_accuracy: 0.6844\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5390 - accuracy: 0.7437 - val_loss: 0.5730 - val_accuracy: 0.7088\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5133 - accuracy: 0.7775 - val_loss: 0.5614 - val_accuracy: 0.7184\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.5011 - accuracy: 0.7950 - val_loss: 0.5557 - val_accuracy: 0.7184\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4932 - accuracy: 0.7850 - val_loss: 0.5928 - val_accuracy: 0.6625\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4844 - accuracy: 0.7900 - val_loss: 0.5389 - val_accuracy: 0.7309\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4766 - accuracy: 0.7925 - val_loss: 0.5583 - val_accuracy: 0.7234\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4713 - accuracy: 0.8100 - val_loss: 0.5319 - val_accuracy: 0.7341\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4752 - accuracy: 0.7962 - val_loss: 0.5276 - val_accuracy: 0.7316\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4663 - accuracy: 0.7987 - val_loss: 0.5430 - val_accuracy: 0.7312\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4624 - accuracy: 0.7975 - val_loss: 0.5276 - val_accuracy: 0.7431\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4480 - accuracy: 0.8100 - val_loss: 0.5396 - val_accuracy: 0.7297\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4504 - accuracy: 0.8100 - val_loss: 0.5327 - val_accuracy: 0.7306\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4314 - accuracy: 0.8300 - val_loss: 0.5258 - val_accuracy: 0.7381\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4408 - accuracy: 0.8175 - val_loss: 0.5158 - val_accuracy: 0.7531\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4214 - accuracy: 0.8300 - val_loss: 0.5122 - val_accuracy: 0.7547\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4353 - accuracy: 0.8188 - val_loss: 0.5579 - val_accuracy: 0.7166\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4438 - accuracy: 0.8062 - val_loss: 0.5226 - val_accuracy: 0.7459\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4286 - accuracy: 0.8188 - val_loss: 0.5442 - val_accuracy: 0.7303\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4545 - accuracy: 0.8125 - val_loss: 0.5114 - val_accuracy: 0.7538\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4306 - accuracy: 0.8188 - val_loss: 0.5118 - val_accuracy: 0.7525\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4130 - accuracy: 0.8425 - val_loss: 0.5108 - val_accuracy: 0.7519\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4104 - accuracy: 0.8313 - val_loss: 0.5218 - val_accuracy: 0.7453\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4013 - accuracy: 0.8363 - val_loss: 0.5088 - val_accuracy: 0.7550\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4341 - accuracy: 0.8050 - val_loss: 0.5195 - val_accuracy: 0.7425\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4518 - accuracy: 0.8087 - val_loss: 0.5057 - val_accuracy: 0.7559\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4064 - accuracy: 0.8350 - val_loss: 0.5120 - val_accuracy: 0.7556\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4096 - accuracy: 0.8288 - val_loss: 0.5072 - val_accuracy: 0.7547\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.4030 - accuracy: 0.8438 - val_loss: 0.5336 - val_accuracy: 0.7478\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3902 - accuracy: 0.8450 - val_loss: 0.5505 - val_accuracy: 0.7284\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3941 - accuracy: 0.8325 - val_loss: 0.5066 - val_accuracy: 0.7600\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4332 - accuracy: 0.8000 - val_loss: 0.5264 - val_accuracy: 0.7316\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.4346 - accuracy: 0.8250 - val_loss: 0.5145 - val_accuracy: 0.7481\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3989 - accuracy: 0.8413 - val_loss: 0.5269 - val_accuracy: 0.7447\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3817 - accuracy: 0.8438 - val_loss: 0.5277 - val_accuracy: 0.7422\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3792 - accuracy: 0.8550 - val_loss: 0.5177 - val_accuracy: 0.7459\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3850 - accuracy: 0.8487 - val_loss: 0.5056 - val_accuracy: 0.7538\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3795 - accuracy: 0.8525 - val_loss: 0.5125 - val_accuracy: 0.7550\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3666 - accuracy: 0.8537 - val_loss: 0.5055 - val_accuracy: 0.7584\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3732 - accuracy: 0.8525 - val_loss: 0.5034 - val_accuracy: 0.7541\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3710 - accuracy: 0.8612 - val_loss: 0.5025 - val_accuracy: 0.7584\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3708 - accuracy: 0.8575 - val_loss: 0.5051 - val_accuracy: 0.7575\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3596 - accuracy: 0.8625 - val_loss: 0.5044 - val_accuracy: 0.7584\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3564 - accuracy: 0.8562 - val_loss: 0.5014 - val_accuracy: 0.7591\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3520 - accuracy: 0.8662 - val_loss: 0.5089 - val_accuracy: 0.7588\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3468 - accuracy: 0.8675 - val_loss: 0.5051 - val_accuracy: 0.7581\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3553 - accuracy: 0.8537 - val_loss: 0.5154 - val_accuracy: 0.7528\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3908 - accuracy: 0.8350 - val_loss: 0.5206 - val_accuracy: 0.7563\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.3821 - accuracy: 0.8363 - val_loss: 0.5042 - val_accuracy: 0.7616\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3552 - accuracy: 0.8662 - val_loss: 0.5014 - val_accuracy: 0.7597\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3548 - accuracy: 0.8625 - val_loss: 0.5138 - val_accuracy: 0.7569\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3485 - accuracy: 0.8612 - val_loss: 0.5126 - val_accuracy: 0.7538\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3504 - accuracy: 0.8662 - val_loss: 0.5109 - val_accuracy: 0.7584\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3462 - accuracy: 0.8612 - val_loss: 0.5082 - val_accuracy: 0.7631\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3381 - accuracy: 0.8650 - val_loss: 0.5107 - val_accuracy: 0.7628\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3354 - accuracy: 0.8675 - val_loss: 0.5054 - val_accuracy: 0.7609\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3297 - accuracy: 0.8700 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3305 - accuracy: 0.8725 - val_loss: 0.5036 - val_accuracy: 0.7669\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3398 - accuracy: 0.8487 - val_loss: 0.5291 - val_accuracy: 0.7525\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3352 - accuracy: 0.8625 - val_loss: 0.5147 - val_accuracy: 0.7581\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3280 - accuracy: 0.8700 - val_loss: 0.5084 - val_accuracy: 0.7663\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3285 - accuracy: 0.8675 - val_loss: 0.5520 - val_accuracy: 0.7456\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3318 - accuracy: 0.8788 - val_loss: 0.5083 - val_accuracy: 0.7659\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3535 - accuracy: 0.8487 - val_loss: 0.5225 - val_accuracy: 0.7538\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3410 - accuracy: 0.8587 - val_loss: 0.5452 - val_accuracy: 0.7494\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3725 - accuracy: 0.8288 - val_loss: 0.5461 - val_accuracy: 0.7397\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3341 - accuracy: 0.8650 - val_loss: 0.5145 - val_accuracy: 0.7631\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3166 - accuracy: 0.8775 - val_loss: 0.5146 - val_accuracy: 0.7659\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3060 - accuracy: 0.8825 - val_loss: 0.5060 - val_accuracy: 0.7650\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3180 - accuracy: 0.8850 - val_loss: 0.5060 - val_accuracy: 0.7650\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3168 - accuracy: 0.8662 - val_loss: 0.5247 - val_accuracy: 0.7597\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3302 - accuracy: 0.8662 - val_loss: 0.5190 - val_accuracy: 0.7569\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3275 - accuracy: 0.8687 - val_loss: 0.5386 - val_accuracy: 0.7594\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3166 - accuracy: 0.8737 - val_loss: 0.5146 - val_accuracy: 0.7650\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3027 - accuracy: 0.8813 - val_loss: 0.5139 - val_accuracy: 0.7684\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3069 - accuracy: 0.8800 - val_loss: 0.5159 - val_accuracy: 0.7653\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3157 - accuracy: 0.8763 - val_loss: 0.5196 - val_accuracy: 0.7594\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3220 - accuracy: 0.8763 - val_loss: 0.5174 - val_accuracy: 0.7622\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3201 - accuracy: 0.8637 - val_loss: 0.5174 - val_accuracy: 0.7631\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.3125 - accuracy: 0.8763 - val_loss: 0.5050 - val_accuracy: 0.7722\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2991 - accuracy: 0.8863 - val_loss: 0.5150 - val_accuracy: 0.7672\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2978 - accuracy: 0.8825 - val_loss: 0.5644 - val_accuracy: 0.7437\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.5113 - accuracy: 0.7616\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......encode_positions\n",
      ".........vars\n",
      "......global_max_pooling1d\n",
      ".........vars\n",
      "......layer_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......masking\n",
      ".........vars\n",
      "......transformer_encoder\n",
      ".........encoder_layers\n",
      "............transformer_encoder_block\n",
      "..............._attention_dropout\n",
      "..................vars\n",
      "..............._attention_layer\n",
      ".................._dropout_layer\n",
      ".....................vars\n",
      ".................._key_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._output_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._query_dense\n",
      ".....................vars\n",
      "........................0\n",
      ".................._softmax\n",
      ".....................vars\n",
      ".................._value_dense\n",
      ".....................vars\n",
      "........................0\n",
      "..................vars\n",
      "..............._attention_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._inner_dropout_layer\n",
      "..................vars\n",
      "..............._intermediate_activation_layer\n",
      "..................vars\n",
      "..............._intermediate_dense\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._output_dense\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "..............._output_dropout\n",
      "..................vars\n",
      "..............._output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      ".........output_normalization\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........33\n",
      ".........34\n",
      ".........35\n",
      ".........36\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-27 11:22:46       110744\n",
      "config.json                                    2023-03-27 11:22:46         2177\n",
      "metadata.json                                  2023-03-27 11:22:46           64\n",
      "500/500 [==============================] - 399s 797ms/step - loss: 0.3797 - accuracy: 0.8511\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.4643 - accuracy: 0.8125\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3896 - accuracy: 0.8524\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Small training dataset with high holdout share\n",
    "experiment(4, ipv6_task, 0.8, input_shape=(92, 24), output_shape=2, activation='softmax')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The 3rd task. List-processing algorithm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "def list_task(holdout):\n",
    "    # Load df from lst.pkl\n",
    "    df = pd.read_pickle('lst.pkl')\n",
    "    X = df['X'].values\n",
    "    y = df['y'].values\n",
    "\n",
    "    # Pad all X to the same length\n",
    "    max_len = max([len(x) for x in X])\n",
    "    X = pad_sequences(X, maxlen=max_len, padding='post', dtype='float32')\n",
    "\n",
    "    X = np.stack(X)\n",
    "    y = np.stack(y)\n",
    "\n",
    "    # Split the data into training and testing sets, preserving the ratio of valid/invalid times\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=holdout, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=holdout, random_state=42)\n",
    "\n",
    "    inspect_data(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    return X_train, X_val, y_train, y_val, X_test, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12800, 14)\n",
      "y_train shape: (12800, 2)\n",
      "X_val shape: (3200, 14)\n",
      "y_val shape: (3200, 2)\n",
      "X_test shape: (4000, 14)\n",
      "y_test shape: (4000, 2)\n",
      "X_train example: [0.439 0.47  0.306 0.43  0.187]\n",
      "y_train example: [0.71428571 0.85714286]\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_160 (Masking)       (None, 14, 1)             0         \n",
      "                                                                 \n",
      " layer_normalization_143 (La  (None, 14, 1)            2         \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " neural_turing_machine (RNN)  (None, 64)               383248    \n",
      "                                                                 \n",
      " dense_661 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 383,380\n",
      "Trainable params: 381,332\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "C: 346112, P: 22704, W: 2048, R: 32, O: 10304, M(n): 2048\n",
      "Epoch 1/200\n",
      "200/200 [==============================] - 620s 3s/step - loss: 0.6837 - accuracy: 0.4973 - val_loss: 0.6837 - val_accuracy: 0.4984\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6833 - accuracy: 0.4996 - val_loss: 0.6832 - val_accuracy: 0.5044\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6832 - accuracy: 0.5012 - val_loss: 0.6835 - val_accuracy: 0.4963\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6832 - accuracy: 0.4966 - val_loss: 0.6834 - val_accuracy: 0.5038\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6831 - accuracy: 0.4984 - val_loss: 0.6832 - val_accuracy: 0.5003\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6830 - accuracy: 0.5041 - val_loss: 0.6838 - val_accuracy: 0.4963\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6830 - accuracy: 0.4970 - val_loss: 0.6835 - val_accuracy: 0.5038\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6831 - accuracy: 0.4966 - val_loss: 0.6833 - val_accuracy: 0.5038\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6830 - accuracy: 0.4985 - val_loss: 0.6834 - val_accuracy: 0.5041\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6831 - accuracy: 0.5006 - val_loss: 0.6835 - val_accuracy: 0.5003\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6830 - accuracy: 0.5016 - val_loss: 0.6834 - val_accuracy: 0.5013\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6830 - accuracy: 0.4990 - val_loss: 0.6834 - val_accuracy: 0.4909\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6831 - accuracy: 0.5010 - val_loss: 0.6832 - val_accuracy: 0.5041\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 592s 3s/step - loss: 0.6831 - accuracy: 0.5004 - val_loss: 0.6831 - val_accuracy: 0.5031\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6830 - accuracy: 0.5022 - val_loss: 0.6834 - val_accuracy: 0.5113\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6830 - accuracy: 0.5012 - val_loss: 0.6831 - val_accuracy: 0.4963\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6830 - accuracy: 0.5030 - val_loss: 0.6833 - val_accuracy: 0.5041\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6831 - accuracy: 0.4952 - val_loss: 0.6833 - val_accuracy: 0.5038\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6831 - accuracy: 0.5010 - val_loss: 0.6832 - val_accuracy: 0.4963\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6830 - accuracy: 0.4966 - val_loss: 0.6833 - val_accuracy: 0.4963\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6830 - accuracy: 0.4974 - val_loss: 0.6833 - val_accuracy: 0.4963\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6830 - accuracy: 0.5033 - val_loss: 0.6835 - val_accuracy: 0.5038\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6829 - accuracy: 0.5047 - val_loss: 0.6835 - val_accuracy: 0.5038\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6830 - accuracy: 0.5045 - val_loss: 0.6833 - val_accuracy: 0.5038\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6830 - accuracy: 0.4980 - val_loss: 0.6832 - val_accuracy: 0.4963\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6830 - accuracy: 0.4998 - val_loss: 0.6831 - val_accuracy: 0.5066\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6830 - accuracy: 0.5012 - val_loss: 0.6831 - val_accuracy: 0.5066\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6829 - accuracy: 0.5016 - val_loss: 0.6833 - val_accuracy: 0.5038\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6830 - accuracy: 0.5071 - val_loss: 0.6834 - val_accuracy: 0.4963\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 590s 3s/step - loss: 0.6829 - accuracy: 0.5003 - val_loss: 0.6832 - val_accuracy: 0.5034\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6830 - accuracy: 0.5042 - val_loss: 0.6832 - val_accuracy: 0.5031\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6830 - accuracy: 0.4996 - val_loss: 0.6833 - val_accuracy: 0.5031\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6830 - accuracy: 0.5005 - val_loss: 0.6831 - val_accuracy: 0.5066\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6830 - accuracy: 0.4998 - val_loss: 0.6832 - val_accuracy: 0.5113\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 591s 3s/step - loss: 0.6830 - accuracy: 0.4999 - val_loss: 0.6834 - val_accuracy: 0.5038\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 592s 3s/step - loss: 0.6830 - accuracy: 0.5016 - val_loss: 0.6833 - val_accuracy: 0.4963\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6829 - accuracy: 0.4960 - val_loss: 0.6832 - val_accuracy: 0.4909\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 592s 3s/step - loss: 0.6830 - accuracy: 0.4958 - val_loss: 0.6831 - val_accuracy: 0.5031\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.6829 - accuracy: 0.5051 - val_loss: 0.6833 - val_accuracy: 0.4963\n",
      "125/125 [==============================] - 158s 1s/step - loss: 0.6857 - accuracy: 0.5035\n"
     ]
    }
   ],
   "source": [
    "# Make an attempt to solve the third task\n",
    "# We need more layers and more computing power to solve it\n",
    "\n",
    "X_train, X_val, y_train, y_val, X_test, y_test = list_task(holdout=0.2)\n",
    "\n",
    "model =build_ntm(input_shape=(14, 1), output_shape=2, activation='sigmoid')\n",
    "history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "loss, _ = model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}