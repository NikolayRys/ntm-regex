{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Based on https://github.com/MarkPKCollier/NeuralTuringMachine\n",
    "# Wire up the required libraries\n",
    "import sys\n",
    "# Add folder with implementation to the system path\n",
    "sys.path.insert(0, 'NeuralTuringMachine')\n",
    "\n",
    "# Import the rest of the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from ntm import NTMCell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5397\n"
     ]
    }
   ],
   "source": [
    "# Generate the data\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate array of 1 and 0 with 10000 rows and 100 columns\n",
    "X = np.random.randint(2, size=(10000, 100))\n",
    "\n",
    "# Define regular expression\n",
    "regex = \"000000\" # 6 zeros - pattern encountered approximately ~1/2 of the time\n",
    "pattern = re.compile(regex)\n",
    "\n",
    "# Apply regular expression to each row of X\n",
    "y = np.array([ [1.0, 0.0] if pattern.search(''.join(map(str, row))) else [0.0, 1.0] for row in X])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from utils import expand, learned_init\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "batch_size = 100\n",
    "number_of_controller_layers = 1\n",
    "number_of_controller_units = 128\n",
    "max_series_length = 100\n",
    "max_grad_norm = 50\n",
    "\n",
    "# Compatibility https://www.tensorflow.org/api_docs/python/tf/compat/v1/reset_default_graph\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "cell = NTMCell(number_of_controller_layers,             # Number of recurrent controller layers\n",
    "               number_of_controller_units,              # Number of units in the controller layer\n",
    "               128,                                     # Number of memory locations (N)\n",
    "               20,                                      # The vector size at each location (M)\n",
    "               1,                                       # Number of read heads (R)\n",
    "               1,                                       # Number of write heads (W)\n",
    "               output_dim=1,                            # The output dimension in bits\n",
    "               clip_value=20,                           # Maximum absolute value of controller and outputs.\n",
    "               shift_range=1,                           # The range of the shift operation\n",
    "               addressing_mode='content_and_location',  # Ways to access memory - using hybrid of content and location based addressing\n",
    "               reuse=False,                             # Whether to reuse the weights of a previous layer by the same name.\n",
    "               init_mode='constant')                    # Initialization mode for the weights of the controller, recommended setting.\n",
    "\n",
    "# ---------------\n",
    "\n",
    "initial_state = tuple(tf.contrib.rnn.LSTMStateTuple(\n",
    "    c=expand(tf.tanh(learned_init(number_of_controller_units)), dim=0, N=batch_size),\n",
    "    h=expand(tf.tanh(learned_init(number_of_controller_units)), dim=0, N=batch_size))\n",
    "                      for _ in range(number_of_controller_layers))\n",
    "\n",
    "\n",
    "\n",
    "inputs_placeholder = tf.placeholder(tf.float32, shape=(batch_size, None, max_series_length))\n",
    "outputs_placeholder = tf.placeholder(tf.float32, shape=(batch_size, None, 1))\n",
    "\n",
    "\n",
    "#\n",
    "# # NTN cell implements RNNCell interface\n",
    "# #ntm = tf.keras.layers.RNN(cell=cell, return_sequences=True, return_state=False,stateful=False, unroll=True)\n",
    "#\n",
    "# # https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/dynamic_rnn\n",
    "output_sequence, _state = tf.nn.dynamic_rnn(\n",
    "    cell=cell,\n",
    "    inputs=inputs_placeholder,\n",
    "    time_major=False,\n",
    "    dtype=tf.float32,\n",
    "    initial_state=None) # initial_state)\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001) # Starting learning rate\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=outputs_placeholder, logits=output_sequence[:, 1:, :])\n",
    "loss = tf.reduce_sum(cross_entropy)/batch_size\n",
    "\n",
    "\n",
    "trainable_variables = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, trainable_variables), max_grad_norm)\n",
    "train_op = optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "max_seq_len_placeholder = tf.placeholder(tf.int32)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "convergence_on_target_task = None\n",
    "convergence_on_multi_task = None\n",
    "performance_on_target_task = None\n",
    "performance_on_multi_task = None\n",
    "generalization_from_target_task = None\n",
    "generalization_from_multi_task = None\n",
    "\n",
    "data_generator = RegexDataGenerator()\n",
    "target_point = args.max_seq_len\n",
    "curriculum_point = 1 if args.curriculum not in ('prediction_gain', 'none') else target_point\n",
    "progress_error = 1.0\n",
    "convergence_error = 0.1\n",
    "\n",
    "if args.curriculum == 'prediction_gain':\n",
    "    exp3s = Exp3S(args.max_seq_len, 0.001, 0, 0.05)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(initializer)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}